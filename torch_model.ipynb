{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58491147-580d-409e-aedf-2d49997dfea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric\n",
      "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting aiohttp (from torch-geometric)\n",
      "  Using cached aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: fsspec in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (2024.12.0)\n",
      "Requirement already satisfied: jinja2 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (6.0.0)\n",
      "Requirement already satisfied: pyparsing in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: requests in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (2.32.3)\n",
      "Collecting tqdm (from torch-geometric)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch-geometric)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch-geometric)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from aiohttp->torch-geometric) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch-geometric)\n",
      "  Using cached propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch-geometric)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from jinja2->torch-geometric) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (2024.8.30)\n",
      "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Using cached aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Using cached propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "Installing collected packages: tqdm, propcache, multidict, frozenlist, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch-geometric\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 frozenlist-1.5.0 multidict-6.1.0 propcache-0.2.1 torch-geometric-2.6.1 tqdm-4.67.1 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f8ed93-0f7e-4ded-8b2a-73e2374eb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import relu, sigmoid, binary_cross_entropy\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56272de-cf3d-409c-87a2-ee7fcb82fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self,  layers):\n",
    "        super(GNN, self).__init__()\n",
    "        convs = []\n",
    "        Bs = []\n",
    "        for l_in, l_out in zip(layers[:-1], layers[1:]):\n",
    "            convs.append(GCNConv(l_in, l_out, bias=False))\n",
    "            torch.nn.init.normal_(convs[-1].lin.weight,mean=0.01, std=0.3)\n",
    "            Bs.append(torch.nn.Linear(l_in, l_out, bias=False))\n",
    "            torch.nn.init.normal_(Bs[-1].weight, mean=0.5, std=0.3)\n",
    "        self.convs = torch.nn.ModuleList(convs)\n",
    "        self.Bs = torch.nn.ModuleList(Bs)\n",
    "\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        for conv, B in zip(self.convs, self.Bs):\n",
    "            x = conv(x, edge_index) -  B(x)\n",
    "            x = relu(x)\n",
    "        return x\n",
    "\n",
    "class EdgesMLP(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(EdgesMLP, self).__init__()\n",
    "        linears = []\n",
    "        for l_in, l_out in zip(layers[:-1], layers[1:]):\n",
    "            linears.append(Linear(l_in, l_out, bias=False))\n",
    "            torch.nn.init.normal_(linears[-1].weight, mean=0.5, std=0.3)\n",
    "        self.linears = linears\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        for linear in self.linears:\n",
    "            x = linear(x)\n",
    "            x = sigmoid(x)\n",
    "        return torch.squeeze(x, 1)\n",
    "\n",
    "def get_models(params):\n",
    "    layers_gnn = params[\"count_neuron_layers_gnn\"]\n",
    "    layers_edge = params[\"count_neuron_layers_edge\"]\n",
    "    node_gnn = GNN(layers_gnn)\n",
    "    edge_linear = EdgesMLP(layers_edge)\n",
    "    return node_gnn, edge_linear\n",
    "\n",
    "def list_batchs(dataset, batch_size):\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        yield dataset[i:i+batch_size]\n",
    "\n",
    "def get_tensor_from_graph(graph):\n",
    "    i = graph[\"A\"]\n",
    "    v_in = [rev_dist(e) for e in graph[\"edges_feature\"]]\n",
    "    v_true = graph[\"true_edges\"]\n",
    "    x = graph[\"nodes_feature\"]\n",
    "    N = len(x)\n",
    "    \n",
    "    X = torch.tensor(data=x, dtype=torch.float32)\n",
    "    sp_A = torch.sparse_coo_tensor(indices=i, values=v_in, size=(N, N), dtype=torch.float32)\n",
    "    E_true = torch.tensor(data=v_true, dtype=torch.float32)\n",
    "    return X, sp_A, E_true, i\n",
    "\n",
    "def validation(models, dataset, criterion):\n",
    "    my_loss_list = []\n",
    "    for j, graph in enumerate(dataset):\n",
    "        X, sp_A, E_true, i = get_tensor_from_graph(graph)\n",
    "        H_end = models[0](X, sp_A)\n",
    "        Omega = torch.cat([H_end[i[0]], H_end[i[1]]],dim=1)\n",
    "        E_pred = models[1](Omega)\n",
    "        loss = criterion(E_pred, E_true)\n",
    "        my_loss_list.append(loss.item())\n",
    "        print(f\"{(j+1)/len(dataset)*100:.2f} % loss = {my_loss_list[-1]:.5f} {' '*30}\", end='\\r')\n",
    "    return np.mean(my_loss_list)\n",
    "\n",
    "def split_train_val(dataset, val_split=0.2, shuffle=True, seed=1234):\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        rng.shuffle(dataset)\n",
    "    train_size = int(len(dataset) * (1 - val_split))\n",
    "    train_dataset = dataset[:train_size]\n",
    "    val_dataset = dataset[train_size:]\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def train_step(models, batch, optimizer, criterion):\n",
    "    optimizer.zero_grad()\n",
    "    my_loss_list = []\n",
    "   \n",
    "    for j, graph in enumerate(batch):\n",
    "        X, sp_A, E_true, i = get_tensor_from_graph(graph)\n",
    "        H_end = models[0](X, sp_A)\n",
    "        Omega = torch.cat([H_end[i[0]], H_end[i[1]]],dim=1)\n",
    "        E_pred = models[1](Omega)\n",
    "        loss = criterion(E_pred, E_true)\n",
    "        my_loss_list.append(loss.item())\n",
    "        print(f\"Batch loss={my_loss_list[-1]:.4f}\" + \" \"*40, end=\"\\r\")\n",
    "        loss.backward()\n",
    "    optimizer.step()\n",
    "    return np.mean(my_loss_list)\n",
    "\n",
    "def train_model(params, models, dataset, path_save, save_frequency=5, restart=False):  \n",
    "    optimizer = torch.optim.Adam(\n",
    "    list(models[0].parameters()) + list(models[1].parameters()),\n",
    "    lr=learning_rate,\n",
    "    )\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    loss_list = []\n",
    "    with open('log.txt', 'a') as f:\n",
    "        for key, val in params.items():\n",
    "            f.write(f\"{key}:\\t{val}\\n\")\n",
    "    train_dataset, val_dataset = split_train_val(dataset, val_split=0.1)\n",
    "    for k in range(params[\"epochs\"]):\n",
    "        my_loss_list = []\n",
    "        \n",
    "        for l, batch in enumerate(list_batchs(train_dataset, params[\"batch_size\"])):\n",
    "            batch_loss = train_step(models, batch, optimizer, criterion)\n",
    "            my_loss_list.append(batch_loss)\n",
    "            print(f\"Batch # {l+1} loss={my_loss_list[-1]:.4f}\" + \" \"*40)\n",
    "        train_val = np.mean(my_loss_list)\n",
    "        loss_list.append(train_val)\n",
    "        validation_val = validation(models, val_dataset, criterion)\n",
    "        print(\"=\"*10, f\"EPOCH #{k+1}\",\"=\"*10, f\"({train_val:.4f}/{validation_val:.4f})\")\n",
    "        \n",
    "        # TODO: DELETE RESTART\n",
    "        if restart and k>=2 and abs(loss_list[k] - loss_list[k-1]) < 0.001:\n",
    "            return True\n",
    "            \n",
    "            \n",
    "        with open('log.txt', 'a') as f:\n",
    "            f.write(f\"EPOCH #{k}\\t {train_val:.8f} (VAL: {validation_val:.8f})\\n\")  \n",
    "        if (k+1) % save_frequency == 0:\n",
    "            num = k//save_frequency\n",
    "            torch.save(models[0].state_dict(), path_save+f\"_node_gnn_{num}\")\n",
    "            torch.save(models[1].state_dict(), path_save+f\"_edge_linear_{num}\")\n",
    "    torch.save(models[0].state_dict(), path_save+f\"_node_gnn_end\")\n",
    "    torch.save(models[1].state_dict(), path_save+f\"_edge_linear_end\")\n",
    "    return False # For restart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d873f8d-d98c-4325-9aac-3cc68cb7b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET INFO:\n",
      "count row: 11900\n",
      "first: dict_keys(['A', 'nodes_feature', 'edges_feature', 'true_edges'])\n",
      "\t A: (2, 925)\n",
      "\t nodes_feature: (451, 9)\n",
      "\t edges_feature: (925,)\n",
      "\t true_edges: (925,)\n",
      "end: dict_keys(['A', 'nodes_feature', 'edges_feature', 'true_edges'])\n",
      "\t A: (2, 1597)\n",
      "\t nodes_feature: (778, 9)\n",
      "\t edges_feature: (1597,)\n",
      "\t true_edges: (1597,)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# with open(\"../dataset.json\", \"r\") as f:\n",
    "#     dataset = json.load(f)['dataset']\n",
    "with open(\"/home/daniil/pager_11000_4N_seg.json\", \"r\") as f:\n",
    "    dataset = json.load(f)['dataset']\n",
    "\n",
    "print(\"DATASET INFO:\")\n",
    "print(\"count row:\", len(dataset))\n",
    "print(\"first:\", dataset[0].keys())\n",
    "print(f\"\\t A:\", np.shape(dataset[0][\"A\"]))\n",
    "print(f\"\\t nodes_feature:\", np.shape(dataset[0][\"nodes_feature\"]))\n",
    "print(f\"\\t edges_feature:\", np.shape(dataset[0][\"edges_feature\"]))\n",
    "print(f\"\\t true_edges:\", np.shape(dataset[0][\"true_edges\"]))\n",
    "print(\"end:\", dataset[-1].keys())\n",
    "print(f\"\\t A:\", np.shape(dataset[-1][\"A\"]))\n",
    "print(f\"\\t nodes_feature:\", np.shape(dataset[-1][\"nodes_feature\"]))\n",
    "print(f\"\\t edges_feature:\", np.shape(dataset[-1][\"edges_feature\"]))\n",
    "print(f\"\\t true_edges:\", np.shape(dataset[-1][\"true_edges\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5096a10-c1be-42c4-9a04-fc6d776ea7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_dist(a):\n",
    "    if a==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1/a\n",
    "        \n",
    "i = dataset[0][\"A\"]\n",
    "v_in = [rev_dist(e) for e in dataset[0][\"edges_feature\"]]\n",
    "v_true = dataset[0][\"true_edges\"]\n",
    "x = dataset[0][\"nodes_feature\"]\n",
    "N = len(x)\n",
    "\n",
    "X = torch.Tensor(x)\n",
    "sp_A = torch.sparse_coo_tensor(i, v_in, (N, N))\n",
    "E_true = torch.Tensor(v_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84eb1c09-c6e5-4280-ac3e-b5763b89b46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_pred:\n",
      "tensor([0.5066, 0.5004, 0.5004, 0.9795, 0.9812, 0.9844, 0.8764, 0.9826, 0.9956,\n",
      "        0.9857, 0.9839, 0.9959, 0.9866, 0.9991, 1.0000, 0.9969, 1.0000, 1.0000,\n",
      "        1.0000, 0.9999, 0.9991, 0.9991, 0.9999, 1.0000, 0.9993, 1.0000, 1.0000,\n",
      "        0.9998, 0.9835, 1.0000, 1.0000, 0.9997, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9018, 0.8834, 0.9021, 0.9257, 0.7123, 0.9141, 0.7482, 0.9124,\n",
      "        0.9338, 0.7073, 0.9298, 0.5291, 0.5000, 0.5000, 0.5000, 0.5000, 0.5291,\n",
      "        0.7931, 0.5291, 0.5935, 0.5018, 0.5018, 0.9284, 0.9609, 0.9312, 0.5000,\n",
      "        0.5000, 0.9336, 0.3938, 0.3850, 0.9317, 0.4818, 0.5000, 0.5000, 0.5277,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5046, 0.5277, 0.5000, 0.5018,\n",
      "        0.6054, 0.5006, 0.5006, 0.7661, 0.4883, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.6158, 0.5116, 0.5116, 0.5116, 0.9913, 0.9790, 0.5568, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5195, 0.5631, 0.5581, 0.5000, 0.5439, 0.5950,\n",
      "        0.5000, 0.6602, 0.5388, 0.5439, 0.5463, 0.5499, 0.6012, 0.6627, 0.5131,\n",
      "        0.5131, 0.6718, 0.5131, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5265,\n",
      "        0.5105, 0.6371, 0.5063, 0.5063, 0.5063, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5010, 0.5010, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5082, 0.5082, 0.5082, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.9488, 0.5460, 0.5460,\n",
      "        0.9540, 0.9540, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5478, 0.6888, 0.5478, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.7026, 0.5000, 0.5000, 0.7992, 0.5136, 0.5210,\n",
      "        0.5210, 0.5000, 0.5795, 0.5000, 0.5795, 0.5000, 0.5000, 0.5000, 0.5095,\n",
      "        0.5095, 0.5095, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5795, 0.5000, 0.5051,\n",
      "        0.5586, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5175, 0.5000, 0.5011, 0.5011, 0.5011, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5163, 0.5397, 0.5000, 0.5536, 0.5000, 0.5000, 0.5034,\n",
      "        0.5034, 0.5034, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.7853, 0.5000, 0.8184, 0.5000, 0.6021, 0.5000, 0.5000, 0.5179, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.7853, 0.5000, 0.7504, 0.5205, 0.7710, 0.8278,\n",
      "        0.5161, 0.8321, 0.5238, 0.5065, 0.5065, 0.5065, 0.5000, 0.6254, 0.5000,\n",
      "        0.5000, 0.5179, 0.5334, 0.5179, 0.5000, 0.5155, 0.6464, 0.5000, 0.5000,\n",
      "        0.5000, 0.5010, 0.5010, 0.5040, 0.5040, 0.5040, 0.5040, 0.5025, 0.5025,\n",
      "        0.5025, 0.5025, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5397,\n",
      "        0.5000, 0.5000, 0.5025, 0.5025, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5011, 0.5011, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6254, 0.5000, 0.5081,\n",
      "        0.5081, 0.5000, 0.5000, 0.5000, 0.5000, 0.5155, 0.5000, 0.5010, 0.5010,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7855,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.7498, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.9906, 0.5000, 0.9906, 0.5000, 0.9906, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5249, 0.5000, 0.5205, 0.5205,\n",
      "        0.7785, 0.5000, 0.5198, 0.8612, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5611, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7498,\n",
      "        0.5000, 0.5173, 0.5173, 0.5000, 0.5069, 0.5000, 0.5069, 0.5249, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.9906, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5731,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6786, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5249, 0.5000, 0.5016, 0.5016, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.8514, 0.9310, 0.5276, 0.8055, 0.5000, 0.5039, 0.5039, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5069, 0.5105, 0.5074, 0.7210, 0.5000, 0.5000, 0.6786, 0.5000,\n",
      "        0.5118, 0.5118, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.9310, 0.5177, 0.8138, 0.5585,\n",
      "        0.5207, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5105, 0.5000, 0.5007, 0.7326, 0.5150, 0.5150,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.9952, 0.5000, 0.5833, 0.5833, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5177, 0.5000, 0.5011, 0.5011, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6815, 0.5000, 0.5120,\n",
      "        0.5120, 0.5000, 0.5744, 0.5000, 0.5744, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.9968, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5223, 0.5000, 0.6875, 0.5223, 0.5125, 0.9969, 0.5000,\n",
      "        0.5000, 0.5000, 0.6875, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5223, 0.5000, 0.9968, 0.5014, 0.5895, 0.5895, 0.5895, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.9999, 0.6397, 0.6397, 0.5000, 0.5000, 0.5477, 0.5477, 0.5477, 0.5477,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5744,\n",
      "        0.5000, 0.5790, 0.5047, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
      "       grad_fn=<SqueezeBackward1>) \n",
      "E_true:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1.])\n",
      "Loss =  tensor(0.6334, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/project/PageR/env/lib/python3.12/site-packages/torch_geometric/utils/_spmm.py:66: UserWarning: Converting sparse tensor to CSR format for more efficient processing. Consider converting your sparse tensor to CSR format beforehand to avoid repeated conversion (got 'torch.sparse_coo')\n",
      "  warnings.warn(f\"Converting sparse tensor to CSR format for more \"\n",
      "/home/daniil/project/PageR/env/lib/python3.12/site-packages/torch_geometric/utils/_spmm.py:70: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  src = src.to_sparse_csr()\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"count_neuron_layers_gnn\": [9, 27, 18],\n",
    "    \"count_neuron_layers_edge\": [18*2, 1],\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 400,\n",
    "}\n",
    "\n",
    "learning_rate = 0.05\n",
    "\n",
    "node_gnn, edge_linear = get_models(params)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(node_gnn.parameters()) + list(edge_linear.parameters()),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "H_end = node_gnn(X, sp_A)\n",
    "Omega = torch.cat([H_end[i[0]], H_end[i[1]]],dim=1)\n",
    "E_pred = edge_linear(Omega)\n",
    "print(f\"E_pred:\\n{E_pred}\", f\"\\nE_true:\\n{E_true}\")\n",
    "print(\"Loss = \", criterion(E_pred, E_true))\n",
    "\n",
    "del optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e60566c-0723-4b95-810b-594ac69c22f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch # 1 loss=1.7818                                        \n",
      "Batch # 2 loss=4.8147                                        \n",
      "Batch # 3 loss=2.3238                                        \n",
      "Batch # 4 loss=0.6592                                        \n",
      "Batch # 5 loss=0.6754                                        \n",
      "Batch # 6 loss=0.6888                                        \n",
      "Batch # 7 loss=0.6781                                        \n",
      "Batch # 8 loss=0.6668                                        \n",
      "Batch # 9 loss=0.6686                                        \n",
      "Batch # 10 loss=0.6430                                        \n",
      "Batch # 11 loss=0.6633                                        \n",
      "Batch # 12 loss=0.6160                                        \n",
      "Batch # 13 loss=0.6769                                        \n",
      "Batch # 14 loss=0.6758                                        \n",
      "Batch # 15 loss=0.6768                                        \n",
      "Batch # 16 loss=0.6778                                        \n",
      "Batch # 17 loss=0.6805                                        \n",
      "Batch # 18 loss=0.6806                                        \n",
      "Batch # 19 loss=0.6750                                        \n",
      "Batch # 20 loss=0.6760                                        \n",
      "Batch # 21 loss=0.6799                                        \n",
      "Batch # 22 loss=0.6869                                        \n",
      "Batch # 23 loss=0.6764                                        \n",
      "Batch # 24 loss=0.6702                                        \n",
      "Batch # 25 loss=1.3400                                        \n",
      "Batch # 26 loss=0.6564                                        \n",
      "Batch # 27 loss=0.6720                                        \n",
      "========== EPOCH #1 ========== (0.9511/0.6768)        \n",
      "Batch # 1 loss=0.6774                                        \n",
      "Batch # 2 loss=0.6747                                        \n",
      "Batch # 3 loss=0.6757                                        \n",
      "Batch # 4 loss=0.6751                                        \n",
      "Batch # 5 loss=0.6789                                        \n",
      "Batch # 6 loss=0.6811                                        \n",
      "Batch # 7 loss=0.6827                                        \n",
      "Batch # 8 loss=0.6850                                        \n",
      "Batch # 9 loss=0.6840                                        \n",
      "Batch # 10 loss=0.6840                                        \n",
      "Batch # 11 loss=0.6842                                        \n",
      "Batch # 12 loss=0.6850                                        \n",
      "Batch # 13 loss=0.6846                                        \n",
      "Batch # 14 loss=0.6851                                        \n",
      "Batch # 15 loss=0.6835                                        \n",
      "Batch # 16 loss=0.6831                                        \n",
      "Batch # 17 loss=0.6861                                        \n",
      "Batch # 18 loss=0.6815                                        \n",
      "Batch # 19 loss=0.6790                                        \n",
      "Batch # 20 loss=0.6066                                        \n",
      "Batch # 21 loss=0.6150                                        \n",
      "Batch # 22 loss=0.7357                                        \n",
      "Batch # 23 loss=0.6159                                        \n",
      "Batch # 24 loss=0.6488                                        \n",
      "Batch # 25 loss=0.6680                                        \n",
      "Batch # 26 loss=0.6784                                        \n",
      "Batch # 27 loss=0.6740                                        \n",
      "========== EPOCH #2 ========== (0.6738/0.6746)        \n",
      "Batch # 1 loss=0.6743                                        \n",
      "Batch # 2 loss=0.6743                                        \n",
      "Batch # 3 loss=0.6750                                        \n",
      "Batch # 4 loss=0.6741                                        \n",
      "Batch # 5 loss=0.6747                                        \n",
      "Batch # 6 loss=0.6743                                        \n",
      "Batch # 7 loss=0.6764                                        \n",
      "Batch # 8 loss=0.6844                                        \n",
      "Batch # 9 loss=0.6770                                        \n",
      "Batch # 10 loss=0.6749                                        \n",
      "Batch # 11 loss=0.6745                                        \n",
      "Batch # 12 loss=0.6767                                        \n",
      "Batch # 13 loss=0.6747                                        \n",
      "Batch # 14 loss=0.6758                                        \n",
      "Batch # 15 loss=0.6768                                        \n",
      "Batch # 16 loss=0.6743                                        \n",
      "Batch # 17 loss=0.6748                                        \n",
      "Batch # 18 loss=0.6762                                        \n",
      "Batch # 19 loss=0.6724                                        \n",
      "Batch # 20 loss=0.6704                                        \n",
      "Batch # 21 loss=0.6648                                        \n",
      "Batch # 22 loss=0.6081                                        \n",
      "Batch # 23 loss=0.6563                                        \n",
      "Batch # 24 loss=0.6667                                        \n",
      "Batch # 25 loss=0.6715                                        \n",
      "Batch # 26 loss=0.6816                                        \n",
      "Batch # 27 loss=0.6740                                        \n",
      "========== EPOCH #3 ========== (0.6714/0.6733)        \n",
      "Batch # 1 loss=0.6741                                        \n",
      "Batch # 2 loss=0.6729                                        \n",
      "Batch # 3 loss=0.6750                                        \n",
      "Batch # 4 loss=0.6743                                        \n",
      "Batch # 5 loss=0.6755                                        \n",
      "Batch # 6 loss=0.6745                                        \n",
      "Batch # 7 loss=0.6787                                        \n",
      "Batch # 8 loss=0.6816                                        \n",
      "Batch # 9 loss=0.6750                                        \n",
      "Batch # 10 loss=0.6718                                        \n",
      "Batch # 11 loss=0.6717                                        \n",
      "Batch # 12 loss=0.6701                                        \n",
      "Batch # 13 loss=0.6365                                        \n",
      "Batch # 14 loss=0.5404                                        \n",
      "Batch # 15 loss=0.6097                                        \n",
      "Batch # 16 loss=0.5070                                        \n",
      "Batch # 17 loss=0.5889                                        \n",
      "Batch # 18 loss=0.4922                                        \n",
      "Batch # 19 loss=0.7065                                        \n",
      "Batch # 20 loss=0.4490                                        \n",
      "Batch # 21 loss=0.5845                                        \n",
      "Batch # 22 loss=0.6280                                        \n",
      "Batch # 23 loss=0.6084                                        \n",
      "Batch # 24 loss=0.4872                                        \n",
      "Batch # 25 loss=0.5814                                        \n",
      "Batch # 26 loss=0.4921                                        \n",
      "Batch # 27 loss=0.5090                                        \n",
      "========== EPOCH #4 ========== (0.6117/0.5738)        \n",
      "Batch # 1 loss=0.5774                                        \n",
      "Batch # 2 loss=0.4611                                        \n",
      "Batch # 3 loss=0.4857                                        \n",
      "Batch # 4 loss=0.4750                                        \n",
      "Batch # 5 loss=0.5435                                        \n",
      "Batch # 6 loss=0.4957                                        \n",
      "Batch # 7 loss=0.5761                                        \n",
      "Batch # 8 loss=0.5545                                        \n",
      "Batch # 9 loss=0.4565                                        \n",
      "Batch # 10 loss=0.4433                                        \n",
      "Batch # 11 loss=0.4637                                        \n",
      "Batch # 12 loss=0.4303                                        \n",
      "Batch # 13 loss=0.4493                                        \n",
      "Batch # 14 loss=0.4264                                        \n",
      "Batch # 15 loss=0.4436                                        \n",
      "Batch # 16 loss=0.4250                                        \n",
      "Batch # 17 loss=0.4365                                        \n",
      "Batch # 18 loss=0.4586                                        \n",
      "Batch # 19 loss=0.4116                                        \n",
      "Batch # 20 loss=0.4261                                        \n",
      "Batch # 21 loss=0.4197                                        \n",
      "Batch # 22 loss=0.4396                                        \n",
      "Batch # 23 loss=0.4454                                        \n",
      "Batch # 24 loss=0.4237                                        \n",
      "Batch # 25 loss=0.4325                                        \n",
      "Batch # 26 loss=0.4140                                        \n",
      "Batch # 27 loss=0.4424                                        \n",
      "========== EPOCH #5 ========== (0.4614/0.4188)        \n",
      "Batch # 1 loss=0.4316                                        \n",
      "Batch # 2 loss=0.4203                                        \n",
      "Batch # 3 loss=0.4198                                        \n",
      "Batch # 4 loss=0.4035                                        \n",
      "Batch # 5 loss=0.4311                                        \n",
      "Batch # 6 loss=0.4138                                        \n",
      "Batch # 7 loss=0.4251                                        \n",
      "Batch # 8 loss=0.4099                                        \n",
      "Batch # 9 loss=0.4385                                        \n",
      "Batch # 10 loss=0.4016                                        \n",
      "Batch # 11 loss=0.4071                                        \n",
      "Batch # 12 loss=0.4231                                        \n",
      "Batch # 13 loss=0.4025                                        \n",
      "Batch # 14 loss=0.4183                                        \n",
      "Batch # 15 loss=0.4057                                        \n",
      "Batch # 16 loss=0.4005                                        \n",
      "Batch # 17 loss=0.4161                                        \n",
      "Batch # 18 loss=0.4245                                        \n",
      "Batch # 19 loss=0.4041                                        \n",
      "Batch # 20 loss=0.3946                                        \n",
      "Batch # 21 loss=0.4142                                        \n",
      "Batch # 22 loss=0.4179                                        \n",
      "Batch # 23 loss=0.4296                                        \n",
      "Batch # 24 loss=0.4092                                        \n",
      "Batch # 25 loss=0.4162                                        \n",
      "Batch # 26 loss=0.4039                                        \n",
      "Batch # 27 loss=0.4205                                        \n",
      "========== EPOCH #6 ========== (0.4149/0.4060)        \n",
      "Batch # 1 loss=0.4153                                        \n",
      "Batch # 2 loss=0.4102                                        \n",
      "Batch # 3 loss=0.3959                                        \n",
      "Batch # 4 loss=0.3993                                        \n",
      "Batch # 5 loss=0.4061                                        \n",
      "Batch # 6 loss=0.4053                                        \n",
      "Batch # 7 loss=0.4084                                        \n",
      "Batch # 8 loss=0.3941                                        \n",
      "Batch # 9 loss=0.4286                                        \n",
      "Batch # 10 loss=0.3992                                        \n",
      "Batch # 11 loss=0.4007                                        \n",
      "Batch # 12 loss=0.4125                                        \n",
      "Batch # 13 loss=0.4138                                        \n",
      "Batch # 14 loss=0.4362                                        \n",
      "Batch # 15 loss=0.3982                                        \n",
      "Batch # 16 loss=0.4287                                        \n",
      "Batch # 17 loss=0.4605                                        \n",
      "Batch # 18 loss=0.4386                                        \n",
      "Batch # 19 loss=0.4483                                        \n",
      "Batch # 20 loss=0.3997                                        \n",
      "Batch # 21 loss=0.4343                                        \n",
      "Batch # 22 loss=0.4438                                        \n",
      "Batch # 23 loss=0.4339                                        \n",
      "Batch # 24 loss=0.4543                                        \n",
      "Batch # 25 loss=0.4214                                        \n",
      "Batch # 26 loss=0.4202                                        \n",
      "Batch # 27 loss=0.4513                                        \n",
      "========== EPOCH #7 ========== (0.4207/0.4036)        \n",
      "Batch # 1 loss=0.4140                                        \n",
      "Batch # 2 loss=0.4376                                        \n",
      "Batch # 3 loss=0.3999                                        \n",
      "Batch # 4 loss=0.4173                                        \n",
      "Batch # 5 loss=0.4209                                        \n",
      "Batch # 6 loss=0.4155                                        \n",
      "Batch # 7 loss=0.4193                                        \n",
      "Batch # 8 loss=0.3986                                        \n",
      "Batch # 9 loss=0.4413                                        \n",
      "Batch # 10 loss=0.3973                                        \n",
      "Batch # 11 loss=0.4109                                        \n",
      "Batch # 12 loss=0.4190                                        \n",
      "Batch # 13 loss=0.4010                                        \n",
      "Batch # 14 loss=0.4051                                        \n",
      "Batch # 15 loss=0.4068                                        \n",
      "Batch # 16 loss=0.3874                                        \n",
      "Batch # 17 loss=0.4193                                        \n",
      "Batch # 18 loss=0.4126                                        \n",
      "Batch # 19 loss=0.4117                                        \n",
      "Batch # 20 loss=0.3868                                        \n",
      "Batch # 21 loss=0.4227                                        \n",
      "Batch # 22 loss=0.4107                                        \n",
      "Batch # 23 loss=0.4376                                        \n",
      "Batch # 24 loss=0.4025                                        \n",
      "Batch # 25 loss=0.4187                                        \n",
      "Batch # 26 loss=0.3996                                        \n",
      "Batch # 27 loss=0.4211                                        \n",
      "========== EPOCH #8 ========== (0.4124/0.4088)        \n",
      "Batch # 1 loss=0.4171                                        \n",
      "Batch # 2 loss=0.4074                                        \n",
      "Batch # 3 loss=0.3990                                        \n",
      "Batch # 4 loss=0.3933                                        \n",
      "Batch # 5 loss=0.4077                                        \n",
      "Batch # 6 loss=0.4008                                        \n",
      "Batch # 7 loss=0.4110                                        \n",
      "Batch # 8 loss=0.3930                                        \n",
      "Batch # 9 loss=0.4140                                        \n",
      "Batch # 10 loss=0.3869                                        \n",
      "Batch # 11 loss=0.3982                                        \n",
      "Batch # 12 loss=0.4071                                        \n",
      "Batch # 13 loss=0.3981                                        \n",
      "Batch # 14 loss=0.4086                                        \n",
      "Batch # 15 loss=0.3946                                        \n",
      "Batch # 16 loss=0.3948                                        \n",
      "Batch # 17 loss=0.4147                                        \n",
      "Batch # 18 loss=0.4092                                        \n",
      "Batch # 19 loss=0.4196                                        \n",
      "Batch # 20 loss=0.4105                                        \n",
      "Batch # 21 loss=0.4215                                        \n",
      "Batch # 22 loss=0.4483                                        \n",
      "Batch # 23 loss=0.4161                                        \n",
      "Batch # 24 loss=0.4143                                        \n",
      "Batch # 25 loss=0.4013                                        \n",
      "Batch # 26 loss=0.4107                                        \n",
      "Batch # 27 loss=0.4141                                        \n",
      "========== EPOCH #9 ========== (0.4078/0.4030)        \n",
      "Batch # 1 loss=0.4150                                        \n",
      "Batch # 2 loss=0.4043                                        \n",
      "Batch # 3 loss=0.3964                                        \n",
      "Batch # 4 loss=0.3944                                        \n",
      "Batch # 5 loss=0.4031                                        \n",
      "Batch # 6 loss=0.4015                                        \n",
      "Batch # 7 loss=0.4052                                        \n",
      "Batch # 8 loss=0.3954                                        \n",
      "Batch # 9 loss=0.4160                                        \n",
      "Batch # 10 loss=0.3865                                        \n",
      "Batch # 11 loss=0.3943                                        \n",
      "Batch # 12 loss=0.4050                                        \n",
      "Batch # 13 loss=0.3890                                        \n",
      "Batch # 14 loss=0.4003                                        \n",
      "Batch # 15 loss=0.3938                                        \n",
      "Batch # 16 loss=0.3808                                        \n",
      "Batch # 17 loss=0.4030                                        \n",
      "Batch # 18 loss=0.4125                                        \n",
      "Batch # 19 loss=0.3887                                        \n",
      "Batch # 20 loss=0.3794                                        \n",
      "Batch # 21 loss=0.3983                                        \n",
      "Batch # 22 loss=0.4129                                        \n",
      "Batch # 23 loss=0.4221                                        \n",
      "Batch # 24 loss=0.4122                                        \n",
      "Batch # 25 loss=0.4019                                        \n",
      "Batch # 26 loss=0.3912                                        \n",
      "Batch # 27 loss=0.4077                                        \n",
      "========== EPOCH #10 ========== (0.4004/0.4034)       \n",
      "Batch # 1 loss=0.4113                                        \n",
      "Batch # 2 loss=0.4262                                        \n",
      "Batch # 3 loss=0.3849                                        \n",
      "Batch # 4 loss=0.3913                                        \n",
      "Batch # 5 loss=0.4200                                        \n",
      "Batch # 6 loss=0.3911                                        \n",
      "Batch # 7 loss=0.4211                                        \n",
      "Batch # 8 loss=0.4104                                        \n",
      "Batch # 9 loss=0.4279                                        \n",
      "Batch # 10 loss=0.4234                                        \n",
      "Batch # 11 loss=0.3953                                        \n",
      "Batch # 12 loss=0.4275                                        \n",
      "Batch # 13 loss=0.3914                                        \n",
      "Batch # 14 loss=0.4053                                        \n",
      "Batch # 15 loss=0.4054                                        \n",
      "Batch # 16 loss=0.3836                                        \n",
      "Batch # 17 loss=0.4137                                        \n",
      "Batch # 18 loss=0.4147                                        \n",
      "Batch # 19 loss=0.3975                                        \n",
      "Batch # 20 loss=0.3915                                        \n",
      "Batch # 21 loss=0.4018                                        \n",
      "Batch # 22 loss=0.4139                                        \n",
      "Batch # 23 loss=0.4104                                        \n",
      "Batch # 24 loss=0.4103                                        \n",
      "Batch # 25 loss=0.3948                                        \n",
      "Batch # 26 loss=0.3981                                        \n",
      "Batch # 27 loss=0.4074                                        \n",
      "========== EPOCH #11 ========== (0.4063/0.4071)       \n",
      "Batch # 1 loss=0.4143                                        \n",
      "Batch # 2 loss=0.3920                                        \n",
      "Batch # 3 loss=0.3909                                        \n",
      "Batch # 4 loss=0.3818                                        \n",
      "Batch # 5 loss=0.4007                                        \n",
      "Batch # 6 loss=0.3907                                        \n",
      "Batch # 7 loss=0.3991                                        \n",
      "Batch # 8 loss=0.3868                                        \n",
      "Batch # 9 loss=0.4018                                        \n",
      "Batch # 10 loss=0.3758                                        \n",
      "Batch # 11 loss=0.3837                                        \n",
      "Batch # 12 loss=0.3952                                        \n",
      "Batch # 13 loss=0.3797                                        \n",
      "Batch # 14 loss=0.3907                                        \n",
      "Batch # 15 loss=0.3837                                        \n",
      "Batch # 16 loss=0.3724                                        \n",
      "Batch # 17 loss=0.3916                                        \n",
      "Batch # 18 loss=0.4042                                        \n",
      "Batch # 19 loss=0.3908                                        \n",
      "Batch # 20 loss=0.3720                                        \n",
      "Batch # 21 loss=0.3868                                        \n",
      "Batch # 22 loss=0.3960                                        \n",
      "Batch # 23 loss=0.4103                                        \n",
      "Batch # 24 loss=0.4071                                        \n",
      "Batch # 25 loss=0.3993                                        \n",
      "Batch # 26 loss=0.3929                                        \n",
      "Batch # 27 loss=0.4005                                        \n",
      "========== EPOCH #12 ========== (0.3923/0.4017)       \n",
      "Batch # 1 loss=0.4093                                        \n",
      "Batch # 2 loss=0.4470                                        \n",
      "Batch # 3 loss=0.3761                                        \n",
      "Batch # 4 loss=0.4521                                        \n",
      "Batch # 5 loss=0.4614                                        \n",
      "Batch # 6 loss=0.4508                                        \n",
      "Batch # 7 loss=0.4057                                        \n",
      "Batch # 8 loss=0.4676                                        \n",
      "Batch # 9 loss=0.4213                                        \n",
      "Batch # 10 loss=0.4055                                        \n",
      "Batch # 11 loss=0.4474                                        \n",
      "Batch # 12 loss=0.4179                                        \n",
      "Batch # 13 loss=0.4401                                        \n",
      "Batch # 14 loss=0.4232                                        \n",
      "Batch # 15 loss=0.3976                                        \n",
      "Batch # 16 loss=0.4037                                        \n",
      "Batch # 17 loss=0.4016                                        \n",
      "Batch # 18 loss=0.4278                                        \n",
      "Batch # 19 loss=0.4044                                        \n",
      "Batch # 20 loss=0.3940                                        \n",
      "Batch # 21 loss=0.4250                                        \n",
      "Batch # 22 loss=0.3996                                        \n",
      "Batch # 23 loss=0.4381                                        \n",
      "Batch # 24 loss=0.3916                                        \n",
      "Batch # 25 loss=0.4179                                        \n",
      "Batch # 26 loss=0.3874                                        \n",
      "Batch # 27 loss=0.4210                                        \n",
      "========== EPOCH #13 ========== (0.4198/0.3994)       \n",
      "Batch # 1 loss=0.4084                                        \n",
      "Batch # 2 loss=0.3984                                        \n",
      "Batch # 3 loss=0.3915                                        \n",
      "Batch # 4 loss=0.3818                                        \n",
      "Batch # 5 loss=0.3994                                        \n",
      "Batch # 6 loss=0.3879                                        \n",
      "Batch # 7 loss=0.4023                                        \n",
      "Batch # 8 loss=0.3810                                        \n",
      "Batch # 9 loss=0.4020                                        \n",
      "Batch # 10 loss=0.3814                                        \n",
      "Batch # 11 loss=0.3885                                        \n",
      "Batch # 12 loss=0.4035                                        \n",
      "Batch # 13 loss=0.3848                                        \n",
      "Batch # 14 loss=0.3912                                        \n",
      "Batch # 15 loss=0.3851                                        \n",
      "Batch # 16 loss=0.3742                                        \n",
      "Batch # 17 loss=0.3907                                        \n",
      "Batch # 18 loss=0.3962                                        \n",
      "Batch # 19 loss=0.3763                                        \n",
      "Batch # 20 loss=0.3714                                        \n",
      "Batch # 21 loss=0.3865                                        \n",
      "Batch # 22 loss=0.3942                                        \n",
      "Batch # 23 loss=0.4037                                        \n",
      "Batch # 24 loss=0.3840                                        \n",
      "Batch # 25 loss=0.3852                                        \n",
      "Batch # 26 loss=0.3789                                        \n",
      "Batch # 27 loss=0.4001                                        \n",
      "========== EPOCH #14 ========== (0.3899/0.3843)       \n",
      "Batch # 1 loss=0.3936                                        \n",
      "Batch # 2 loss=0.3880                                        \n",
      "Batch # 3 loss=0.3759                                        \n",
      "Batch # 4 loss=0.3760                                        \n",
      "Batch # 5 loss=0.3825                                        \n",
      "Batch # 6 loss=0.3797                                        \n",
      "Batch # 7 loss=0.3865                                        \n",
      "Batch # 8 loss=0.3821                                        \n",
      "Batch # 9 loss=0.4458                                        \n",
      "Batch # 10 loss=0.4072                                        \n",
      "Batch # 11 loss=0.4352                                        \n",
      "Batch # 12 loss=0.3941                                        \n",
      "Batch # 13 loss=0.4951                                        \n",
      "Batch # 14 loss=0.4684                                        \n",
      "Batch # 15 loss=0.4564                                        \n",
      "Batch # 16 loss=0.3843                                        \n",
      "Batch # 17 loss=0.4709                                        \n",
      "Batch # 18 loss=0.4414                                        \n",
      "Batch # 19 loss=0.3966                                        \n",
      "Batch # 20 loss=0.4355                                        \n",
      "Batch # 21 loss=0.4244                                        \n",
      "Batch # 22 loss=0.4169                                        \n",
      "Batch # 23 loss=0.4575                                        \n",
      "Batch # 24 loss=0.4085                                        \n",
      "Batch # 25 loss=0.4086                                        \n",
      "Batch # 26 loss=0.4151                                        \n",
      "Batch # 27 loss=0.4120                                        \n",
      "========== EPOCH #15 ========== (0.4162/0.4251)       \n",
      "Batch # 1 loss=0.4311                                        \n",
      "Batch # 2 loss=0.4023                                        \n",
      "Batch # 3 loss=0.3973                                        \n",
      "Batch # 4 loss=0.4054                                        \n",
      "Batch # 5 loss=0.3886                                        \n",
      "Batch # 6 loss=0.4156                                        \n",
      "Batch # 7 loss=0.3909                                        \n",
      "Batch # 8 loss=0.3921                                        \n",
      "Batch # 9 loss=0.4121                                        \n",
      "Batch # 10 loss=0.3912                                        \n",
      "Batch # 11 loss=0.3922                                        \n",
      "Batch # 12 loss=0.4048                                        \n",
      "Batch # 13 loss=0.3863                                        \n",
      "Batch # 14 loss=0.3893                                        \n",
      "Batch # 15 loss=0.3905                                        \n",
      "Batch # 16 loss=0.3727                                        \n",
      "Batch # 17 loss=0.4019                                        \n",
      "Batch # 18 loss=0.3962                                        \n",
      "Batch # 19 loss=0.3943                                        \n",
      "Batch # 20 loss=0.3716                                        \n",
      "Batch # 21 loss=0.4049                                        \n",
      "Batch # 22 loss=0.3953                                        \n",
      "Batch # 23 loss=0.4192                                        \n",
      "Batch # 24 loss=0.3845                                        \n",
      "Batch # 25 loss=0.4009                                        \n",
      "Batch # 26 loss=0.3817                                        \n",
      "Batch # 27 loss=0.4067                                        \n",
      "========== EPOCH #16 ========== (0.3970/0.3914)       \n",
      "Batch # 1 loss=0.4002                                        \n",
      "Batch # 2 loss=0.3918                                        \n",
      "Batch # 3 loss=0.3817                                        \n",
      "Batch # 4 loss=0.3787                                        \n",
      "Batch # 5 loss=0.3886                                        \n",
      "Batch # 6 loss=0.3850                                        \n",
      "Batch # 7 loss=0.3918                                        \n",
      "Batch # 8 loss=0.3809                                        \n",
      "Batch # 9 loss=0.3956                                        \n",
      "Batch # 10 loss=0.3717                                        \n",
      "Batch # 11 loss=0.3808                                        \n",
      "Batch # 12 loss=0.3918                                        \n",
      "Batch # 13 loss=0.3772                                        \n",
      "Batch # 14 loss=0.3895                                        \n",
      "Batch # 15 loss=0.3776                                        \n",
      "Batch # 16 loss=0.3739                                        \n",
      "Batch # 17 loss=0.3929                                        \n",
      "Batch # 18 loss=0.3922                                        \n",
      "Batch # 19 loss=0.3874                                        \n",
      "Batch # 20 loss=0.3849                                        \n",
      "Batch # 21 loss=0.3911                                        \n",
      "Batch # 22 loss=0.4346                                        \n",
      "Batch # 23 loss=0.4319                                        \n",
      "Batch # 24 loss=0.3919                                        \n",
      "Batch # 25 loss=0.4172                                        \n",
      "Batch # 26 loss=0.3792                                        \n",
      "Batch # 27 loss=0.4262                                        \n",
      "========== EPOCH #17 ========== (0.3921/0.3862)       \n",
      "Batch # 1 loss=0.3982                                        \n",
      "Batch # 2 loss=0.4035                                        \n",
      "Batch # 3 loss=0.3845                                        \n",
      "Batch # 4 loss=0.3861                                        \n",
      "Batch # 5 loss=0.4034                                        \n",
      "Batch # 6 loss=0.3883                                        \n",
      "Batch # 7 loss=0.4044                                        \n",
      "Batch # 8 loss=0.3859                                        \n",
      "Batch # 9 loss=0.4107                                        \n",
      "Batch # 10 loss=0.3810                                        \n",
      "Batch # 11 loss=0.3837                                        \n",
      "Batch # 12 loss=0.3998                                        \n",
      "Batch # 13 loss=0.3810                                        \n",
      "Batch # 14 loss=0.3942                                        \n",
      "Batch # 15 loss=0.3822                                        \n",
      "Batch # 16 loss=0.3769                                        \n",
      "Batch # 17 loss=0.3876                                        \n",
      "Batch # 18 loss=0.3968                                        \n",
      "Batch # 19 loss=0.3741                                        \n",
      "Batch # 20 loss=0.3701                                        \n",
      "Batch # 21 loss=0.3892                                        \n",
      "Batch # 22 loss=0.3914                                        \n",
      "Batch # 23 loss=0.4049                                        \n",
      "Batch # 24 loss=0.3840                                        \n",
      "Batch # 25 loss=0.3848                                        \n",
      "Batch # 26 loss=0.3850                                        \n",
      "Batch # 27 loss=0.4134                                        \n",
      "========== EPOCH #18 ========== (0.3906/0.3796)       \n",
      "Batch # 1 loss=0.3910                                        \n",
      "Batch # 2 loss=0.4072                                        \n",
      "Batch # 3 loss=0.4101                                        \n",
      "Batch # 4 loss=0.3818                                        \n",
      "Batch # 5 loss=0.4422                                        \n",
      "Batch # 6 loss=0.4077                                        \n",
      "Batch # 7 loss=0.4186                                        \n",
      "Batch # 8 loss=0.3927                                        \n",
      "Batch # 9 loss=0.4112                                        \n",
      "Batch # 10 loss=0.3756                                        \n",
      "Batch # 11 loss=0.4031                                        \n",
      "Batch # 12 loss=0.4028                                        \n",
      "Batch # 13 loss=0.3970                                        \n",
      "Batch # 14 loss=0.4035                                        \n",
      "Batch # 15 loss=0.3864                                        \n",
      "Batch # 16 loss=0.3860                                        \n",
      "Batch # 17 loss=0.3980                                        \n",
      "Batch # 18 loss=0.4015                                        \n",
      "Batch # 19 loss=0.3960                                        \n",
      "Batch # 20 loss=0.3731                                        \n",
      "Batch # 21 loss=0.4062                                        \n",
      "Batch # 22 loss=0.3987                                        \n",
      "Batch # 23 loss=0.4150                                        \n",
      "Batch # 24 loss=0.3922                                        \n",
      "Batch # 25 loss=0.3966                                        \n",
      "Batch # 26 loss=0.3899                                        \n",
      "Batch # 27 loss=0.4007                                        \n",
      "========== EPOCH #19 ========== (0.3994/0.4057)       \n",
      "Batch # 1 loss=0.4135                                        \n",
      "Batch # 2 loss=0.3867                                        \n",
      "Batch # 3 loss=0.3897                                        \n",
      "Batch # 4 loss=0.3760                                        \n",
      "Batch # 5 loss=0.3970                                        \n",
      "Batch # 6 loss=0.3817                                        \n",
      "Batch # 7 loss=0.3982                                        \n",
      "Batch # 8 loss=0.3742                                        \n",
      "Batch # 9 loss=0.3983                                        \n",
      "Batch # 10 loss=0.3715                                        \n",
      "Batch # 11 loss=0.3867                                        \n",
      "Batch # 12 loss=0.3924                                        \n",
      "Batch # 13 loss=0.3888                                        \n",
      "Batch # 14 loss=0.3869                                        \n",
      "Batch # 15 loss=0.3839                                        \n",
      "Batch # 16 loss=0.3709                                        \n",
      "Batch # 17 loss=0.3863                                        \n",
      "Batch # 18 loss=0.3940                                        \n",
      "Batch # 19 loss=0.3725                                        \n",
      "Batch # 20 loss=0.3683                                        \n",
      "Batch # 21 loss=0.3859                                        \n",
      "Batch # 22 loss=0.3912                                        \n",
      "Batch # 23 loss=0.4007                                        \n",
      "Batch # 24 loss=0.3803                                        \n",
      "Batch # 25 loss=0.3845                                        \n",
      "Batch # 26 loss=0.3789                                        \n",
      "Batch # 27 loss=0.4012                                        \n",
      "========== EPOCH #20 ========== (0.3867/0.3791)       \n",
      "Batch # 1 loss=0.3898                                        \n",
      "Batch # 2 loss=0.3843                                        \n",
      "Batch # 3 loss=0.3739                                        \n",
      "Batch # 4 loss=0.3746                                        \n",
      "Batch # 5 loss=0.3846                                        \n",
      "Batch # 6 loss=0.3817                                        \n",
      "Batch # 7 loss=0.3850                                        \n",
      "Batch # 8 loss=0.3779                                        \n",
      "Batch # 9 loss=0.4125                                        \n",
      "Batch # 10 loss=0.3768                                        \n",
      "Batch # 11 loss=0.3800                                        \n",
      "Batch # 12 loss=0.3938                                        \n",
      "Batch # 13 loss=0.3851                                        \n",
      "Batch # 14 loss=0.3936                                        \n",
      "Batch # 15 loss=0.3772                                        \n",
      "Batch # 16 loss=0.3817                                        \n",
      "Batch # 17 loss=0.3991                                        \n",
      "Batch # 18 loss=0.3961                                        \n",
      "Batch # 19 loss=0.4009                                        \n",
      "Batch # 20 loss=0.3747                                        \n",
      "Batch # 21 loss=0.4066                                        \n",
      "Batch # 22 loss=0.3954                                        \n",
      "Batch # 23 loss=0.4169                                        \n",
      "Batch # 24 loss=0.3874                                        \n",
      "Batch # 25 loss=0.4013                                        \n",
      "Batch # 26 loss=0.3810                                        \n",
      "Batch # 27 loss=0.4084                                        \n",
      "========== EPOCH #21 ========== (0.3896/0.3880)       \n",
      "Batch # 1 loss=0.3970                                        \n",
      "Batch # 2 loss=0.3894                                        \n",
      "Batch # 3 loss=0.3817                                        \n",
      "Batch # 4 loss=0.3775                                        \n",
      "Batch # 5 loss=0.3903                                        \n",
      "Batch # 6 loss=0.3824                                        \n",
      "Batch # 7 loss=0.3933                                        \n",
      "Batch # 8 loss=0.3755                                        \n",
      "Batch # 9 loss=0.3955                                        \n",
      "Batch # 10 loss=0.3714                                        \n",
      "Batch # 11 loss=0.3833                                        \n",
      "Batch # 12 loss=0.3911                                        \n",
      "Batch # 13 loss=0.3850                                        \n",
      "Batch # 14 loss=0.3900                                        \n",
      "Batch # 15 loss=0.3789                                        \n",
      "Batch # 16 loss=0.3795                                        \n",
      "Batch # 17 loss=0.3935                                        \n",
      "Batch # 18 loss=0.3928                                        \n",
      "Batch # 19 loss=0.3949                                        \n",
      "Batch # 20 loss=0.3881                                        \n",
      "Batch # 21 loss=0.3971                                        \n",
      "Batch # 22 loss=0.4319                                        \n",
      "Batch # 23 loss=0.4077                                        \n",
      "Batch # 24 loss=0.3921                                        \n",
      "Batch # 25 loss=0.3894                                        \n",
      "Batch # 26 loss=0.3872                                        \n",
      "Batch # 27 loss=0.4077                                        \n",
      "========== EPOCH #22 ========== (0.3905/0.3892)       \n",
      "Batch # 1 loss=0.4023                                        \n",
      "Batch # 2 loss=0.3877                                        \n",
      "Batch # 3 loss=0.3860                                        \n",
      "Batch # 4 loss=0.3781                                        \n",
      "Batch # 5 loss=0.3961                                        \n",
      "Batch # 6 loss=0.3847                                        \n",
      "Batch # 7 loss=0.3957                                        \n",
      "Batch # 8 loss=0.3813                                        \n",
      "Batch # 9 loss=0.4059                                        \n",
      "Batch # 10 loss=0.3738                                        \n",
      "Batch # 11 loss=0.3826                                        \n",
      "Batch # 12 loss=0.3935                                        \n",
      "Batch # 13 loss=0.3756                                        \n",
      "Batch # 14 loss=0.3900                                        \n",
      "Batch # 15 loss=0.3783                                        \n",
      "Batch # 16 loss=0.3732                                        \n",
      "Batch # 17 loss=0.3906                                        \n",
      "Batch # 18 loss=0.3934                                        \n",
      "Batch # 19 loss=0.3860                                        \n",
      "Batch # 20 loss=0.3709                                        \n",
      "Batch # 21 loss=0.3943                                        \n",
      "Batch # 22 loss=0.4033                                        \n",
      "Batch # 23 loss=0.3995                                        \n",
      "Batch # 24 loss=0.3837                                        \n",
      "Batch # 25 loss=0.3857                                        \n",
      "Batch # 26 loss=0.3777                                        \n",
      "Batch # 27 loss=0.4065                                        \n",
      "========== EPOCH #23 ========== (0.3880/0.3793)       \n",
      "Batch # 1 loss=0.3901                                        \n",
      "Batch # 2 loss=0.3904                                        \n",
      "Batch # 3 loss=0.3759                                        \n",
      "Batch # 4 loss=0.3798                                        \n",
      "Batch # 5 loss=0.3889                                        \n",
      "Batch # 6 loss=0.3793                                        \n",
      "Batch # 7 loss=0.3918                                        \n",
      "Batch # 8 loss=0.3770                                        \n",
      "Batch # 9 loss=0.3958                                        \n",
      "Batch # 10 loss=0.3701                                        \n",
      "Batch # 11 loss=0.3799                                        \n",
      "Batch # 12 loss=0.3906                                        \n",
      "Batch # 13 loss=0.3797                                        \n",
      "Batch # 14 loss=0.3881                                        \n",
      "Batch # 15 loss=0.3766                                        \n",
      "Batch # 16 loss=0.3752                                        \n",
      "Batch # 17 loss=0.3918                                        \n",
      "Batch # 18 loss=0.3911                                        \n",
      "Batch # 19 loss=0.3858                                        \n",
      "Batch # 20 loss=0.3773                                        \n",
      "Batch # 21 loss=0.3942                                        \n",
      "Batch # 22 loss=0.4106                                        \n",
      "Batch # 23 loss=0.4017                                        \n",
      "Batch # 24 loss=0.3863                                        \n",
      "Batch # 25 loss=0.3869                                        \n",
      "Batch # 26 loss=0.3789                                        \n",
      "Batch # 27 loss=0.4062                                        \n",
      "========== EPOCH #24 ========== (0.3867/0.3816)       \n",
      "Batch # 1 loss=0.3927                                        \n",
      "Batch # 2 loss=0.3917                                        \n",
      "Batch # 3 loss=0.3731                                        \n",
      "Batch # 4 loss=0.3814                                        \n",
      "Batch # 5 loss=0.3827                                        \n",
      "Batch # 6 loss=0.3884                                        \n",
      "Batch # 7 loss=0.3869                                        \n",
      "Batch # 8 loss=0.3746                                        \n",
      "Batch # 9 loss=0.3944                                        \n",
      "Batch # 10 loss=0.3792                                        \n",
      "Batch # 11 loss=0.3828                                        \n",
      "Batch # 12 loss=0.3967                                        \n",
      "Batch # 13 loss=0.3884                                        \n",
      "Batch # 14 loss=0.3849                                        \n",
      "Batch # 15 loss=0.3824                                        \n",
      "Batch # 16 loss=0.3706                                        \n",
      "Batch # 17 loss=0.3845                                        \n",
      "Batch # 18 loss=0.3927                                        \n",
      "Batch # 19 loss=0.3726                                        \n",
      "Batch # 20 loss=0.3674                                        \n",
      "Batch # 21 loss=0.3865                                        \n",
      "Batch # 22 loss=0.3908                                        \n",
      "Batch # 23 loss=0.3994                                        \n",
      "Batch # 24 loss=0.3805                                        \n",
      "Batch # 25 loss=0.3833                                        \n",
      "Batch # 26 loss=0.3785                                        \n",
      "Batch # 27 loss=0.4038                                        \n",
      "========== EPOCH #25 ========== (0.3849/0.3786)       \n",
      "Batch # 1 loss=0.3894                                        \n",
      "Batch # 2 loss=0.3867                                        \n",
      "Batch # 3 loss=0.3774                                        \n",
      "Batch # 4 loss=0.3753                                        \n",
      "Batch # 5 loss=0.3899                                        \n",
      "Batch # 6 loss=0.3883                                        \n",
      "Batch # 7 loss=0.3863                                        \n",
      "Batch # 8 loss=0.3921                                        \n",
      "Batch # 9 loss=0.4250                                        \n",
      "Batch # 10 loss=0.3698                                        \n",
      "Batch # 11 loss=0.4020                                        \n",
      "Batch # 12 loss=0.3998                                        \n",
      "Batch # 13 loss=0.3812                                        \n",
      "Batch # 14 loss=0.3885                                        \n",
      "Batch # 15 loss=0.3842                                        \n",
      "Batch # 16 loss=0.3730                                        \n",
      "Batch # 17 loss=0.3972                                        \n",
      "Batch # 18 loss=0.3937                                        \n",
      "Batch # 19 loss=0.3892                                        \n",
      "Batch # 20 loss=0.3707                                        \n",
      "Batch # 21 loss=0.4030                                        \n",
      "Batch # 22 loss=0.3931                                        \n",
      "Batch # 23 loss=0.4165                                        \n",
      "Batch # 24 loss=0.3834                                        \n",
      "Batch # 25 loss=0.3985                                        \n",
      "Batch # 26 loss=0.3805                                        \n",
      "Batch # 27 loss=0.4041                                        \n",
      "========== EPOCH #26 ========== (0.3903/0.3918)       \n",
      "Batch # 1 loss=0.4001                                        \n",
      "Batch # 2 loss=0.3889                                        \n",
      "Batch # 3 loss=0.3808                                        \n",
      "Batch # 4 loss=0.3775                                        \n",
      "Batch # 5 loss=0.3894                                        \n",
      "Batch # 6 loss=0.3828                                        \n",
      "Batch # 7 loss=0.3920                                        \n",
      "Batch # 8 loss=0.3823                                        \n",
      "Batch # 9 loss=0.3947                                        \n",
      "Batch # 10 loss=0.3697                                        \n",
      "Batch # 11 loss=0.3792                                        \n",
      "Batch # 12 loss=0.3903                                        \n",
      "Batch # 13 loss=0.3748                                        \n",
      "Batch # 14 loss=0.3873                                        \n",
      "Batch # 15 loss=0.3768                                        \n",
      "Batch # 16 loss=0.3705                                        \n",
      "Batch # 17 loss=0.3918                                        \n",
      "Batch # 18 loss=0.3914                                        \n",
      "Batch # 19 loss=0.3778                                        \n",
      "Batch # 20 loss=0.3796                                        \n",
      "Batch # 21 loss=0.3850                                        \n",
      "Batch # 22 loss=0.4184                                        \n",
      "Batch # 23 loss=0.4308                                        \n",
      "Batch # 24 loss=0.3821                                        \n",
      "Batch # 25 loss=0.4187                                        \n",
      "Batch # 26 loss=0.3840                                        \n",
      "Batch # 27 loss=0.4255                                        \n",
      "========== EPOCH #27 ========== (0.3897/0.3811)       \n",
      "Batch # 1 loss=0.3914                                        \n",
      "Batch # 2 loss=0.4084                                        \n",
      "Batch # 3 loss=0.3750                                        \n",
      "Batch # 4 loss=0.3940                                        \n",
      "Batch # 5 loss=0.3942                                        \n",
      "Batch # 6 loss=0.3921                                        \n",
      "Batch # 7 loss=0.4028                                        \n",
      "Batch # 8 loss=0.3781                                        \n",
      "Batch # 9 loss=0.4171                                        \n",
      "Batch # 10 loss=0.3736                                        \n",
      "Batch # 11 loss=0.3892                                        \n",
      "Batch # 12 loss=0.3938                                        \n",
      "Batch # 13 loss=0.3789                                        \n",
      "Batch # 14 loss=0.3908                                        \n",
      "Batch # 15 loss=0.3802                                        \n",
      "Batch # 16 loss=0.3744                                        \n",
      "Batch # 17 loss=0.3932                                        \n",
      "Batch # 18 loss=0.3938                                        \n",
      "Batch # 19 loss=0.3892                                        \n",
      "Batch # 20 loss=0.3690                                        \n",
      "Batch # 21 loss=0.3990                                        \n",
      "Batch # 22 loss=0.3963                                        \n",
      "Batch # 23 loss=0.4025                                        \n",
      "Batch # 24 loss=0.3884                                        \n",
      "Batch # 25 loss=0.3841                                        \n",
      "Batch # 26 loss=0.3886                                        \n",
      "Batch # 27 loss=0.4050                                        \n",
      "========== EPOCH #28 ========== (0.3905/0.3830)       \n",
      "Batch # 1 loss=0.3954                                        \n",
      "Batch # 2 loss=0.3933                                        \n",
      "Batch # 3 loss=0.3719                                        \n",
      "Batch # 4 loss=0.3831                                        \n",
      "Batch # 5 loss=0.3819                                        \n",
      "Batch # 6 loss=0.3896                                        \n",
      "Batch # 7 loss=0.3867                                        \n",
      "Batch # 8 loss=0.3759                                        \n",
      "Batch # 9 loss=0.3943                                        \n",
      "Batch # 10 loss=0.3803                                        \n",
      "Batch # 11 loss=0.3818                                        \n",
      "Batch # 12 loss=0.3991                                        \n",
      "Batch # 13 loss=0.3815                                        \n",
      "Batch # 14 loss=0.3862                                        \n",
      "Batch # 15 loss=0.3817                                        \n",
      "Batch # 16 loss=0.3689                                        \n",
      "Batch # 17 loss=0.3860                                        \n",
      "Batch # 18 loss=0.3915                                        \n",
      "Batch # 19 loss=0.3718                                        \n",
      "Batch # 20 loss=0.3669                                        \n",
      "Batch # 21 loss=0.3829                                        \n",
      "Batch # 22 loss=0.3902                                        \n",
      "Batch # 23 loss=0.3986                                        \n",
      "Batch # 24 loss=0.3792                                        \n",
      "Batch # 25 loss=0.3835                                        \n",
      "Batch # 26 loss=0.3760                                        \n",
      "Batch # 27 loss=0.3985                                        \n",
      "========== EPOCH #29 ========== (0.3843/0.3807)       \n",
      "Batch # 1 loss=0.3906                                        \n",
      "Batch # 2 loss=0.3821                                        \n",
      "Batch # 3 loss=0.3702                                        \n",
      "Batch # 4 loss=0.3740                                        \n",
      "Batch # 5 loss=0.3806                                        \n",
      "Batch # 6 loss=0.3783                                        \n",
      "Batch # 7 loss=0.3846                                        \n",
      "Batch # 8 loss=0.3721                                        \n",
      "Batch # 9 loss=0.3959                                        \n",
      "Batch # 10 loss=0.3809                                        \n",
      "Batch # 11 loss=0.3980                                        \n",
      "Batch # 12 loss=0.3889                                        \n",
      "Batch # 13 loss=0.4063                                        \n",
      "Batch # 14 loss=0.4423                                        \n",
      "Batch # 15 loss=0.3891                                        \n",
      "Batch # 16 loss=0.4337                                        \n",
      "Batch # 17 loss=0.3877                                        \n",
      "Batch # 18 loss=0.4246                                        \n",
      "Batch # 19 loss=0.3804                                        \n",
      "Batch # 20 loss=0.3950                                        \n",
      "Batch # 21 loss=0.3983                                        \n",
      "Batch # 22 loss=0.4063                                        \n",
      "Batch # 23 loss=0.4202                                        \n",
      "Batch # 24 loss=0.3906                                        \n",
      "Batch # 25 loss=0.4022                                        \n",
      "Batch # 26 loss=0.3834                                        \n",
      "Batch # 27 loss=0.4158                                        \n",
      "========== EPOCH #30 ========== (0.3953/0.3885)       \n"
     ]
    }
   ],
   "source": [
    "# restart = True\n",
    "# num_test = 0\n",
    "# while restart:\n",
    "#     num_test += 1\n",
    "#     print(\"=/\"*10 + \"NUMTEST \" + str(num_test) + \" \" + \"=/\"*30)\n",
    "models = get_models(params)\n",
    "restart = train_model(params, models, dataset, f\"{num_test}_deep_torch_11000\", save_frequency=5, restart=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2674a-fb87-4c50-a726-32d39a29bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weigths(models, path_node_gnn, path_edge_linear):\n",
    "    models[0].load_state_dict(torch.load(path_node_gnn, weights_only=True))\n",
    "    models[1].load_state_dict(torch.load(path_edge_linear, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca54f343-cb1a-4731-9c2c-c0d71d48c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_load = get_models(params)\n",
    "load_weigths(models_load, \"deep_torch_11000_node_gnn_end\", \"deep_torch_11000_edge_linear_end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d097ece-7450-4682-b01d-f178dc020a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_classification_edges(models, graph, k=0.51):\n",
    "    i = graph[\"A\"]\n",
    "    v_in = [rev_dist(e) for e in graph[\"edges_feature\"]]\n",
    "    x = graph[\"nodes_feature\"]\n",
    "    N = len(x)\n",
    "    X = torch.tensor(data=x, dtype=torch.float32)\n",
    "    sp_A = torch.sparse_coo_tensor(indices=i, values=v_in, size=(N, N), dtype=torch.float32)\n",
    "    \n",
    "    H_end = models[0](X, sp_A)\n",
    "    Omega = torch.cat([H_end[i[0]], H_end[i[1]]],dim=1)\n",
    "    E_pred = models[1](Omega)\n",
    "    a = np.zeros(E_pred.shape)\n",
    "    return E_pred\n",
    "    a[E_pred>k] = 1.0\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecfdfcd6-00c4-4813-bb17-29d5a86bd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch_classification_edges(models, dataset[2], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bac399b2-9eee-4986-992a-6fc2b542b441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mask == np.array(dataset[2]['true_edges']))/ len(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ca165-54bb-435f-87e6-436d5935df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.90 -  1500 \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7192cb90-9f67-4d5f-816a-32883794b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in dataset[2]['true_edges']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f7eb3-f353-43c8-9ccc-b75d80e6551c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
