{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58491147-580d-409e-aedf-2d49997dfea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric\n",
      "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting aiohttp (from torch-geometric)\n",
      "  Using cached aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: fsspec in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (2024.12.0)\n",
      "Requirement already satisfied: jinja2 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (6.0.0)\n",
      "Requirement already satisfied: pyparsing in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: requests in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (2.32.3)\n",
      "Collecting tqdm (from torch-geometric)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch-geometric)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch-geometric)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from aiohttp->torch-geometric) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch-geometric)\n",
      "  Using cached propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch-geometric)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from jinja2->torch-geometric) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (2024.8.30)\n",
      "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Using cached aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Using cached propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "Installing collected packages: tqdm, propcache, multidict, frozenlist, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch-geometric\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 frozenlist-1.5.0 multidict-6.1.0 propcache-0.2.1 torch-geometric-2.6.1 tqdm-4.67.1 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "04f8ed93-0f7e-4ded-8b2a-73e2374eb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import relu, sigmoid, binary_cross_entropy\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b56272de-cf3d-409c-87a2-ee7fcb82fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self,  layers):\n",
    "        super(GNN, self).__init__()\n",
    "        convs = []\n",
    "        Bs = []\n",
    "        for l_in, l_out in zip(layers[:-1], layers[1:]):\n",
    "            convs.append(GCNConv(l_in, l_out, bias=False))\n",
    "            torch.nn.init.normal_(convs[-1].lin.weight,mean=0.01, std=0.3)\n",
    "            Bs.append(torch.nn.Linear(l_in, l_out, bias=False))\n",
    "            torch.nn.init.normal_(Bs[-1].weight, mean=0.5, std=0.3)\n",
    "        self.convs = torch.nn.ModuleList(convs)\n",
    "        self.Bs = torch.nn.ModuleList(Bs)\n",
    "\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        for conv, B in zip(self.convs, self.Bs):\n",
    "            x = conv(x, edge_index) -  B(x)\n",
    "            x = relu(x)\n",
    "        return x\n",
    "\n",
    "class EdgesMLP(torch.nn.Module):\n",
    "    def __init__(self, l3):\n",
    "        super(EdgesMLP, self).__init__()\n",
    "        self.linear = Linear(2*l3, 1, bias=False)\n",
    "        torch.nn.init.normal_(self.linear.weight, mean=0.5, std=0.3)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear(x)\n",
    "        return torch.squeeze(sigmoid(x), 1)\n",
    "\n",
    "def get_models(params):\n",
    "    layers = params[\"count_neuron_layers\"]\n",
    "    node_gnn = GNN(layers)\n",
    "    edge_linear = EdgesMLP(layers[-1])\n",
    "    return node_gnn, edge_linear\n",
    "\n",
    "def list_batchs(dataset, batch_size):\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        yield dataset[i:i+batch_size]\n",
    "\n",
    "def get_tensor_from_graph(graph):\n",
    "    i = graph[\"A\"]\n",
    "    v_in = [rev_dist(e) for e in graph[\"edges_feature\"]]\n",
    "    v_true = graph[\"true_edges\"]\n",
    "    x = graph[\"nodes_feature\"]\n",
    "    N = len(x)\n",
    "    \n",
    "    X = torch.tensor(data=x, dtype=torch.float32)\n",
    "    sp_A = torch.sparse_coo_tensor(indices=i, values=v_in, size=(N, N), dtype=torch.float32)\n",
    "    E_true = torch.tensor(data=v_true, dtype=torch.float32)\n",
    "    return X, sp_A, E_true, i\n",
    "\n",
    "def validation(models, dataset, criterion):\n",
    "    my_loss_list = []\n",
    "    for j, graph in enumerate(dataset):\n",
    "        X, sp_A, E_true, i = get_tensor_from_graph(graph)\n",
    "        H_end = models[0](X, sp_A)\n",
    "        Omega = torch.cat([H_end[i[0]], H_end[i[1]]],dim=1)\n",
    "        E_pred = models[1](Omega)\n",
    "        loss = criterion(E_pred, E_true)\n",
    "        my_loss_list.append(loss.item())\n",
    "        print(f\"{(j+1)/len(dataset)*100:.2f} % loss = {my_loss_list[-1]:.5f} {' '*30}\", end='\\r')\n",
    "    return np.mean(my_loss_list)\n",
    "\n",
    "def split_train_val(dataset, val_split=0.2, shuffle=True, seed=1234):\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        rng.shuffle(dataset)\n",
    "    train_size = int(len(dataset) * (1 - val_split))\n",
    "    train_dataset = dataset[:train_size]\n",
    "    val_dataset = dataset[train_size:]\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def train_step(models, batch, optimizer, criterion):\n",
    "    optimizer.zero_grad()\n",
    "    my_loss_list = []\n",
    "   \n",
    "    for j, graph in enumerate(batch):\n",
    "        X, sp_A, E_true, i = get_tensor_from_graph(graph)\n",
    "        H_end = models[0](X, sp_A)\n",
    "        Omega = torch.cat([H_end[i[0]], H_end[i[1]]],dim=1)\n",
    "        E_pred = models[1](Omega)\n",
    "        loss = criterion(E_pred, E_true)\n",
    "        my_loss_list.append(loss.item())\n",
    "        print(f\"Batch loss={my_loss_list[-1]:.4f}\" + \" \"*40, end=\"\\r\")\n",
    "        loss.backward()\n",
    "    optimizer.step()\n",
    "    return np.mean(my_loss_list)\n",
    "\n",
    "def train_model(params, models, dataset, path_save, save_frequency=5):  \n",
    "    optimizer = torch.optim.Adam(\n",
    "    list(models[0].parameters()) + list(models[1].parameters()),\n",
    "    lr=learning_rate,\n",
    "    )\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    loss_list = []\n",
    "    train_dataset, val_dataset = split_train_val(dataset, val_split=0.1)\n",
    "    for k in range(params[\"epochs\"]):\n",
    "        my_loss_list = []\n",
    "        \n",
    "        for l, batch in enumerate(list_batchs(train_dataset, params[\"batch_size\"])):\n",
    "            batch_loss = train_step(models, batch, optimizer, criterion)\n",
    "            my_loss_list.append(batch_loss)\n",
    "            print(f\"Batch # {l+1} loss={my_loss_list[-1]:.4f}\" + \" \"*40)\n",
    "        train_val = np.mean(my_loss_list)\n",
    "        validation_val = validation(models, val_dataset, criterion)\n",
    "        print(\"=\"*10, f\"EPOCH #{k+1}\",\"=\"*10, f\"({train_val:.4f}/{validation_val:.4f})\")\n",
    "        with open('log.txt', 'a') as f:\n",
    "            f.write(f\"EPOCH #{k}\\t {train_val:.8f} (VAL: {validation_val:.8f})\\n\")  \n",
    "        if (k+1) % save_frequency == 0:\n",
    "            num = k//save_frequency\n",
    "            torch.save(models[0].state_dict(), path_save+f\"_node_gnn_{num}\")\n",
    "            torch.save(models[1].state_dict(), path_save+f\"_edge_linear_{num}\")\n",
    "    torch.save(models[0].state_dict(), path_save+f\"_node_gnn_end\")\n",
    "    torch.save(models[1].state_dict(), path_save+f\"_edge_linear_end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2d873f8d-d98c-4325-9aac-3cc68cb7b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET INFO:\n",
      "count row: 1557\n",
      "first: dict_keys(['A', 'nodes_feature', 'edges_feature', 'true_edges'])\n",
      "\t A: (2, 779)\n",
      "\t nodes_feature: (385, 9)\n",
      "\t edges_feature: (779,)\n",
      "\t true_edges: (779,)\n",
      "end: dict_keys(['A', 'nodes_feature', 'edges_feature', 'true_edges'])\n",
      "\t A: (2, 2142)\n",
      "\t nodes_feature: (1039, 9)\n",
      "\t edges_feature: (2142,)\n",
      "\t true_edges: (2142,)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)['dataset']\n",
    "# with open(\"../delaunay_seg.json\", \"r\") as f:\n",
    "#     dataset = json.load(f)['dataset']\n",
    "\n",
    "print(\"DATASET INFO:\")\n",
    "print(\"count row:\", len(dataset))\n",
    "print(\"first:\", dataset[0].keys())\n",
    "print(f\"\\t A:\", np.shape(dataset[0][\"A\"]))\n",
    "print(f\"\\t nodes_feature:\", np.shape(dataset[0][\"nodes_feature\"]))\n",
    "print(f\"\\t edges_feature:\", np.shape(dataset[0][\"edges_feature\"]))\n",
    "print(f\"\\t true_edges:\", np.shape(dataset[0][\"true_edges\"]))\n",
    "print(\"end:\", dataset[-1].keys())\n",
    "print(f\"\\t A:\", np.shape(dataset[-1][\"A\"]))\n",
    "print(f\"\\t nodes_feature:\", np.shape(dataset[-1][\"nodes_feature\"]))\n",
    "print(f\"\\t edges_feature:\", np.shape(dataset[-1][\"edges_feature\"]))\n",
    "print(f\"\\t true_edges:\", np.shape(dataset[-1][\"true_edges\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a5096a10-c1be-42c4-9a04-fc6d776ea7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_dist(a):\n",
    "    if a==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1/a\n",
    "        \n",
    "i = dataset[0][\"A\"]\n",
    "v_in = [rev_dist(e) for e in dataset[0][\"edges_feature\"]]\n",
    "v_true = dataset[0][\"true_edges\"]\n",
    "x = dataset[0][\"nodes_feature\"]\n",
    "N = len(x)\n",
    "\n",
    "X = torch.Tensor(x)\n",
    "sp_A = torch.sparse_coo_tensor(i, v_in, (N, N))\n",
    "E_true = torch.Tensor(v_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "84eb1c09-c6e5-4280-ac3e-b5763b89b46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_pred:\n",
      "tensor([0.5000, 0.9523, 1.0000, 0.9966, 0.9421, 1.0000, 0.5447, 0.5212, 1.0000,\n",
      "        0.5000, 0.5000, 1.0000, 0.5000, 0.5000, 1.0000, 0.5000, 0.5000, 1.0000,\n",
      "        0.5000, 0.5000, 1.0000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7894,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        1.0000, 1.0000, 1.0000, 0.5000, 0.5000, 0.7894, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9994, 1.0000, 0.7894, 0.9997, 0.7666, 0.9999, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9993, 1.0000, 0.5000, 0.9739,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9630,\n",
      "        1.0000, 1.0000, 0.5000, 0.9992, 0.5000, 0.9370, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9191,\n",
      "        0.9965, 0.5000, 0.9611, 0.5000, 0.5000, 0.5000, 0.9976, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9472,\n",
      "        1.0000, 1.0000, 0.5000, 1.0000, 0.5000, 0.9989, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5000, 0.5000, 0.5000, 0.9976,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9978, 1.0000, 0.5000, 0.9994, 0.5000, 0.9998, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9995,\n",
      "        1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 0.9999,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9956,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9991, 0.8674, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9995, 0.8891, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9892, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.7083, 0.5509, 0.9605, 0.5000, 0.9998, 0.5000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9225, 0.9917, 0.9996, 0.9986, 0.9967, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SqueezeBackward1>) \n",
      "E_true:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0.])\n",
      "Loss =  tensor(8.1137, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"count_neuron_layers\": [9, 27, 18],\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 60,\n",
    "}\n",
    "\n",
    "learning_rate = 0.02\n",
    "\n",
    "node_gnn, edge_linear = get_models(params)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(node_gnn.parameters()) + list(edge_linear.parameters()),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "H_end = node_gnn(X, sp_A)\n",
    "Omega = torch.cat([H_end[i[0]], H_end[i[1]]],dim=1)\n",
    "E_pred = edge_linear(Omega)\n",
    "print(f\"E_pred:\\n{E_pred}\", f\"\\nE_true:\\n{E_true}\")\n",
    "print(\"Loss = \", criterion(E_pred, E_true))\n",
    "\n",
    "del optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60566c-0723-4b95-810b-594ac69c22f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d2e2674a-fb87-4c50-a726-32d39a29bbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch # 1 loss=0.3822                                        \n",
      "Batch # 2 loss=0.7642                                        \n",
      "Batch # 3 loss=0.4809                                        \n",
      "Batch # 4 loss=0.3877                                        \n",
      "Batch # 5 loss=0.4833                                        \n",
      "Batch # 6 loss=0.5117                                        \n",
      "Batch # 7 loss=0.4665                                        \n",
      "Batch # 8 loss=0.4245                                        \n",
      "Batch # 9 loss=0.4286                                        \n",
      "Batch # 10 loss=0.4377                                        \n",
      "Batch # 11 loss=0.4206                                        \n",
      "Batch # 12 loss=0.3638                                        \n",
      "Batch # 13 loss=0.4228                                        \n",
      "Batch # 14 loss=0.3739                                        \n",
      "Batch # 15 loss=0.4099                                        \n",
      "Batch # 16 loss=0.3874                                        \n",
      "Batch # 17 loss=0.4061                                        \n",
      "Batch # 18 loss=0.3534                                        \n",
      "Batch # 19 loss=0.3921                                        \n",
      "Batch # 20 loss=0.3632                                        \n",
      "Batch # 21 loss=0.3715                                        \n",
      "Batch # 22 loss=0.3959                                        \n",
      "Batch # 23 loss=0.3582                                        \n",
      "Batch # 24 loss=0.3421                                        \n",
      "========== EPOCH #1 ========== (0.4220/0.3758)        \n",
      "Batch # 1 loss=0.3569                                        \n",
      "Batch # 2 loss=0.3828                                        \n",
      "Batch # 3 loss=0.3854                                        \n",
      "Batch # 4 loss=0.3780                                        \n",
      "Batch # 5 loss=0.3516                                        \n",
      "Batch # 6 loss=0.3758                                        \n",
      "Batch # 7 loss=0.3478                                        \n",
      "Batch # 8 loss=0.3596                                        \n",
      "Batch # 9 loss=0.3681                                        \n",
      "Batch # 10 loss=0.3736                                        \n",
      "Batch # 11 loss=0.3747                                        \n",
      "Batch # 12 loss=0.3446                                        \n",
      "Batch # 13 loss=0.3972                                        \n",
      "Batch # 14 loss=0.3486                                        \n",
      "Batch # 15 loss=0.3895                                        \n",
      "Batch # 16 loss=0.3668                                        \n",
      "Batch # 17 loss=0.3800                                        \n",
      "Batch # 18 loss=0.3481                                        \n",
      "Batch # 19 loss=0.3799                                        \n",
      "Batch # 20 loss=0.3499                                        \n",
      "Batch # 21 loss=0.3469                                        \n",
      "Batch # 22 loss=0.3840                                        \n",
      "Batch # 23 loss=0.3434                                        \n",
      "Batch # 24 loss=0.3305                                        \n",
      "========== EPOCH #2 ========== (0.3652/0.3624)        \n",
      "Batch # 1 loss=0.3414                                        \n",
      "Batch # 2 loss=0.3663                                        \n",
      "Batch # 3 loss=0.3712                                        \n",
      "Batch # 4 loss=0.3706                                        \n",
      "Batch # 5 loss=0.3405                                        \n",
      "Batch # 6 loss=0.3673                                        \n",
      "Batch # 7 loss=0.3363                                        \n",
      "Batch # 8 loss=0.3502                                        \n",
      "Batch # 9 loss=0.3590                                        \n",
      "Batch # 10 loss=0.3618                                        \n",
      "Batch # 11 loss=0.3619                                        \n",
      "Batch # 12 loss=0.3387                                        \n",
      "Batch # 13 loss=0.3844                                        \n",
      "Batch # 14 loss=0.3378                                        \n",
      "Batch # 15 loss=0.3820                                        \n",
      "Batch # 16 loss=0.3583                                        \n",
      "Batch # 17 loss=0.3689                                        \n",
      "Batch # 18 loss=0.3374                                        \n",
      "Batch # 19 loss=0.3746                                        \n",
      "Batch # 20 loss=0.3436                                        \n",
      "Batch # 21 loss=0.3377                                        \n",
      "Batch # 22 loss=0.3800                                        \n",
      "Batch # 23 loss=0.3372                                        \n",
      "Batch # 24 loss=0.3215                                        \n",
      "========== EPOCH #3 ========== (0.3554/0.3534)        \n",
      "Batch # 1 loss=0.3330                                        \n",
      "Batch # 2 loss=0.3583                                        \n",
      "Batch # 3 loss=0.3587                                        \n",
      "Batch # 4 loss=0.3637                                        \n",
      "Batch # 5 loss=0.3334                                        \n",
      "Batch # 6 loss=0.3588                                        \n",
      "Batch # 7 loss=0.3290                                        \n",
      "Batch # 8 loss=0.3426                                        \n",
      "Batch # 9 loss=0.3478                                        \n",
      "Batch # 10 loss=0.3544                                        \n",
      "Batch # 11 loss=0.3528                                        \n",
      "Batch # 12 loss=0.3274                                        \n",
      "Batch # 13 loss=0.3861                                        \n",
      "Batch # 14 loss=0.3283                                        \n",
      "Batch # 15 loss=0.3773                                        \n",
      "Batch # 16 loss=0.3522                                        \n",
      "Batch # 17 loss=0.3598                                        \n",
      "Batch # 18 loss=0.3270                                        \n",
      "Batch # 19 loss=0.3709                                        \n",
      "Batch # 20 loss=0.3391                                        \n",
      "Batch # 21 loss=0.3331                                        \n",
      "Batch # 22 loss=0.3738                                        \n",
      "Batch # 23 loss=0.3449                                        \n",
      "Batch # 24 loss=0.3165                                        \n",
      "========== EPOCH #4 ========== (0.3487/0.3753)        \n",
      "Batch # 1 loss=0.3457                                        \n",
      "Batch # 2 loss=0.3541                                        \n",
      "Batch # 3 loss=0.3849                                        \n",
      "Batch # 4 loss=0.3629                                        \n",
      "Batch # 5 loss=0.3341                                        \n",
      "Batch # 6 loss=0.3597                                        \n",
      "Batch # 7 loss=0.3454                                        \n",
      "Batch # 8 loss=0.3376                                        \n",
      "Batch # 9 loss=0.3522                                        \n",
      "Batch # 10 loss=0.3533                                        \n",
      "Batch # 11 loss=0.3534                                        \n",
      "Batch # 12 loss=0.3336                                        \n",
      "Batch # 13 loss=0.3883                                        \n",
      "Batch # 14 loss=0.3319                                        \n",
      "Batch # 15 loss=0.3767                                        \n",
      "Batch # 16 loss=0.3629                                        \n",
      "Batch # 17 loss=0.3593                                        \n",
      "Batch # 18 loss=0.3273                                        \n",
      "Batch # 19 loss=0.3822                                        \n",
      "Batch # 20 loss=0.3391                                        \n",
      "Batch # 21 loss=0.3364                                        \n",
      "Batch # 22 loss=0.3716                                        \n",
      "Batch # 23 loss=0.3346                                        \n",
      "Batch # 24 loss=0.3163                                        \n",
      "========== EPOCH #5 ========== (0.3518/0.3513)        \n",
      "Batch # 1 loss=0.3272                                        \n",
      "Batch # 2 loss=0.3541                                        \n",
      "Batch # 3 loss=0.3529                                        \n",
      "Batch # 4 loss=0.3587                                        \n",
      "Batch # 5 loss=0.3246                                        \n",
      "Batch # 6 loss=0.3586                                        \n",
      "Batch # 7 loss=0.3259                                        \n",
      "Batch # 8 loss=0.3364                                        \n",
      "Batch # 9 loss=0.3415                                        \n",
      "Batch # 10 loss=0.3478                                        \n",
      "Batch # 11 loss=0.3474                                        \n",
      "Batch # 12 loss=0.3256                                        \n",
      "Batch # 13 loss=0.3814                                        \n",
      "Batch # 14 loss=0.3242                                        \n",
      "Batch # 15 loss=0.4044                                        \n",
      "Batch # 16 loss=0.3488                                        \n",
      "Batch # 17 loss=0.3545                                        \n",
      "Batch # 18 loss=0.3227                                        \n",
      "Batch # 19 loss=0.3831                                        \n",
      "Batch # 20 loss=0.3387                                        \n",
      "Batch # 21 loss=0.3321                                        \n",
      "Batch # 22 loss=0.3706                                        \n",
      "Batch # 23 loss=0.3505                                        \n",
      "Batch # 24 loss=0.3214                                        \n",
      "========== EPOCH #6 ========== (0.3472/0.4043)        \n",
      "Batch # 1 loss=0.3711                                        \n",
      "Batch # 2 loss=0.3595                                        \n",
      "Batch # 3 loss=0.4093                                        \n",
      "Batch # 4 loss=0.3594                                        \n",
      "Batch # 5 loss=0.3408                                        \n",
      "Batch # 6 loss=0.3827                                        \n",
      "Batch # 7 loss=0.3336                                        \n",
      "Batch # 8 loss=0.3549                                        \n",
      "Batch # 9 loss=0.3468                                        \n",
      "Batch # 10 loss=0.3579                                        \n",
      "Batch # 11 loss=0.3615                                        \n",
      "Batch # 12 loss=0.3268                                        \n",
      "Batch # 13 loss=0.3797                                        \n",
      "Batch # 14 loss=0.3332                                        \n",
      "Batch # 15 loss=0.3784                                        \n",
      "Batch # 16 loss=0.3525                                        \n",
      "Batch # 17 loss=0.3590                                        \n",
      "Batch # 18 loss=0.3332                                        \n",
      "Batch # 19 loss=0.3694                                        \n",
      "Batch # 20 loss=0.3368                                        \n",
      "Batch # 21 loss=0.3343                                        \n",
      "Batch # 22 loss=0.3719                                        \n",
      "Batch # 23 loss=0.3361                                        \n",
      "Batch # 24 loss=0.3190                                        \n",
      "========== EPOCH #7 ========== (0.3545/0.3495)        \n",
      "Batch # 1 loss=0.3267                                        \n",
      "Batch # 2 loss=0.3569                                        \n",
      "Batch # 3 loss=0.3532                                        \n",
      "Batch # 4 loss=0.3594                                        \n",
      "Batch # 5 loss=0.3335                                        \n",
      "Batch # 6 loss=0.3535                                        \n",
      "Batch # 7 loss=0.3272                                        \n",
      "Batch # 8 loss=0.3376                                        \n",
      "Batch # 9 loss=0.3408                                        \n",
      "Batch # 10 loss=0.3530                                        \n",
      "Batch # 11 loss=0.3464                                        \n",
      "Batch # 12 loss=0.3234                                        \n",
      "Batch # 13 loss=0.3794                                        \n",
      "Batch # 14 loss=0.3267                                        \n",
      "Batch # 15 loss=0.4031                                        \n",
      "Batch # 16 loss=0.3457                                        \n",
      "Batch # 17 loss=0.3521                                        \n",
      "Batch # 18 loss=0.3249                                        \n",
      "Batch # 19 loss=0.3823                                        \n",
      "Batch # 20 loss=0.3330                                        \n",
      "Batch # 21 loss=0.3272                                        \n",
      "Batch # 22 loss=0.3672                                        \n",
      "Batch # 23 loss=0.3329                                        \n",
      "Batch # 24 loss=0.3126                                        \n",
      "========== EPOCH #8 ========== (0.3458/0.3579)        \n",
      "Batch # 1 loss=0.3309                                        \n",
      "Batch # 2 loss=0.3499                                        \n",
      "Batch # 3 loss=0.3638                                        \n",
      "Batch # 4 loss=0.3592                                        \n",
      "Batch # 5 loss=0.3225                                        \n",
      "Batch # 6 loss=0.3498                                        \n",
      "Batch # 7 loss=0.3387                                        \n",
      "Batch # 8 loss=0.3374                                        \n",
      "Batch # 9 loss=0.3483                                        \n",
      "Batch # 10 loss=0.3497                                        \n",
      "Batch # 11 loss=0.3494                                        \n",
      "Batch # 12 loss=0.3222                                        \n",
      "Batch # 13 loss=0.3920                                        \n",
      "Batch # 14 loss=0.3236                                        \n",
      "Batch # 15 loss=0.4092                                        \n",
      "Batch # 16 loss=0.3460                                        \n",
      "Batch # 17 loss=0.3572                                        \n",
      "Batch # 18 loss=0.3230                                        \n",
      "Batch # 19 loss=0.3804                                        \n",
      "Batch # 20 loss=0.3352                                        \n",
      "Batch # 21 loss=0.3297                                        \n",
      "Batch # 22 loss=0.3710                                        \n",
      "Batch # 23 loss=0.3379                                        \n",
      "Batch # 24 loss=0.3144                                        \n",
      "========== EPOCH #9 ========== (0.3476/0.3505)        \n",
      "Batch # 1 loss=0.3258                                        \n",
      "Batch # 2 loss=0.3554                                        \n",
      "Batch # 3 loss=0.3496                                        \n",
      "Batch # 4 loss=0.3589                                        \n",
      "Batch # 5 loss=0.3207                                        \n",
      "Batch # 6 loss=0.3639                                        \n",
      "Batch # 7 loss=0.3245                                        \n",
      "Batch # 8 loss=0.3366                                        \n",
      "Batch # 9 loss=0.3374                                        \n",
      "Batch # 10 loss=0.3473                                        \n",
      "Batch # 11 loss=0.3441                                        \n",
      "Batch # 12 loss=0.3273                                        \n",
      "Batch # 13 loss=0.3796                                        \n",
      "Batch # 14 loss=0.3228                                        \n",
      "Batch # 15 loss=0.4027                                        \n",
      "Batch # 16 loss=0.3509                                        \n",
      "Batch # 17 loss=0.3498                                        \n",
      "Batch # 18 loss=0.3219                                        \n",
      "Batch # 19 loss=0.3993                                        \n",
      "Batch # 20 loss=0.3416                                        \n",
      "Batch # 21 loss=0.3279                                        \n",
      "Batch # 22 loss=0.3876                                        \n",
      "Batch # 23 loss=0.3364                                        \n",
      "Batch # 24 loss=0.3141                                        \n",
      "========== EPOCH #10 ========== (0.3469/0.3482)       \n",
      "Batch # 1 loss=0.3233                                        \n",
      "Batch # 2 loss=0.3531                                        \n",
      "Batch # 3 loss=0.3495                                        \n",
      "Batch # 4 loss=0.3576                                        \n",
      "Batch # 5 loss=0.3197                                        \n",
      "Batch # 6 loss=0.3586                                        \n",
      "Batch # 7 loss=0.3293                                        \n",
      "Batch # 8 loss=0.3342                                        \n",
      "Batch # 9 loss=0.3397                                        \n",
      "Batch # 10 loss=0.3460                                        \n",
      "Batch # 11 loss=0.3459                                        \n",
      "Batch # 12 loss=0.3204                                        \n",
      "Batch # 13 loss=0.3936                                        \n",
      "Batch # 14 loss=0.3207                                        \n",
      "Batch # 15 loss=0.4045                                        \n",
      "Batch # 16 loss=0.3460                                        \n",
      "Batch # 17 loss=0.3522                                        \n",
      "Batch # 18 loss=0.3214                                        \n",
      "Batch # 19 loss=0.3986                                        \n",
      "Batch # 20 loss=0.3339                                        \n",
      "Batch # 21 loss=0.3275                                        \n",
      "Batch # 22 loss=0.3803                                        \n",
      "Batch # 23 loss=0.3407                                        \n",
      "Batch # 24 loss=0.3124                                        \n",
      "========== EPOCH #11 ========== (0.3462/0.3670)       \n",
      "Batch # 1 loss=0.3380                                        \n",
      "Batch # 2 loss=0.3499                                        \n",
      "Batch # 3 loss=0.3773                                        \n",
      "Batch # 4 loss=0.3596                                        \n",
      "Batch # 5 loss=0.3287                                        \n",
      "Batch # 6 loss=0.3537                                        \n",
      "Batch # 7 loss=0.3414                                        \n",
      "Batch # 8 loss=0.3318                                        \n",
      "Batch # 9 loss=0.3483                                        \n",
      "Batch # 10 loss=0.3484                                        \n",
      "Batch # 11 loss=0.3494                                        \n",
      "Batch # 12 loss=0.3257                                        \n",
      "Batch # 13 loss=0.3858                                        \n",
      "Batch # 14 loss=0.3285                                        \n",
      "Batch # 15 loss=0.4024                                        \n",
      "Batch # 16 loss=0.3566                                        \n",
      "Batch # 17 loss=0.3487                                        \n",
      "Batch # 18 loss=0.3249                                        \n",
      "Batch # 19 loss=0.3866                                        \n",
      "Batch # 20 loss=0.3373                                        \n",
      "Batch # 21 loss=0.3319                                        \n",
      "Batch # 22 loss=0.3688                                        \n",
      "Batch # 23 loss=0.3296                                        \n",
      "Batch # 24 loss=0.3116                                        \n",
      "========== EPOCH #12 ========== (0.3485/0.3457)       \n",
      "Batch # 1 loss=0.3232                                        \n",
      "Batch # 2 loss=0.3490                                        \n",
      "Batch # 3 loss=0.3466                                        \n",
      "Batch # 4 loss=0.3524                                        \n",
      "Batch # 5 loss=0.3221                                        \n",
      "Batch # 6 loss=0.3519                                        \n",
      "Batch # 7 loss=0.3220                                        \n",
      "Batch # 8 loss=0.3300                                        \n",
      "Batch # 9 loss=0.3358                                        \n",
      "Batch # 10 loss=0.3448                                        \n",
      "Batch # 11 loss=0.3437                                        \n",
      "Batch # 12 loss=0.3189                                        \n",
      "Batch # 13 loss=0.3762                                        \n",
      "Batch # 14 loss=0.3202                                        \n",
      "Batch # 15 loss=0.4013                                        \n",
      "Batch # 16 loss=0.3422                                        \n",
      "Batch # 17 loss=0.3454                                        \n",
      "Batch # 18 loss=0.3196                                        \n",
      "Batch # 19 loss=0.4029                                        \n",
      "Batch # 20 loss=0.3341                                        \n",
      "Batch # 21 loss=0.3256                                        \n",
      "Batch # 22 loss=0.3814                                        \n",
      "Batch # 23 loss=0.3384                                        \n",
      "Batch # 24 loss=0.3108                                        \n",
      "========== EPOCH #13 ========== (0.3433/0.3710)       \n",
      "Batch # 1 loss=0.3407                                        \n",
      "Batch # 2 loss=0.3470                                        \n",
      "Batch # 3 loss=0.3831                                        \n",
      "Batch # 4 loss=0.3760                                        \n",
      "Batch # 5 loss=0.3357                                        \n",
      "Batch # 6 loss=0.3549                                        \n",
      "Batch # 7 loss=0.3525                                        \n",
      "Batch # 8 loss=0.3326                                        \n",
      "Batch # 9 loss=0.3589                                        \n",
      "Batch # 10 loss=0.3526                                        \n",
      "Batch # 11 loss=0.3523                                        \n",
      "Batch # 12 loss=0.3329                                        \n",
      "Batch # 13 loss=0.3854                                        \n",
      "Batch # 14 loss=0.3353                                        \n",
      "Batch # 15 loss=0.3973                                        \n",
      "Batch # 16 loss=0.3538                                        \n",
      "Batch # 17 loss=0.3607                                        \n",
      "Batch # 18 loss=0.3236                                        \n",
      "Batch # 19 loss=0.4012                                        \n",
      "Batch # 20 loss=0.3328                                        \n",
      "Batch # 21 loss=0.3378                                        \n",
      "Batch # 22 loss=0.3696                                        \n",
      "Batch # 23 loss=0.3293                                        \n",
      "Batch # 24 loss=0.3155                                        \n",
      "========== EPOCH #14 ========== (0.3526/0.3692)       \n",
      "Batch # 1 loss=0.3395                                        \n",
      "Batch # 2 loss=0.3533                                        \n",
      "Batch # 3 loss=0.3583                                        \n",
      "Batch # 4 loss=0.3633                                        \n",
      "Batch # 5 loss=0.3250                                        \n",
      "Batch # 6 loss=0.3737                                        \n",
      "Batch # 7 loss=0.3287                                        \n",
      "Batch # 8 loss=0.3332                                        \n",
      "Batch # 9 loss=0.3459                                        \n",
      "Batch # 10 loss=0.3474                                        \n",
      "Batch # 11 loss=0.3517                                        \n",
      "Batch # 12 loss=0.3198                                        \n",
      "Batch # 13 loss=0.3742                                        \n",
      "Batch # 14 loss=0.3272                                        \n",
      "Batch # 15 loss=0.4011                                        \n",
      "Batch # 16 loss=0.3422                                        \n",
      "Batch # 17 loss=0.3472                                        \n",
      "Batch # 18 loss=0.3250                                        \n",
      "Batch # 19 loss=0.3996                                        \n",
      "Batch # 20 loss=0.3295                                        \n",
      "Batch # 21 loss=0.3271                                        \n",
      "Batch # 22 loss=0.3630                                        \n",
      "Batch # 23 loss=0.3294                                        \n",
      "Batch # 24 loss=0.3106                                        \n",
      "========== EPOCH #15 ========== (0.3465/0.3517)       \n",
      "Batch # 1 loss=0.3252                                        \n",
      "Batch # 2 loss=0.3476                                        \n",
      "Batch # 3 loss=0.3545                                        \n",
      "Batch # 4 loss=0.3510                                        \n",
      "Batch # 5 loss=0.3202                                        \n",
      "Batch # 6 loss=0.3521                                        \n",
      "Batch # 7 loss=0.3349                                        \n",
      "Batch # 8 loss=0.3288                                        \n",
      "Batch # 9 loss=0.3407                                        \n",
      "Batch # 10 loss=0.3442                                        \n",
      "Batch # 11 loss=0.3437                                        \n",
      "Batch # 12 loss=0.3166                                        \n",
      "Batch # 13 loss=0.3969                                        \n",
      "Batch # 14 loss=0.3210                                        \n",
      "Batch # 15 loss=0.4017                                        \n",
      "Batch # 16 loss=0.3396                                        \n",
      "Batch # 17 loss=0.3480                                        \n",
      "Batch # 18 loss=0.3214                                        \n",
      "Batch # 19 loss=0.3943                                        \n",
      "Batch # 20 loss=0.3286                                        \n",
      "Batch # 21 loss=0.3247                                        \n",
      "Batch # 22 loss=0.3772                                        \n",
      "Batch # 23 loss=0.3315                                        \n",
      "Batch # 24 loss=0.3083                                        \n",
      "========== EPOCH #16 ========== (0.3439/0.3573)       \n",
      "Batch # 1 loss=0.3289                                        \n",
      "Batch # 2 loss=0.3469                                        \n",
      "Batch # 3 loss=0.3621                                        \n",
      "Batch # 4 loss=0.3527                                        \n",
      "Batch # 5 loss=0.3229                                        \n",
      "Batch # 6 loss=0.3503                                        \n",
      "Batch # 7 loss=0.3396                                        \n",
      "Batch # 8 loss=0.3288                                        \n",
      "Batch # 9 loss=0.3441                                        \n",
      "Batch # 10 loss=0.3432                                        \n",
      "Batch # 11 loss=0.3470                                        \n",
      "Batch # 12 loss=0.3174                                        \n",
      "Batch # 13 loss=0.4008                                        \n",
      "Batch # 14 loss=0.3209                                        \n",
      "Batch # 15 loss=0.4021                                        \n",
      "Batch # 16 loss=0.3452                                        \n",
      "Batch # 17 loss=0.3501                                        \n",
      "Batch # 18 loss=0.3200                                        \n",
      "Batch # 19 loss=0.3937                                        \n",
      "Batch # 20 loss=0.3355                                        \n",
      "Batch # 21 loss=0.3254                                        \n",
      "Batch # 22 loss=0.3850                                        \n",
      "Batch # 23 loss=0.3289                                        \n",
      "Batch # 24 loss=0.3140                                        \n",
      "========== EPOCH #17 ========== (0.3461/0.3430)       \n",
      "Batch # 1 loss=0.3197                                        \n",
      "Batch # 2 loss=0.3518                                        \n",
      "Batch # 3 loss=0.3437                                        \n",
      "Batch # 4 loss=0.3556                                        \n",
      "Batch # 5 loss=0.3193                                        \n",
      "Batch # 6 loss=0.3580                                        \n",
      "Batch # 7 loss=0.3248                                        \n",
      "Batch # 8 loss=0.3307                                        \n",
      "Batch # 9 loss=0.3338                                        \n",
      "Batch # 10 loss=0.3435                                        \n",
      "Batch # 11 loss=0.3415                                        \n",
      "Batch # 12 loss=0.3204                                        \n",
      "Batch # 13 loss=0.3957                                        \n",
      "Batch # 14 loss=0.3208                                        \n",
      "Batch # 15 loss=0.4000                                        \n",
      "Batch # 16 loss=0.3430                                        \n",
      "Batch # 17 loss=0.3448                                        \n",
      "Batch # 18 loss=0.3178                                        \n",
      "Batch # 19 loss=0.3936                                        \n",
      "Batch # 20 loss=0.3326                                        \n",
      "Batch # 21 loss=0.3246                                        \n",
      "Batch # 22 loss=0.3812                                        \n",
      "Batch # 23 loss=0.3327                                        \n",
      "Batch # 24 loss=0.3076                                        \n",
      "========== EPOCH #18 ========== (0.3432/0.3505)       \n",
      "Batch # 1 loss=0.3227                                        \n",
      "Batch # 2 loss=0.3472                                        \n",
      "Batch # 3 loss=0.3537                                        \n",
      "Batch # 4 loss=0.3565                                        \n",
      "Batch # 5 loss=0.3190                                        \n",
      "Batch # 6 loss=0.3491                                        \n",
      "Batch # 7 loss=0.3344                                        \n",
      "Batch # 8 loss=0.3285                                        \n",
      "Batch # 9 loss=0.3404                                        \n",
      "Batch # 10 loss=0.3433                                        \n",
      "Batch # 11 loss=0.3436                                        \n",
      "Batch # 12 loss=0.3157                                        \n",
      "Batch # 13 loss=0.4043                                        \n",
      "Batch # 14 loss=0.3183                                        \n",
      "Batch # 15 loss=0.4026                                        \n",
      "Batch # 16 loss=0.3393                                        \n",
      "Batch # 17 loss=0.3479                                        \n",
      "Batch # 18 loss=0.3193                                        \n",
      "Batch # 19 loss=0.3926                                        \n",
      "Batch # 20 loss=0.3283                                        \n",
      "Batch # 21 loss=0.3248                                        \n",
      "Batch # 22 loss=0.3777                                        \n",
      "Batch # 23 loss=0.3331                                        \n",
      "Batch # 24 loss=0.3074                                        \n",
      "========== EPOCH #19 ========== (0.3437/0.3549)       \n",
      "Batch # 1 loss=0.3264                                        \n",
      "Batch # 2 loss=0.3469                                        \n",
      "Batch # 3 loss=0.3572                                        \n",
      "Batch # 4 loss=0.3562                                        \n",
      "Batch # 5 loss=0.3205                                        \n",
      "Batch # 6 loss=0.3530                                        \n",
      "Batch # 7 loss=0.3345                                        \n",
      "Batch # 8 loss=0.3288                                        \n",
      "Batch # 9 loss=0.3403                                        \n",
      "Batch # 10 loss=0.3423                                        \n",
      "Batch # 11 loss=0.3440                                        \n",
      "Batch # 12 loss=0.3178                                        \n",
      "Batch # 13 loss=0.4048                                        \n",
      "Batch # 14 loss=0.3212                                        \n",
      "Batch # 15 loss=0.4013                                        \n",
      "Batch # 16 loss=0.3439                                        \n",
      "Batch # 17 loss=0.3488                                        \n",
      "Batch # 18 loss=0.3185                                        \n",
      "Batch # 19 loss=0.3926                                        \n",
      "Batch # 20 loss=0.3342                                        \n",
      "Batch # 21 loss=0.3244                                        \n",
      "Batch # 22 loss=0.3839                                        \n",
      "Batch # 23 loss=0.3295                                        \n",
      "Batch # 24 loss=0.3114                                        \n",
      "========== EPOCH #20 ========== (0.3451/0.3422)       \n",
      "Batch # 1 loss=0.3172                                        \n",
      "Batch # 2 loss=0.3504                                        \n",
      "Batch # 3 loss=0.3423                                        \n",
      "Batch # 4 loss=0.3606                                        \n",
      "Batch # 5 loss=0.3170                                        \n",
      "Batch # 6 loss=0.3583                                        \n",
      "Batch # 7 loss=0.3243                                        \n",
      "Batch # 8 loss=0.3316                                        \n",
      "Batch # 9 loss=0.3344                                        \n",
      "Batch # 10 loss=0.3431                                        \n",
      "Batch # 11 loss=0.3400                                        \n",
      "Batch # 12 loss=0.3187                                        \n",
      "Batch # 13 loss=0.4011                                        \n",
      "Batch # 14 loss=0.3210                                        \n",
      "Batch # 15 loss=0.3997                                        \n",
      "Batch # 16 loss=0.3421                                        \n",
      "Batch # 17 loss=0.3467                                        \n",
      "Batch # 18 loss=0.3178                                        \n",
      "Batch # 19 loss=0.3925                                        \n",
      "Batch # 20 loss=0.3312                                        \n",
      "Batch # 21 loss=0.3250                                        \n",
      "Batch # 22 loss=0.3810                                        \n",
      "Batch # 23 loss=0.3339                                        \n",
      "Batch # 24 loss=0.3072                                        \n",
      "========== EPOCH #21 ========== (0.3432/0.3512)       \n",
      "Batch # 1 loss=0.3231                                        \n",
      "Batch # 2 loss=0.3471                                        \n",
      "Batch # 3 loss=0.3532                                        \n",
      "Batch # 4 loss=0.3555                                        \n",
      "Batch # 5 loss=0.3190                                        \n",
      "Batch # 6 loss=0.3516                                        \n",
      "Batch # 7 loss=0.3325                                        \n",
      "Batch # 8 loss=0.3286                                        \n",
      "Batch # 9 loss=0.3399                                        \n",
      "Batch # 10 loss=0.3420                                        \n",
      "Batch # 11 loss=0.3435                                        \n",
      "Batch # 12 loss=0.3160                                        \n",
      "Batch # 13 loss=0.4057                                        \n",
      "Batch # 14 loss=0.3206                                        \n",
      "Batch # 15 loss=0.4015                                        \n",
      "Batch # 16 loss=0.3412                                        \n",
      "Batch # 17 loss=0.3482                                        \n",
      "Batch # 18 loss=0.3181                                        \n",
      "Batch # 19 loss=0.3926                                        \n",
      "Batch # 20 loss=0.3315                                        \n",
      "Batch # 21 loss=0.3244                                        \n",
      "Batch # 22 loss=0.3810                                        \n",
      "Batch # 23 loss=0.3317                                        \n",
      "Batch # 24 loss=0.3087                                        \n",
      "========== EPOCH #22 ========== (0.3441/0.3451)       \n",
      "Batch # 1 loss=0.3185                                        \n",
      "Batch # 2 loss=0.3481                                        \n",
      "Batch # 3 loss=0.3457                                        \n",
      "Batch # 4 loss=0.3568                                        \n",
      "Batch # 5 loss=0.3170                                        \n",
      "Batch # 6 loss=0.3546                                        \n",
      "Batch # 7 loss=0.3275                                        \n",
      "Batch # 8 loss=0.3297                                        \n",
      "Batch # 9 loss=0.3374                                        \n",
      "Batch # 10 loss=0.3425                                        \n",
      "Batch # 11 loss=0.3416                                        \n",
      "Batch # 12 loss=0.3156                                        \n",
      "Batch # 13 loss=0.4047                                        \n",
      "Batch # 14 loss=0.3201                                        \n",
      "Batch # 15 loss=0.4013                                        \n",
      "Batch # 16 loss=0.3389                                        \n",
      "Batch # 17 loss=0.3472                                        \n",
      "Batch # 18 loss=0.3186                                        \n",
      "Batch # 19 loss=0.3923                                        \n",
      "Batch # 20 loss=0.3285                                        \n",
      "Batch # 21 loss=0.3238                                        \n",
      "Batch # 22 loss=0.3777                                        \n",
      "Batch # 23 loss=0.3343                                        \n",
      "Batch # 24 loss=0.3075                                        \n",
      "========== EPOCH #23 ========== (0.3429/0.3587)       \n",
      "Batch # 1 loss=0.3294                                        \n",
      "Batch # 2 loss=0.3466                                        \n",
      "Batch # 3 loss=0.3627                                        \n",
      "Batch # 4 loss=0.3561                                        \n",
      "Batch # 5 loss=0.3213                                        \n",
      "Batch # 6 loss=0.3510                                        \n",
      "Batch # 7 loss=0.3310                                        \n",
      "Batch # 8 loss=0.3288                                        \n",
      "Batch # 9 loss=0.3411                                        \n",
      "Batch # 10 loss=0.3428                                        \n",
      "Batch # 11 loss=0.3434                                        \n",
      "Batch # 12 loss=0.3189                                        \n",
      "Batch # 13 loss=0.3992                                        \n",
      "Batch # 14 loss=0.3209                                        \n",
      "Batch # 15 loss=0.3999                                        \n",
      "Batch # 16 loss=0.3486                                        \n",
      "Batch # 17 loss=0.3491                                        \n",
      "Batch # 18 loss=0.3198                                        \n",
      "Batch # 19 loss=0.3892                                        \n",
      "Batch # 20 loss=0.3354                                        \n",
      "Batch # 21 loss=0.3232                                        \n",
      "Batch # 22 loss=0.3850                                        \n",
      "Batch # 23 loss=0.3276                                        \n",
      "Batch # 24 loss=0.3129                                        \n",
      "========== EPOCH #24 ========== (0.3452/0.3421)       \n",
      "Batch # 1 loss=0.3193                                        \n",
      "Batch # 2 loss=0.3502                                        \n",
      "Batch # 3 loss=0.3436                                        \n",
      "Batch # 4 loss=0.3593                                        \n",
      "Batch # 5 loss=0.3193                                        \n",
      "Batch # 6 loss=0.3558                                        \n",
      "Batch # 7 loss=0.3240                                        \n",
      "Batch # 8 loss=0.3288                                        \n",
      "Batch # 9 loss=0.3327                                        \n",
      "Batch # 10 loss=0.3426                                        \n",
      "Batch # 11 loss=0.3408                                        \n",
      "Batch # 12 loss=0.3176                                        \n",
      "Batch # 13 loss=0.3969                                        \n",
      "Batch # 14 loss=0.3184                                        \n",
      "Batch # 15 loss=0.3999                                        \n",
      "Batch # 16 loss=0.3421                                        \n",
      "Batch # 17 loss=0.3446                                        \n",
      "Batch # 18 loss=0.3166                                        \n",
      "Batch # 19 loss=0.3927                                        \n",
      "Batch # 20 loss=0.3308                                        \n",
      "Batch # 21 loss=0.3227                                        \n",
      "Batch # 22 loss=0.3942                                        \n",
      "Batch # 23 loss=0.3342                                        \n",
      "Batch # 24 loss=0.3055                                        \n",
      "========== EPOCH #25 ========== (0.3430/0.3506)       \n",
      "Batch # 1 loss=0.3220                                        \n",
      "Batch # 2 loss=0.3454                                        \n",
      "Batch # 3 loss=0.3533                                        \n",
      "Batch # 4 loss=0.3548                                        \n",
      "Batch # 5 loss=0.3172                                        \n",
      "Batch # 6 loss=0.3553                                        \n",
      "Batch # 7 loss=0.3346                                        \n",
      "Batch # 8 loss=0.3269                                        \n",
      "Batch # 9 loss=0.3390                                        \n",
      "Batch # 10 loss=0.3412                                        \n",
      "Batch # 11 loss=0.3428                                        \n",
      "Batch # 12 loss=0.3144                                        \n",
      "Batch # 13 loss=0.4059                                        \n",
      "Batch # 14 loss=0.3190                                        \n",
      "Batch # 15 loss=0.4015                                        \n",
      "Batch # 16 loss=0.3408                                        \n",
      "Batch # 17 loss=0.3502                                        \n",
      "Batch # 18 loss=0.3185                                        \n",
      "Batch # 19 loss=0.3924                                        \n",
      "Batch # 20 loss=0.3293                                        \n",
      "Batch # 21 loss=0.3248                                        \n",
      "Batch # 22 loss=0.3941                                        \n",
      "Batch # 23 loss=0.3346                                        \n",
      "Batch # 24 loss=0.3070                                        \n",
      "========== EPOCH #26 ========== (0.3444/0.3491)       \n",
      "Batch # 1 loss=0.3215                                        \n",
      "Batch # 2 loss=0.3472                                        \n",
      "Batch # 3 loss=0.3497                                        \n",
      "Batch # 4 loss=0.3553                                        \n",
      "Batch # 5 loss=0.3178                                        \n",
      "Batch # 6 loss=0.3621                                        \n",
      "Batch # 7 loss=0.3307                                        \n",
      "Batch # 8 loss=0.3288                                        \n",
      "Batch # 9 loss=0.3364                                        \n",
      "Batch # 10 loss=0.3419                                        \n",
      "Batch # 11 loss=0.3412                                        \n",
      "Batch # 12 loss=0.3171                                        \n",
      "Batch # 13 loss=0.4031                                        \n",
      "Batch # 14 loss=0.3200                                        \n",
      "Batch # 15 loss=0.4006                                        \n",
      "Batch # 16 loss=0.3431                                        \n",
      "Batch # 17 loss=0.3523                                        \n",
      "Batch # 18 loss=0.3175                                        \n",
      "Batch # 19 loss=0.3925                                        \n",
      "Batch # 20 loss=0.3324                                        \n",
      "Batch # 21 loss=0.3259                                        \n",
      "Batch # 22 loss=0.3971                                        \n",
      "Batch # 23 loss=0.3353                                        \n",
      "Batch # 24 loss=0.3093                                        \n",
      "========== EPOCH #27 ========== (0.3450/0.3444)       \n",
      "Batch # 1 loss=0.3183                                        \n",
      "Batch # 2 loss=0.3474                                        \n",
      "Batch # 3 loss=0.3450                                        \n",
      "Batch # 4 loss=0.3580                                        \n",
      "Batch # 5 loss=0.3160                                        \n",
      "Batch # 6 loss=0.3616                                        \n",
      "Batch # 7 loss=0.3273                                        \n",
      "Batch # 8 loss=0.3292                                        \n",
      "Batch # 9 loss=0.3345                                        \n",
      "Batch # 10 loss=0.3413                                        \n",
      "Batch # 11 loss=0.3405                                        \n",
      "Batch # 12 loss=0.3163                                        \n",
      "Batch # 13 loss=0.4031                                        \n",
      "Batch # 14 loss=0.3197                                        \n",
      "Batch # 15 loss=0.3998                                        \n",
      "Batch # 16 loss=0.3430                                        \n",
      "Batch # 17 loss=0.3483                                        \n",
      "Batch # 18 loss=0.3184                                        \n",
      "Batch # 19 loss=0.3921                                        \n",
      "Batch # 20 loss=0.3307                                        \n",
      "Batch # 21 loss=0.3240                                        \n",
      "Batch # 22 loss=0.3960                                        \n",
      "Batch # 23 loss=0.3333                                        \n",
      "Batch # 24 loss=0.3060                                        \n",
      "========== EPOCH #28 ========== (0.3437/0.3487)       \n",
      "Batch # 1 loss=0.3211                                        \n",
      "Batch # 2 loss=0.3478                                        \n",
      "Batch # 3 loss=0.3479                                        \n",
      "Batch # 4 loss=0.3554                                        \n",
      "Batch # 5 loss=0.3176                                        \n",
      "Batch # 6 loss=0.3608                                        \n",
      "Batch # 7 loss=0.3307                                        \n",
      "Batch # 8 loss=0.3290                                        \n",
      "Batch # 9 loss=0.3359                                        \n",
      "Batch # 10 loss=0.3427                                        \n",
      "Batch # 11 loss=0.3409                                        \n",
      "Batch # 12 loss=0.3165                                        \n",
      "Batch # 13 loss=0.4028                                        \n",
      "Batch # 14 loss=0.3204                                        \n",
      "Batch # 15 loss=0.3999                                        \n",
      "Batch # 16 loss=0.3433                                        \n",
      "Batch # 17 loss=0.3508                                        \n",
      "Batch # 18 loss=0.3178                                        \n",
      "Batch # 19 loss=0.3926                                        \n",
      "Batch # 20 loss=0.3317                                        \n",
      "Batch # 21 loss=0.3243                                        \n",
      "Batch # 22 loss=0.3969                                        \n",
      "Batch # 23 loss=0.3359                                        \n",
      "Batch # 24 loss=0.3086                                        \n",
      "========== EPOCH #29 ========== (0.3446/0.3471)       \n",
      "Batch # 1 loss=0.3202                                        \n",
      "Batch # 2 loss=0.3470                                        \n",
      "Batch # 3 loss=0.3472                                        \n",
      "Batch # 4 loss=0.3572                                        \n",
      "Batch # 5 loss=0.3168                                        \n",
      "Batch # 6 loss=0.3616                                        \n",
      "Batch # 7 loss=0.3284                                        \n",
      "Batch # 8 loss=0.3297                                        \n",
      "Batch # 9 loss=0.3348                                        \n",
      "Batch # 10 loss=0.3427                                        \n",
      "Batch # 11 loss=0.3402                                        \n",
      "Batch # 12 loss=0.3175                                        \n",
      "Batch # 13 loss=0.4030                                        \n",
      "Batch # 14 loss=0.3211                                        \n",
      "Batch # 15 loss=0.3992                                        \n",
      "Batch # 16 loss=0.3462                                        \n",
      "Batch # 17 loss=0.3501                                        \n",
      "Batch # 18 loss=0.3194                                        \n",
      "Batch # 19 loss=0.3939                                        \n",
      "Batch # 20 loss=0.3339                                        \n",
      "Batch # 21 loss=0.3246                                        \n",
      "Batch # 22 loss=0.3989                                        \n",
      "Batch # 23 loss=0.3365                                        \n",
      "Batch # 24 loss=0.3096                                        \n",
      "========== EPOCH #30 ========== (0.3450/0.3449)       \n"
     ]
    }
   ],
   "source": [
    "# models =  get_models(params)\n",
    "train_model(params,models, dataset, \"z_torch\", save_frequency=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54f343-cb1a-4731-9c2c-c0d71d48c333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d097ece-7450-4682-b01d-f178dc020a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Parameter containing:\n",
      "tensor([[-0.1759, -0.0254,  0.2722,  0.0184,  0.1136, -0.2754,  0.2124,  0.1935,\n",
      "          0.5147],\n",
      "        [-0.1288, -0.4236, -0.1713, -0.2819, -0.1806, -0.0876,  0.2570,  0.0384,\n",
      "          0.6041],\n",
      "        [ 0.0236, -0.6083,  0.1191, -0.2275,  0.1009,  0.3368,  0.0306, -0.0403,\n",
      "         -0.2145],\n",
      "        [-0.3864, -0.2112, -0.0350,  0.4570, -0.1351,  0.7280, -0.0679, -0.1624,\n",
      "          0.1483],\n",
      "        [-0.9543, -0.0974, -0.1931,  0.2187,  0.0159,  0.0479,  0.0109, -0.0153,\n",
      "          0.5601],\n",
      "        [-0.1470, -0.1628, -0.2523, -0.6196, -0.3178,  0.0788,  0.0615, -0.3432,\n",
      "          0.1215],\n",
      "        [-0.4620,  0.2739, -0.5049, -0.0629, -0.6254,  0.0990, -0.1985, -0.0373,\n",
      "         -0.0076],\n",
      "        [ 0.4061, -0.1382,  0.4136,  0.3187,  0.3797,  0.0730,  0.4111,  0.6153,\n",
      "          0.3442],\n",
      "        [ 0.0625, -0.2081, -0.0831,  0.3625,  0.2356, -0.1471,  0.1947,  0.3956,\n",
      "         -0.0047],\n",
      "        [ 0.4516,  0.8717,  0.9890,  0.7712,  0.4401,  0.6299,  0.2625,  0.5194,\n",
      "          0.5632],\n",
      "        [-0.1161,  0.6520, -0.0500,  0.5225,  0.1529,  0.0400, -0.4865, -0.1892,\n",
      "          0.1482],\n",
      "        [ 0.0350, -0.0907,  0.1741, -0.1943,  0.8430,  0.0799,  0.4364, -0.3920,\n",
      "          0.0785],\n",
      "        [-0.0184, -0.1775,  0.0700, -0.1954,  0.0176,  0.0080,  0.2606,  0.1024,\n",
      "         -0.4242],\n",
      "        [-0.2461,  0.4684,  0.3936, -0.2276, -0.0481,  0.1622,  0.2282, -0.1273,\n",
      "         -0.0740],\n",
      "        [-0.0160, -0.1475, -0.1481, -0.0984, -0.4170,  0.2270,  0.2920, -0.2880,\n",
      "         -0.3681],\n",
      "        [-0.2625,  0.3076, -0.2487, -0.0222, -0.1937,  0.5875, -0.2667, -0.1810,\n",
      "         -0.2084],\n",
      "        [ 0.0686, -0.2583, -0.3274, -0.3542, -0.1995,  0.5296, -0.1789, -0.0273,\n",
      "          0.5106],\n",
      "        [-0.1384, -0.3742,  0.2935,  0.1824,  0.2869,  0.3403, -0.2070, -0.1171,\n",
      "         -0.5292],\n",
      "        [ 0.1537,  0.0734,  0.0665,  0.5696, -0.2750, -0.2819,  0.6124,  0.4315,\n",
      "         -0.0056],\n",
      "        [-0.5263, -0.3938,  0.5159, -0.2003, -0.1781,  0.2627,  0.0844,  0.1046,\n",
      "         -0.1028],\n",
      "        [ 0.6208, -0.0547,  0.0175,  0.0350,  0.0105,  0.4303, -0.0899,  0.4127,\n",
      "          0.3131],\n",
      "        [-0.2671,  0.1399, -0.0475, -0.2122, -0.1897,  0.2687,  0.7497,  0.2046,\n",
      "          0.2487],\n",
      "        [ 0.1426,  0.1589, -0.1551, -0.4957,  0.1720, -0.1388, -0.1442,  0.5660,\n",
      "         -0.6110],\n",
      "        [-0.4371,  0.1140,  0.2804, -0.2098,  0.3050, -0.0335, -0.0360,  0.2226,\n",
      "         -0.2088],\n",
      "        [ 0.2179, -0.2317, -0.1633, -0.1614,  0.1989, -0.5329, -0.2887, -0.0671,\n",
      "         -0.1584],\n",
      "        [-0.2262,  0.5371, -0.1831, -0.4412, -0.1809, -0.0609,  0.4453, -0.1061,\n",
      "         -0.1264],\n",
      "        [ 0.0216, -0.2840,  0.0495, -0.1428,  0.0058,  0.0528,  0.1312,  0.0453,\n",
      "          0.2298]], requires_grad=True)\n",
      "1 Parameter containing:\n",
      "tensor([[-3.5306e-01,  3.6127e-01,  2.5033e-01,  1.0293e-01, -4.7069e-01,\n",
      "         -4.0175e-01,  3.9446e-02, -5.5371e-01,  3.0281e-01, -9.6288e-02,\n",
      "          2.9942e-01, -7.5727e-02, -2.1255e-01, -6.7340e-01, -5.6563e-01,\n",
      "          3.6508e-01,  1.2544e-01,  3.5772e-01, -3.1389e-02,  9.6473e-02,\n",
      "          1.4282e-01, -7.1527e-01, -5.4998e-01,  3.9139e-01, -3.9898e-01,\n",
      "         -3.1445e-01, -3.9288e-02],\n",
      "        [-3.6834e-01,  2.1037e-01, -7.9732e-01, -5.1547e-02, -2.0924e-01,\n",
      "         -4.2161e-01,  4.4060e-01, -2.9551e-01,  4.4352e-01, -5.1383e-01,\n",
      "          3.8321e-01,  2.2870e-01,  4.2500e-02, -1.8875e-01,  1.4795e-02,\n",
      "          1.4355e-01, -3.5410e-01, -1.7934e-01,  7.8253e-02,  1.2942e-01,\n",
      "         -1.4445e-02, -1.4667e-01, -4.1848e-02,  2.6173e-01,  5.7025e-02,\n",
      "          2.2605e-01, -2.8250e-01],\n",
      "        [-1.6331e-01,  5.7217e-01,  1.4910e-01,  1.1589e-01,  1.7434e-01,\n",
      "         -1.7907e-01, -3.8710e-01, -8.2168e-01, -8.4598e-02, -6.1097e-02,\n",
      "         -4.6584e-01, -3.3378e-01,  5.5118e-01, -1.4803e-01,  7.6238e-02,\n",
      "          5.7096e-01, -4.0569e-01, -3.6000e-02, -3.3175e-02, -2.4617e-01,\n",
      "         -3.3348e-02, -5.7888e-02, -2.5850e-01,  1.8671e-01, -7.2827e-01,\n",
      "         -3.1528e-02, -9.1882e-02],\n",
      "        [-1.0590e-01,  1.7717e-01,  7.3432e-02, -4.9210e-01,  3.3703e-01,\n",
      "         -1.6783e-01,  1.6441e-01, -7.0772e-01, -4.9592e-02,  3.8716e-02,\n",
      "          1.6554e-01, -2.8409e-01,  1.1980e-01,  9.0716e-02, -8.9981e-02,\n",
      "         -4.1114e-01, -3.4862e-01,  2.0685e-03,  2.6365e-01, -1.2396e-01,\n",
      "         -3.0995e-01, -6.7246e-02, -2.9354e-01,  4.9636e-01, -1.6874e-01,\n",
      "         -1.5765e-01,  1.2839e-01],\n",
      "        [ 2.0629e-01, -3.4543e-01, -1.6079e-01, -1.7225e-01,  3.1847e-01,\n",
      "         -3.4027e-01, -2.4735e-01, -7.4394e-01, -7.8718e-02, -7.0275e-01,\n",
      "         -4.4768e-01,  3.3385e-02,  2.4231e-01, -1.9927e-01,  4.2023e-01,\n",
      "          3.1844e-01,  6.1031e-01,  6.0118e-01,  5.4616e-01, -1.3882e-01,\n",
      "         -4.7111e-01,  1.2121e-01, -7.2486e-01, -1.7082e-01,  6.1149e-02,\n",
      "         -4.0321e-01,  1.4667e-01],\n",
      "        [-3.7576e-01, -3.7614e-02, -3.1744e-01,  4.5434e-01,  2.7344e-01,\n",
      "         -2.5318e-03, -4.6582e-02,  1.0419e-01, -4.7823e-01, -2.2454e-01,\n",
      "          2.2229e-01,  1.4510e-01, -2.7219e-01,  2.7559e-01,  3.8351e-01,\n",
      "          9.1848e-02, -2.7285e-01,  1.7400e-01, -1.8471e-01,  8.4518e-02,\n",
      "          2.3659e-01, -3.3002e-02, -3.1404e-03,  1.0812e-01, -1.4370e-01,\n",
      "         -1.4720e-01, -3.4489e-01],\n",
      "        [ 5.0572e-01, -2.0467e-01,  3.5837e-01, -1.1374e-01, -2.6364e-01,\n",
      "         -1.9468e-01,  1.6221e-01, -7.7050e-01,  4.1882e-01, -1.2434e-01,\n",
      "         -3.7020e-01, -4.0635e-01,  7.8266e-02,  3.7813e-01, -1.4757e-01,\n",
      "         -1.8856e-01, -3.0070e-01,  1.1894e-01, -9.0424e-02,  2.0547e-01,\n",
      "         -2.7405e-01, -2.2123e-01, -1.4263e-01, -1.5285e-01,  3.0608e-01,\n",
      "         -4.9813e-01,  1.4992e-05],\n",
      "        [-2.9155e-01, -1.4095e-01,  8.7267e-02,  1.0573e-01, -9.0605e-01,\n",
      "         -1.6683e-01,  2.4899e-02,  1.8679e-01,  2.6835e-01, -3.7158e-01,\n",
      "          2.5805e-01,  8.8418e-02, -7.7374e-02, -1.7334e-01,  1.7832e-01,\n",
      "         -8.4045e-02,  2.6387e-01,  2.1638e-01, -3.7461e-01,  2.2669e-01,\n",
      "         -2.7184e-01, -6.6841e-02, -7.2854e-01, -2.3532e-01,  4.2312e-01,\n",
      "         -2.6609e-01, -3.3969e-01],\n",
      "        [ 1.5235e-02, -1.0132e-01,  2.5013e-02, -1.2127e-01, -1.5446e-01,\n",
      "          7.1720e-01, -3.8493e-01, -2.8001e-01, -3.2214e-01, -3.4981e-01,\n",
      "          2.2988e-01, -1.6845e-01, -2.9294e-01,  8.8717e-02,  2.4792e-02,\n",
      "          9.4754e-02,  3.8839e-01, -3.2329e-01, -4.9420e-01,  4.0616e-01,\n",
      "         -1.2149e-02,  4.1878e-02, -6.1777e-01, -9.6023e-02, -8.1472e-02,\n",
      "         -6.5095e-01, -4.0456e-01],\n",
      "        [ 9.9100e-02, -1.2151e-01,  3.1207e-01, -3.7657e-01,  5.7150e-01,\n",
      "          1.9484e-01, -5.1298e-01, -2.3133e-01, -1.1128e-01,  1.4733e-01,\n",
      "         -3.0823e-01,  2.2095e-01, -2.0441e-01, -4.1821e-01,  2.2076e-01,\n",
      "          1.1021e-01, -4.4879e-01,  1.8176e-01, -6.0580e-01, -2.9524e-02,\n",
      "          2.7634e-01,  3.3852e-01,  1.6087e-01,  3.2323e-02, -3.2485e-01,\n",
      "          3.9700e-01,  3.6555e-02],\n",
      "        [ 1.1978e-01, -8.3744e-02,  1.8821e-01,  1.4321e-01, -2.4900e-01,\n",
      "          1.5373e-01, -1.2121e-01,  1.4657e-01, -5.6968e-01, -1.1708e-01,\n",
      "          1.6905e-01,  1.4712e-01, -4.7492e-01,  1.0808e-01, -2.8630e-01,\n",
      "          4.3264e-01, -9.1499e-03,  1.4084e-01, -2.2283e-01,  1.6854e-01,\n",
      "          3.3429e-01, -7.3813e-01, -4.4283e-03,  5.1434e-01, -3.2470e-01,\n",
      "          3.3850e-02, -3.3411e-01],\n",
      "        [ 5.0367e-01,  4.9192e-01,  1.5522e-01,  2.1565e-01, -9.2392e-02,\n",
      "          2.1661e-01,  5.7174e-02, -1.4076e-01,  4.0397e-01, -4.9689e-01,\n",
      "          1.0731e-01, -1.1807e-01,  1.1884e-01, -2.2918e-01, -3.6622e-01,\n",
      "         -1.4543e-01, -1.8848e-01,  7.6713e-01, -1.8768e-02,  2.5693e-01,\n",
      "          4.6526e-01,  7.0988e-02,  2.4047e-01,  1.2102e-01, -5.4719e-01,\n",
      "          1.1414e-01, -1.6971e-01],\n",
      "        [-4.6705e-01,  3.1698e-01,  1.2823e-01, -1.6898e-01,  4.8698e-01,\n",
      "          1.7150e-01,  8.9660e-02, -2.4093e-01, -1.0191e-01, -1.5028e-01,\n",
      "         -1.3515e-02, -7.9084e-01, -1.5426e-01,  8.5662e-01,  8.2616e-02,\n",
      "         -2.4980e-02,  2.5438e-01, -1.3867e-01,  7.5944e-02,  9.8971e-02,\n",
      "          3.5919e-01,  2.9350e-01, -5.8796e-01, -3.7216e-02, -5.7448e-02,\n",
      "         -1.4509e-01, -3.6249e-01],\n",
      "        [-8.8960e-02, -8.3963e-02, -3.0209e-01,  1.8726e-01, -3.4614e-01,\n",
      "         -2.4468e-01, -3.5216e-01, -2.5399e-01, -1.9245e-01, -1.3233e-01,\n",
      "         -7.1775e-01, -2.3754e-01, -7.7902e-02,  6.2220e-01, -1.8393e-01,\n",
      "          2.7006e-03,  8.1263e-02, -3.5372e-01, -9.8768e-01, -3.9787e-02,\n",
      "         -4.7233e-01,  1.7587e-01,  2.0270e-02,  1.3339e-01, -2.7361e-01,\n",
      "         -3.5736e-01, -2.0034e-01],\n",
      "        [ 1.2620e-01, -9.3815e-02, -4.1998e-03,  2.9091e-01, -5.1644e-01,\n",
      "          6.0080e-01,  2.4157e-01, -3.1208e-01,  4.4068e-01,  8.5184e-02,\n",
      "          1.5412e-01,  2.8395e-01, -1.3612e-01, -5.7789e-02, -1.5988e-01,\n",
      "          2.1393e-01, -1.5865e-01, -6.6731e-02, -1.0312e-01, -2.0385e-02,\n",
      "          1.3995e-01, -5.1470e-01, -7.4445e-01,  2.2755e-01, -5.6245e-01,\n",
      "         -3.1755e-01, -8.8003e-02],\n",
      "        [ 1.7984e-01,  7.2602e-02,  7.1254e-01, -2.3169e-01, -1.5257e-01,\n",
      "          4.1325e-01,  6.5898e-02, -1.6424e-01,  1.3245e-01, -5.2976e-01,\n",
      "          1.2455e-01,  2.1548e-01, -8.1124e-02, -1.7306e-01, -3.0107e-01,\n",
      "         -3.0677e-01,  1.3501e-01,  1.6700e-01, -2.0958e-01, -4.5271e-01,\n",
      "          4.7869e-01, -5.9801e-01,  3.7355e-02,  1.9880e-01, -1.8551e-02,\n",
      "          1.7411e-02, -2.0727e-01],\n",
      "        [-4.3810e-02, -6.0998e-01, -7.0783e-03, -4.0305e-01, -8.0984e-03,\n",
      "          1.3580e-01, -2.5255e-02, -2.1762e-01,  5.1524e-01, -2.8178e-01,\n",
      "          5.1078e-01, -4.7080e-01,  2.8661e-02,  7.8269e-02, -6.0080e-03,\n",
      "          2.2878e-01, -3.8196e-01, -4.6898e-01, -5.2982e-02,  9.1661e-02,\n",
      "         -1.5930e-01,  7.0346e-02,  2.6966e-01,  3.1195e-01,  3.0401e-01,\n",
      "         -1.0272e-01,  3.5358e-01],\n",
      "        [-2.9834e-01,  3.2913e-01,  5.3449e-02,  4.7757e-01,  1.4460e-01,\n",
      "          7.2623e-02, -4.1609e-01, -1.5212e-01,  1.1953e-01,  1.2463e-01,\n",
      "         -3.3317e-02, -3.1420e-01, -2.7574e-01,  4.1435e-01, -5.8137e-02,\n",
      "         -4.7105e-02, -5.6556e-02, -4.4225e-01, -2.2225e-01, -3.7713e-01,\n",
      "          2.2929e-01,  2.2695e-01, -4.4059e-01,  1.3231e-01, -2.3355e-01,\n",
      "         -1.3423e-01, -1.6928e-02]], requires_grad=True)\n",
      "2 Parameter containing:\n",
      "tensor([[ 0.3840,  0.8335,  0.4881,  0.3722,  0.3385,  0.7990,  0.3373,  0.2727,\n",
      "          0.7436],\n",
      "        [ 0.7922,  0.9761,  0.2594,  0.6451,  0.0974,  1.4175,  0.4836,  0.5142,\n",
      "          0.4424],\n",
      "        [ 0.6315,  0.3966,  0.5370,  0.7790,  0.5992,  1.0594,  0.7238,  0.6136,\n",
      "          0.3425],\n",
      "        [ 0.1573,  1.1292,  0.0867,  0.2088,  0.1810,  0.4855,  0.4453,  0.8365,\n",
      "          0.4634],\n",
      "        [ 0.8174,  0.3035,  0.8955,  0.5317,  0.2071,  0.6415,  0.5627,  0.6978,\n",
      "          0.2932],\n",
      "        [ 0.4367,  0.1986,  0.7490,  0.1960,  0.7632,  0.1888,  0.5114,  0.1736,\n",
      "          0.4386],\n",
      "        [ 0.9223,  0.4740,  0.7021,  0.1678,  0.8130,  0.5831,  0.7893,  0.6940,\n",
      "          0.8510],\n",
      "        [-0.2999,  0.1708, -0.1272,  0.3986,  0.9352,  0.7378,  0.2461,  0.0362,\n",
      "         -0.1811],\n",
      "        [ 0.7084,  0.6435,  0.5279,  0.1787,  0.6807,  0.9045,  0.6179,  0.3460,\n",
      "          0.3632],\n",
      "        [ 0.1908, -0.1602, -0.1506,  0.1924, -0.0302, -0.0637,  0.1530,  0.0110,\n",
      "         -0.0922],\n",
      "        [ 0.7487,  0.9982,  0.4245,  0.2546,  1.0780,  0.1160,  0.2578,  0.4941,\n",
      "          0.4653],\n",
      "        [ 0.2695,  0.8284,  0.7118,  0.5910,  0.6522,  0.5210,  0.5457, -0.0210,\n",
      "          0.5441],\n",
      "        [ 0.6559,  0.5154,  0.7523,  0.7355,  0.3923,  0.8267,  0.5394,  0.4219,\n",
      "          0.7968],\n",
      "        [ 0.9731,  0.7444,  0.6925,  0.4716,  0.0034,  0.8993,  0.1642,  0.4901,\n",
      "          0.7979],\n",
      "        [ 0.4105,  0.4148,  0.4479,  0.8030,  0.7485,  0.4343,  0.6308,  0.2571,\n",
      "          0.0452],\n",
      "        [ 0.8284,  0.7122,  0.3989,  0.6268,  0.2472,  0.1995,  0.1570,  0.4418,\n",
      "          0.9280],\n",
      "        [ 0.6342,  0.6322,  0.8154,  0.4310,  0.8127,  1.0464,  0.8884,  0.6391,\n",
      "          0.9368],\n",
      "        [ 0.5234,  0.1144,  0.6267,  0.6867,  0.8576,  0.2525,  0.4603,  0.5045,\n",
      "          0.4260],\n",
      "        [ 0.0766,  0.6956,  0.5770,  0.9483,  0.8218,  0.9197,  0.4049,  0.4190,\n",
      "          0.0228],\n",
      "        [ 0.3071,  0.6668,  0.7815,  0.0020,  0.4844, -0.1177,  0.6127,  0.4987,\n",
      "          0.4436],\n",
      "        [ 0.9800,  0.7669,  0.6107,  0.8088,  0.1620,  0.4650,  0.6720,  0.8882,\n",
      "          0.8257],\n",
      "        [ 0.6264,  0.6801,  0.5981,  0.6965,  0.1561,  0.8672,  1.0646,  0.4172,\n",
      "          0.9990],\n",
      "        [ 0.4347,  0.7977,  0.7902,  0.8665,  1.0289,  0.9048,  0.7809,  0.7310,\n",
      "          0.5138],\n",
      "        [ 0.3140,  0.8310, -0.0173,  0.2494,  0.2724,  0.6356,  0.6700,  0.1729,\n",
      "          0.4550],\n",
      "        [ 0.6424,  0.3915,  0.5557,  0.7429,  0.4831,  0.6846,  0.6878,  0.5029,\n",
      "          0.7147],\n",
      "        [ 0.2449,  0.2082,  0.5219,  0.9374,  0.4808,  0.2981,  0.5781,  0.4055,\n",
      "          0.6797],\n",
      "        [ 0.1378,  0.2585,  0.6723,  0.6969,  0.9152,  0.5157, -0.1259,  0.4362,\n",
      "          0.1169]], requires_grad=True)\n",
      "3 Parameter containing:\n",
      "tensor([[ 2.6460e-01,  8.3272e-01,  8.0305e-01,  4.1190e-01,  6.2342e-01,\n",
      "          5.1238e-01,  3.0582e-01,  2.2675e-01,  9.7834e-01,  5.4299e-01,\n",
      "          7.2659e-01, -1.1013e-01,  5.9068e-01,  4.5797e-01,  1.8492e-01,\n",
      "          5.0305e-01,  7.5490e-01,  2.3557e-01,  1.1363e-01,  7.6668e-01,\n",
      "          2.1663e-01,  8.4505e-01,  1.0259e+00,  7.5692e-01,  4.6026e-01,\n",
      "          7.8449e-01,  7.3362e-01],\n",
      "        [ 8.2593e-01,  7.5120e-01,  6.4061e-01,  4.1762e-01,  7.5465e-02,\n",
      "          1.7771e-01,  1.9133e-01,  6.8764e-01,  5.9749e-01,  8.1093e-01,\n",
      "          1.2302e+00,  4.8017e-01,  1.0097e+00,  1.9776e-01, -7.1019e-02,\n",
      "          5.7500e-01,  1.3388e+00,  4.0388e-01,  2.4126e-01,  7.2931e-01,\n",
      "          7.5263e-01,  1.1874e-01,  3.8866e-01,  6.0279e-01,  5.8294e-01,\n",
      "          1.5167e+00,  4.0773e-01],\n",
      "        [ 3.3675e-01,  7.0031e-01,  2.4947e-01,  3.4043e-01,  1.6490e-01,\n",
      "          3.2702e-01,  6.0249e-01,  7.9644e-01,  3.0356e-01,  6.9460e-01,\n",
      "          6.0017e-01,  1.3110e-01,  3.9367e-01,  7.4831e-01,  1.1165e+00,\n",
      "          3.1441e-01,  6.4675e-01,  2.5913e-01,  3.0345e-01,  6.0446e-01,\n",
      "          1.1731e+00,  9.3639e-01,  2.3281e-01,  9.3327e-01,  8.3431e-01,\n",
      "          6.0328e-01,  5.8766e-01],\n",
      "        [ 1.2349e-01,  4.6259e-01,  7.2514e-01,  5.2218e-01,  6.9792e-01,\n",
      "          4.4562e-01,  5.2132e-01,  1.2991e+00,  6.0424e-01,  8.5100e-01,\n",
      "          3.6267e-01, -1.7435e-01,  2.9175e-01,  5.1129e-01,  5.4340e-01,\n",
      "          3.5876e-01,  1.2917e+00,  4.7493e-01,  7.5802e-01,  5.1817e-01,\n",
      "          1.8554e-01,  5.1041e-01,  2.5313e-01,  5.6720e-01,  5.3705e-01,\n",
      "          4.6225e-01,  6.8640e-02],\n",
      "        [ 3.9543e-01,  6.7208e-01,  6.6262e-01,  6.2369e-01,  9.4523e-01,\n",
      "          4.7797e-01,  5.5430e-01,  8.4129e-01,  3.8818e-01,  9.7753e-01,\n",
      "          2.9370e-01,  7.5940e-01,  5.7721e-01,  6.4264e-01,  2.0236e-01,\n",
      "          1.0172e+00,  1.0527e+00,  6.5073e-01,  9.8021e-01,  4.5494e-01,\n",
      "          9.2414e-01,  1.7268e-01,  2.8419e-01,  5.1549e-01,  3.8427e-01,\n",
      "          8.9875e-01,  1.0481e-01],\n",
      "        [ 4.8299e-01,  8.3870e-04,  3.8954e-01,  5.5282e-01,  9.8892e-01,\n",
      "          7.3728e-01,  9.2834e-01,  5.9204e-01,  5.4260e-01,  1.0050e+00,\n",
      "          6.4920e-01,  4.2947e-01,  6.9091e-01,  4.1301e-01,  4.0894e-01,\n",
      "          3.4561e-01,  8.0825e-01,  1.7256e-01,  5.9387e-01,  5.0742e-01,\n",
      "          5.4684e-01,  3.5113e-01,  8.6849e-01,  7.9438e-01,  7.5690e-01,\n",
      "          6.4556e-01,  5.8165e-01],\n",
      "        [ 6.2806e-01,  4.0151e-01,  3.2942e-01,  3.5701e-01,  2.9196e-01,\n",
      "          5.8076e-01,  3.6201e-01,  6.1993e-01,  7.4735e-01,  1.8824e-01,\n",
      "          7.7525e-01,  6.9501e-01, -4.4240e-02,  1.2107e-01,  5.5168e-01,\n",
      "          9.5383e-01,  9.4178e-01,  1.1799e+00,  5.8036e-01,  7.4959e-01,\n",
      "          5.0366e-01, -2.4111e-03,  8.4610e-01,  3.8340e-01,  8.6834e-01,\n",
      "          6.5671e-01,  4.1976e-01],\n",
      "        [ 2.1572e-01,  8.6355e-03,  8.8995e-02,  4.7534e-02,  9.4365e-01,\n",
      "          7.5556e-02,  3.7032e-01,  5.4045e-01,  7.4876e-01,  1.5279e-01,\n",
      "          7.3891e-02,  4.5364e-01,  6.3412e-01,  5.6122e-01,  5.6485e-02,\n",
      "          1.0529e+00,  7.4969e-01,  1.0941e-01,  3.5374e-01,  1.8741e-01,\n",
      "          8.6151e-01,  4.4364e-01,  7.1106e-01, -9.2345e-02,  9.0541e-01,\n",
      "          4.8975e-01,  6.0466e-01],\n",
      "        [ 1.8454e-01,  1.4091e-01,  1.1120e+00,  4.4378e-01, -5.6051e-02,\n",
      "          4.9458e-01,  1.5967e-01,  6.6754e-01,  3.4754e-01,  3.4554e-01,\n",
      "          3.3079e-01,  6.1314e-01,  3.9749e-01,  4.4601e-01,  6.9806e-01,\n",
      "          7.9393e-01,  1.1288e+00,  2.6731e-01,  7.2483e-01,  9.1928e-01,\n",
      "          4.6037e-01,  6.7246e-02,  4.1521e-01,  6.0281e-01,  8.8144e-01,\n",
      "          5.3441e-01,  1.9451e-01],\n",
      "        [ 7.1659e-01,  7.8480e-01,  9.5253e-01,  9.3910e-01,  5.3606e-01,\n",
      "          7.1006e-01,  4.9107e-01,  9.9434e-01, -2.7956e-02,  1.5658e-01,\n",
      "          7.6559e-01, -3.9008e-02,  8.3021e-01,  6.4364e-01,  2.1094e-01,\n",
      "          1.0671e+00,  7.7634e-01,  9.4941e-01,  5.5881e-01,  6.1949e-01,\n",
      "          9.1848e-01,  3.7829e-01,  8.6898e-01,  5.6797e-01,  5.5710e-01,\n",
      "          1.1977e+00, -1.5755e-01],\n",
      "        [ 9.1446e-01,  5.0858e-01, -2.8979e-01,  5.4718e-01,  1.9472e-01,\n",
      "          3.1380e-01, -2.4767e-01,  5.6286e-01,  4.9322e-01,  3.4824e-01,\n",
      "          9.2575e-02,  4.4256e-01,  5.2002e-01,  1.2273e-01,  7.6967e-01,\n",
      "          4.3968e-01, -8.8078e-02,  6.5521e-01,  1.3073e-02,  6.0661e-01,\n",
      "          4.6285e-01,  6.6447e-01,  6.9827e-01, -1.1254e-01,  5.4254e-01,\n",
      "          1.9128e-01,  4.4734e-01],\n",
      "        [ 1.1539e-01,  4.2155e-01,  9.1020e-01,  1.7368e-01,  4.9185e-01,\n",
      "          3.2470e-01,  4.8308e-01,  3.8631e-01,  3.9642e-01,  3.4592e-01,\n",
      "          2.7792e-01,  4.2121e-01,  4.9708e-01,  6.0006e-01,  5.6467e-01,\n",
      "          3.9020e-01,  7.5823e-01,  8.4215e-01,  9.0378e-01,  4.6416e-01,\n",
      "          6.0895e-01,  7.4806e-01,  7.0456e-01,  1.1048e+00,  2.8638e-01,\n",
      "          4.9115e-01,  4.5475e-01],\n",
      "        [ 7.8502e-01,  3.4486e-01,  4.3062e-01,  4.6989e-01,  2.1886e-01,\n",
      "          4.7877e-01,  7.6127e-01,  4.2083e-01,  7.4704e-01,  4.7256e-01,\n",
      "          1.0011e+00,  7.4919e-01,  4.2879e-01,  2.9933e-01,  5.4371e-01,\n",
      "          5.5090e-01,  2.0877e-01,  1.0649e+00,  5.4336e-01,  3.6952e-01,\n",
      "          2.7847e-01,  3.3009e-01,  6.4223e-01,  8.1118e-01,  4.0484e-01,\n",
      "          2.7726e-01,  5.2126e-01],\n",
      "        [ 6.9281e-01,  4.1716e-01,  7.8025e-01,  1.3541e+00,  3.8975e-01,\n",
      "          4.7088e-01,  1.1892e-01,  8.7589e-01,  1.8280e-01,  9.3098e-02,\n",
      "          3.6283e-01,  1.0106e+00,  4.1802e-01, -3.5386e-01, -3.3723e-02,\n",
      "          3.3852e-01,  5.8105e-01,  2.0099e-01,  7.6157e-01,  3.0801e-01,\n",
      "         -8.8231e-02,  7.6365e-01,  3.9299e-01,  4.2358e-01,  8.5927e-01,\n",
      "          4.7105e-01,  6.2977e-01],\n",
      "        [ 1.0226e+00,  4.3280e-01,  4.4155e-01,  6.4355e-01,  8.0037e-01,\n",
      "          1.9123e-01,  2.4582e-01,  6.9551e-01,  1.9569e-01,  7.4802e-01,\n",
      "          6.3309e-01,  1.1373e+00,  6.1112e-01,  8.2405e-02,  1.5596e-01,\n",
      "          1.6913e-01,  2.7559e-01,  2.8148e-01,  3.8383e-01,  2.8493e-01,\n",
      "          7.6508e-01,  7.4332e-01,  5.1116e-01,  6.2022e-01,  7.0601e-01,\n",
      "         -1.9018e-01,  9.2204e-01],\n",
      "        [ 5.7669e-01,  9.6392e-02,  2.8391e-01,  6.4578e-01,  2.7805e-01,\n",
      "          5.7501e-01,  7.3728e-01,  4.2774e-01,  7.7706e-01,  1.1842e+00,\n",
      "          4.8706e-01, -8.8313e-02, -3.0166e-01,  3.1419e-01,  3.3094e-01,\n",
      "          2.9231e-01,  8.2426e-01,  3.2843e-01,  4.1082e-01,  2.8454e-01,\n",
      "          5.5776e-01,  1.0261e+00,  5.2353e-01,  5.7947e-01,  5.5562e-01,\n",
      "         -1.0706e-01,  8.1981e-01],\n",
      "        [ 6.5399e-01,  3.2218e-01,  4.1393e-01,  4.5069e-01,  5.8047e-01,\n",
      "          2.2291e-01,  5.6872e-01,  6.3740e-01,  7.3572e-01,  5.6078e-01,\n",
      "          6.8017e-01,  6.8666e-01,  1.7791e-01,  7.0868e-01,  6.0260e-01,\n",
      "          1.0620e+00,  7.7048e-01,  4.6097e-01,  1.6810e-01,  4.8136e-01,\n",
      "          7.4296e-01,  5.7723e-01,  9.9516e-01,  5.3383e-01,  5.5370e-01,\n",
      "          7.0363e-01,  1.5387e-01],\n",
      "        [ 5.5741e-01,  4.2394e-01,  2.9005e-01,  5.7374e-01, -1.3511e-01,\n",
      "          4.3151e-01,  1.0003e+00,  5.5214e-01,  3.9157e-01,  1.1215e+00,\n",
      "          4.5699e-01,  1.9555e-01,  3.9621e-01,  1.0197e-01,  2.1910e-01,\n",
      "          3.9665e-01,  2.8388e-01,  7.9566e-01,  6.8047e-01,  3.9019e-01,\n",
      "         -4.3812e-02,  4.3466e-01, -1.5161e-01,  5.8795e-01,  5.9643e-01,\n",
      "          1.8933e-01,  5.6075e-01]], requires_grad=True)\n",
      "4 Parameter containing:\n",
      "tensor([[ 0.2867,  0.7195, -0.1917, -0.0969,  0.0661,  0.4451,  0.3685, -0.0583,\n",
      "          0.7458,  0.3905,  0.6607,  0.5281,  0.7443,  0.3417,  0.0739,  0.6344,\n",
      "          0.2325,  0.6511,  0.6870,  0.8509,  0.0534, -0.0226,  0.1840,  0.2289,\n",
      "          0.3152,  0.4273,  0.1647,  0.3978,  0.2943, -0.3297,  0.4541,  0.2122,\n",
      "         -0.0395,  0.7521,  0.6149,  0.1358]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(list(models[0].parameters()) + list(models[1].parameters())):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdfcd6-00c4-4813-bb17-29d5a86bd8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
