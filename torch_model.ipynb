{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58491147-580d-409e-aedf-2d49997dfea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric\n",
      "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting aiohttp (from torch-geometric)\n",
      "  Using cached aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: fsspec in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (2024.12.0)\n",
      "Requirement already satisfied: jinja2 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (6.0.0)\n",
      "Requirement already satisfied: pyparsing in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: requests in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from torch-geometric) (2.32.3)\n",
      "Collecting tqdm (from torch-geometric)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch-geometric)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch-geometric)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from aiohttp->torch-geometric) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch-geometric)\n",
      "  Using cached propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch-geometric)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from jinja2->torch-geometric) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniil/project/PageR/env/lib/python3.12/site-packages (from requests->torch-geometric) (2024.8.30)\n",
      "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Using cached aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Using cached propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "Installing collected packages: tqdm, propcache, multidict, frozenlist, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch-geometric\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 frozenlist-1.5.0 multidict-6.1.0 propcache-0.2.1 torch-geometric-2.6.1 tqdm-4.67.1 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f8ed93-0f7e-4ded-8b2a-73e2374eb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import relu, sigmoid, binary_cross_entropy\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56272de-cf3d-409c-87a2-ee7fcb82fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self,  layers):\n",
    "        super(GNN, self).__init__()\n",
    "        convs = []\n",
    "        Bs = []\n",
    "        for l_in, l_out in zip(layers[:-1], layers[1:]):\n",
    "            convs.append(GCNConv(l_in, l_out, bias=False))\n",
    "            torch.nn.init.normal_(convs[-1].lin.weight,mean=0.01, std=0.3)\n",
    "            Bs.append(torch.nn.Linear(l_in, l_out, bias=False))\n",
    "            torch.nn.init.normal_(Bs[-1].weight, mean=0.5, std=0.3)\n",
    "        self.convs = torch.nn.ModuleList(convs)\n",
    "        self.Bs = torch.nn.ModuleList(Bs)\n",
    "\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        for conv, B in zip(self.convs, self.Bs):\n",
    "            x = conv(x, edge_index) -  B(x)\n",
    "            x = relu(x)\n",
    "        return x\n",
    "\n",
    "class EdgesMLP(torch.nn.Module):\n",
    "    def __init__(self, l3):\n",
    "        super(EdgesMLP, self).__init__()\n",
    "        self.linear = Linear(2*l3, 1, bias=False)\n",
    "        torch.nn.init.normal_(self.linear.weight, mean=0.5, std=0.3)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear(x)\n",
    "        return torch.squeeze(sigmoid(x), 1)\n",
    "\n",
    "def get_models(params):\n",
    "    layers = params[\"count_neuron_layers\"]\n",
    "    node_gnn = GNN(layers)\n",
    "    edge_linear = EdgesMLP(layers[-1])\n",
    "    return node_gnn, edge_linear\n",
    "\n",
    "def list_batchs(dataset, batch_size):\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        yield dataset[i:i+batch_size]\n",
    "\n",
    "def get_tensor_from_graph(graph):\n",
    "    i = graph[\"A\"]\n",
    "    v_in = [rev_dist(e) for e in graph[\"edges_feature\"]]\n",
    "    v_true = graph[\"true_edges\"]\n",
    "    x = graph[\"nodes_feature\"]\n",
    "    N = len(x)\n",
    "    \n",
    "    X = torch.tensor(data=x, dtype=torch.float32)\n",
    "    sp_A = torch.sparse_coo_tensor(indices=i, values=v_in, size=(N, N), dtype=torch.float32)\n",
    "    E_true = torch.tensor(data=v_true, dtype=torch.float32)\n",
    "    return X, sp_A, E_true, i\n",
    "\n",
    "def validation(models, dataset, criterion):\n",
    "    my_loss_list = []\n",
    "    for j, graph in enumerate(dataset):\n",
    "        X, sp_A, E_true, i = get_tensor_from_graph(graph)\n",
    "        H_end = models[0](X, sp_A)\n",
    "        Omega = torch.cat([H_end[i[0]], H_end[i[1]]],dim=1)\n",
    "        E_pred = models[1](Omega)\n",
    "        loss = criterion(E_pred, E_true)\n",
    "        my_loss_list.append(loss.item())\n",
    "        print(f\"{(j+1)/len(dataset)*100:.2f} % loss = {my_loss_list[-1]:.5f} {' '*30}\", end='\\r')\n",
    "    return np.mean(my_loss_list)\n",
    "\n",
    "def split_train_val(dataset, val_split=0.2, shuffle=True, seed=1234):\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        rng.shuffle(dataset)\n",
    "    train_size = int(len(dataset) * (1 - val_split))\n",
    "    train_dataset = dataset[:train_size]\n",
    "    val_dataset = dataset[train_size:]\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def train_step(models, batch, optimizer, criterion):\n",
    "    optimizer.zero_grad()\n",
    "    my_loss_list = []\n",
    "   \n",
    "    for j, graph in enumerate(batch):\n",
    "        X, sp_A, E_true, i = get_tensor_from_graph(graph)\n",
    "        H_end = models[0](X, sp_A)\n",
    "        Omega = torch.cat([H_end[i[0]], H_end[i[1]]],dim=1)\n",
    "        E_pred = models[1](Omega)\n",
    "        loss = criterion(E_pred, E_true)\n",
    "        my_loss_list.append(loss.item())\n",
    "        print(f\"Batch loss={my_loss_list[-1]:.4f}\" + \" \"*40, end=\"\\r\")\n",
    "        loss.backward()\n",
    "    optimizer.step()\n",
    "    return np.mean(my_loss_list)\n",
    "\n",
    "def train_model(params, models, dataset, path_save, save_frequency=5):  \n",
    "    optimizer = torch.optim.Adam(\n",
    "    list(models[0].parameters()) + list(models[1].parameters()),\n",
    "    lr=learning_rate,\n",
    "    )\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    loss_list = []\n",
    "    with open('log.txt', 'a') as f:\n",
    "        for key, val in params.items():\n",
    "            f.write(f\"{key}:\\t{val}\\n\")\n",
    "    train_dataset, val_dataset = split_train_val(dataset, val_split=0.1)\n",
    "    for k in range(params[\"epochs\"]):\n",
    "        my_loss_list = []\n",
    "        \n",
    "        for l, batch in enumerate(list_batchs(train_dataset, params[\"batch_size\"])):\n",
    "            batch_loss = train_step(models, batch, optimizer, criterion)\n",
    "            my_loss_list.append(batch_loss)\n",
    "            print(f\"Batch # {l+1} loss={my_loss_list[-1]:.4f}\" + \" \"*40)\n",
    "        train_val = np.mean(my_loss_list)\n",
    "        validation_val = validation(models, val_dataset, criterion)\n",
    "        print(\"=\"*10, f\"EPOCH #{k+1}\",\"=\"*10, f\"({train_val:.4f}/{validation_val:.4f})\")\n",
    "        with open('log.txt', 'a') as f:\n",
    "            f.write(f\"EPOCH #{k}\\t {train_val:.8f} (VAL: {validation_val:.8f})\\n\")  \n",
    "        if (k+1) % save_frequency == 0:\n",
    "            num = k//save_frequency\n",
    "            torch.save(models[0].state_dict(), path_save+f\"_node_gnn_{num}\")\n",
    "            torch.save(models[1].state_dict(), path_save+f\"_edge_linear_{num}\")\n",
    "    torch.save(models[0].state_dict(), path_save+f\"_node_gnn_end\")\n",
    "    torch.save(models[1].state_dict(), path_save+f\"_edge_linear_end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d873f8d-d98c-4325-9aac-3cc68cb7b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET INFO:\n",
      "count row: 11900\n",
      "first: dict_keys(['A', 'nodes_feature', 'edges_feature', 'true_edges'])\n",
      "\t A: (2, 925)\n",
      "\t nodes_feature: (451, 9)\n",
      "\t edges_feature: (925,)\n",
      "\t true_edges: (925,)\n",
      "end: dict_keys(['A', 'nodes_feature', 'edges_feature', 'true_edges'])\n",
      "\t A: (2, 1597)\n",
      "\t nodes_feature: (778, 9)\n",
      "\t edges_feature: (1597,)\n",
      "\t true_edges: (1597,)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# with open(\"../dataset.json\", \"r\") as f:\n",
    "#     dataset = json.load(f)['dataset']\n",
    "with open(\"/home/daniil/pager_11000_4N_seg.json\", \"r\") as f:\n",
    "    dataset = json.load(f)['dataset']\n",
    "\n",
    "print(\"DATASET INFO:\")\n",
    "print(\"count row:\", len(dataset))\n",
    "print(\"first:\", dataset[0].keys())\n",
    "print(f\"\\t A:\", np.shape(dataset[0][\"A\"]))\n",
    "print(f\"\\t nodes_feature:\", np.shape(dataset[0][\"nodes_feature\"]))\n",
    "print(f\"\\t edges_feature:\", np.shape(dataset[0][\"edges_feature\"]))\n",
    "print(f\"\\t true_edges:\", np.shape(dataset[0][\"true_edges\"]))\n",
    "print(\"end:\", dataset[-1].keys())\n",
    "print(f\"\\t A:\", np.shape(dataset[-1][\"A\"]))\n",
    "print(f\"\\t nodes_feature:\", np.shape(dataset[-1][\"nodes_feature\"]))\n",
    "print(f\"\\t edges_feature:\", np.shape(dataset[-1][\"edges_feature\"]))\n",
    "print(f\"\\t true_edges:\", np.shape(dataset[-1][\"true_edges\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5096a10-c1be-42c4-9a04-fc6d776ea7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_dist(a):\n",
    "    if a==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1/a\n",
    "        \n",
    "i = dataset[0][\"A\"]\n",
    "v_in = [rev_dist(e) for e in dataset[0][\"edges_feature\"]]\n",
    "v_true = dataset[0][\"true_edges\"]\n",
    "x = dataset[0][\"nodes_feature\"]\n",
    "N = len(x)\n",
    "\n",
    "X = torch.Tensor(x)\n",
    "sp_A = torch.sparse_coo_tensor(i, v_in, (N, N))\n",
    "E_true = torch.Tensor(v_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "84eb1c09-c6e5-4280-ac3e-b5763b89b46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_pred:\n",
      "tensor([0.8562, 0.9925, 0.9880, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8223, 0.5695,\n",
      "        0.9577, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9938, 0.6183,\n",
      "        0.8115, 0.9876, 0.9648, 0.9986, 0.9983, 0.9997, 0.9574, 0.9995, 0.9997,\n",
      "        0.9997, 0.9998, 0.9996, 0.9999, 0.9999, 0.8244, 0.9717, 0.8828, 0.9999,\n",
      "        1.0000, 0.9848, 0.9980, 0.9991, 0.9586, 0.9869, 1.0000, 1.0000, 1.0000,\n",
      "        0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9986, 0.9999, 0.9997, 1.0000, 0.9996, 1.0000, 0.9999, 1.0000, 1.0000,\n",
      "        0.9999, 1.0000, 1.0000, 1.0000, 0.9969, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 0.7629, 0.9984, 0.9922,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9991, 0.9994,\n",
      "        0.9994, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.6405, 0.5000, 0.5000, 0.9847, 0.7998, 1.0000, 0.9999,\n",
      "        1.0000, 1.0000, 0.9993, 0.9821, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5000, 0.6722, 0.9737,\n",
      "        0.6722, 0.5637, 1.0000, 0.9998, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9995, 0.9950, 0.9546, 1.0000, 0.9039, 0.7950, 0.6922, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8259,\n",
      "        1.0000, 0.9016, 0.9683, 0.9466, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9498, 0.8298, 0.9998, 0.9927, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5361, 0.6150,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.5000, 0.6150, 0.5000, 0.5000, 0.7427, 0.7141,\n",
      "        0.8697, 0.9160, 0.9999, 0.9949, 0.8915, 0.5000, 0.9840, 0.9898, 1.0000,\n",
      "        0.9970, 0.9211, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.6113, 0.5000, 0.7080, 0.9919, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5433, 0.9639, 0.5840, 1.0000,\n",
      "        0.9998, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9494, 0.5000, 1.0000, 0.9999,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5000, 0.7009, 0.5000, 0.5000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.7009, 0.5000, 0.9963, 0.8693, 1.0000, 0.9999, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.8703, 0.5572, 1.0000, 0.9979, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9476, 0.6105, 1.0000, 0.9994, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9295, 0.9995, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SqueezeBackward1>) \n",
      "E_true:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1.])\n",
      "Loss =  tensor(7.7927, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"count_neuron_layers\": [9, 27, 18],\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 500,\n",
    "}\n",
    "\n",
    "learning_rate = 0.005\n",
    "\n",
    "node_gnn, edge_linear = get_models(params)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(node_gnn.parameters()) + list(edge_linear.parameters()),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "H_end = node_gnn(X, sp_A)\n",
    "Omega = torch.cat([H_end[i[0]], H_end[i[1]]],dim=1)\n",
    "E_pred = edge_linear(Omega)\n",
    "print(f\"E_pred:\\n{E_pred}\", f\"\\nE_true:\\n{E_true}\")\n",
    "print(\"Loss = \", criterion(E_pred, E_true))\n",
    "\n",
    "del optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5e60566c-0723-4b95-810b-594ac69c22f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch # 1 loss=0.6904                                        \n",
      "Batch # 2 loss=0.6897                                        \n",
      "Batch # 3 loss=0.6885                                        \n",
      "Batch # 4 loss=0.6891                                        \n",
      "Batch # 5 loss=0.6883                                        \n",
      "Batch # 6 loss=0.6879                                        \n",
      "Batch # 7 loss=0.6882                                        \n",
      "Batch # 8 loss=0.6882                                        \n",
      "Batch # 9 loss=0.6888                                        \n",
      "Batch # 10 loss=0.6876                                        \n",
      "Batch # 11 loss=0.6910                                        \n",
      "Batch # 12 loss=0.6870                                        \n",
      "Batch # 13 loss=0.6881                                        \n",
      "Batch # 14 loss=0.6882                                        \n",
      "Batch # 15 loss=0.6869                                        \n",
      "Batch # 16 loss=0.6893                                        \n",
      "Batch # 17 loss=0.6855                                        \n",
      "Batch # 18 loss=0.6848                                        \n",
      "Batch # 19 loss=0.7022                                        \n",
      "Batch # 20 loss=0.6894                                        \n",
      "Batch # 21 loss=0.6907                                        \n",
      "Batch # 22 loss=0.6855                                        \n",
      "========== EPOCH #1 ========== (0.6889/0.6906)        \n",
      "Batch # 1 loss=0.6905                                        \n",
      "Batch # 2 loss=0.6897                                        \n",
      "Batch # 3 loss=0.6851                                        \n",
      "Batch # 4 loss=0.6825                                        \n",
      "Batch # 5 loss=0.6766                                        \n",
      "Batch # 6 loss=0.6727                                        \n",
      "Batch # 7 loss=0.6838                                        \n",
      "Batch # 8 loss=0.6787                                        \n",
      "Batch # 9 loss=0.6957                                        \n",
      "Batch # 10 loss=0.6800                                        \n",
      "Batch # 11 loss=0.6715                                        \n",
      "Batch # 12 loss=0.6663                                        \n",
      "Batch # 13 loss=0.6740                                        \n",
      "Batch # 14 loss=0.6747                                        \n",
      "Batch # 15 loss=0.6712                                        \n",
      "Batch # 16 loss=0.6750                                        \n",
      "Batch # 17 loss=0.6680                                        \n",
      "Batch # 18 loss=0.6638                                        \n",
      "Batch # 19 loss=0.6770                                        \n",
      "Batch # 20 loss=0.6788                                        \n",
      "Batch # 21 loss=0.6733                                        \n",
      "Batch # 22 loss=0.6488                                        \n",
      "========== EPOCH #2 ========== (0.6763/0.6663)        \n",
      "Batch # 1 loss=0.6603                                        \n",
      "Batch # 2 loss=0.6624                                        \n",
      "Batch # 3 loss=0.6547                                        \n",
      "Batch # 4 loss=0.6515                                        \n",
      "Batch # 5 loss=0.6436                                        \n",
      "Batch # 6 loss=0.6382                                        \n",
      "Batch # 7 loss=0.6334                                        \n",
      "Batch # 8 loss=0.6236                                        \n",
      "Batch # 9 loss=0.6312                                        \n",
      "Batch # 10 loss=0.6258                                        \n",
      "Batch # 11 loss=0.6105                                        \n",
      "Batch # 12 loss=0.6065                                        \n",
      "Batch # 13 loss=0.6031                                        \n",
      "Batch # 14 loss=0.6063                                        \n",
      "Batch # 15 loss=0.5991                                        \n",
      "Batch # 16 loss=0.6031                                        \n",
      "Batch # 17 loss=0.5924                                        \n",
      "Batch # 18 loss=0.5698                                        \n",
      "Batch # 19 loss=0.5757                                        \n",
      "Batch # 20 loss=0.5950                                        \n",
      "Batch # 21 loss=0.5982                                        \n",
      "Batch # 22 loss=0.5573                                        \n",
      "========== EPOCH #3 ========== (0.6155/0.5674)        \n",
      "Batch # 1 loss=0.5696                                        \n",
      "Batch # 2 loss=0.5683                                        \n",
      "Batch # 3 loss=0.5602                                        \n",
      "Batch # 4 loss=0.5497                                        \n",
      "Batch # 5 loss=0.5371                                        \n",
      "Batch # 6 loss=0.5420                                        \n",
      "Batch # 7 loss=0.5304                                        \n",
      "Batch # 8 loss=0.5244                                        \n",
      "Batch # 9 loss=0.5235                                        \n",
      "Batch # 10 loss=0.5181                                        \n",
      "Batch # 11 loss=0.5057                                        \n",
      "Batch # 12 loss=0.5035                                        \n",
      "Batch # 13 loss=0.4956                                        \n",
      "Batch # 14 loss=0.4953                                        \n",
      "Batch # 15 loss=0.4985                                        \n",
      "Batch # 16 loss=0.4934                                        \n",
      "Batch # 17 loss=0.4903                                        \n",
      "Batch # 18 loss=0.4711                                        \n",
      "Batch # 19 loss=0.4658                                        \n",
      "Batch # 20 loss=0.4791                                        \n",
      "Batch # 21 loss=0.4811                                        \n",
      "Batch # 22 loss=0.4631                                        \n",
      "========== EPOCH #4 ========== (0.5121/0.4655)        \n",
      "Batch # 1 loss=0.4556                                        \n",
      "Batch # 2 loss=0.4637                                        \n",
      "Batch # 3 loss=0.4525                                        \n",
      "Batch # 4 loss=0.4562                                        \n",
      "Batch # 5 loss=0.4462                                        \n",
      "Batch # 6 loss=0.4543                                        \n",
      "Batch # 7 loss=0.4489                                        \n",
      "Batch # 8 loss=0.4408                                        \n",
      "Batch # 9 loss=0.4441                                        \n",
      "Batch # 10 loss=0.4414                                        \n",
      "Batch # 11 loss=0.4344                                        \n",
      "Batch # 12 loss=0.4391                                        \n",
      "Batch # 13 loss=0.4322                                        \n",
      "Batch # 14 loss=0.4311                                        \n",
      "Batch # 15 loss=0.4387                                        \n",
      "Batch # 16 loss=0.4377                                        \n",
      "Batch # 17 loss=0.4390                                        \n",
      "Batch # 18 loss=0.4230                                        \n",
      "Batch # 19 loss=0.4187                                        \n",
      "Batch # 20 loss=0.4334                                        \n",
      "Batch # 21 loss=0.4380                                        \n",
      "Batch # 22 loss=0.4280                                        \n",
      "========== EPOCH #5 ========== (0.4408/0.4315)        \n",
      "Batch # 1 loss=0.4223                                        \n",
      "Batch # 2 loss=0.4334                                        \n",
      "Batch # 3 loss=0.4234                                        \n",
      "Batch # 4 loss=0.4304                                        \n",
      "Batch # 5 loss=0.4186                                        \n",
      "Batch # 6 loss=0.4299                                        \n",
      "Batch # 7 loss=0.4277                                        \n",
      "Batch # 8 loss=0.4213                                        \n",
      "Batch # 9 loss=0.4255                                        \n",
      "Batch # 10 loss=0.4241                                        \n",
      "Batch # 11 loss=0.4184                                        \n",
      "Batch # 12 loss=0.4246                                        \n",
      "Batch # 13 loss=0.4193                                        \n",
      "Batch # 14 loss=0.4185                                        \n",
      "Batch # 15 loss=0.4274                                        \n",
      "Batch # 16 loss=0.4268                                        \n",
      "Batch # 17 loss=0.4285                                        \n",
      "Batch # 18 loss=0.4144                                        \n",
      "Batch # 19 loss=0.4099                                        \n",
      "Batch # 20 loss=0.4224                                        \n",
      "Batch # 21 loss=0.4271                                        \n",
      "Batch # 22 loss=0.4201                                        \n",
      "========== EPOCH #6 ========== (0.4234/0.4235)        \n",
      "Batch # 1 loss=0.4160                                        \n",
      "Batch # 2 loss=0.4206                                        \n",
      "Batch # 3 loss=0.4176                                        \n",
      "Batch # 4 loss=0.4225                                        \n",
      "Batch # 5 loss=0.4100                                        \n",
      "Batch # 6 loss=0.4231                                        \n",
      "Batch # 7 loss=0.4207                                        \n",
      "Batch # 8 loss=0.4131                                        \n",
      "Batch # 9 loss=0.4191                                        \n",
      "Batch # 10 loss=0.4176                                        \n",
      "Batch # 11 loss=0.4108                                        \n",
      "Batch # 12 loss=0.4181                                        \n",
      "Batch # 13 loss=0.4134                                        \n",
      "Batch # 14 loss=0.4112                                        \n",
      "Batch # 15 loss=0.4210                                        \n",
      "Batch # 16 loss=0.4205                                        \n",
      "Batch # 17 loss=0.4216                                        \n",
      "Batch # 18 loss=0.4092                                        \n",
      "Batch # 19 loss=0.4049                                        \n",
      "Batch # 20 loss=0.4144                                        \n",
      "Batch # 21 loss=0.4227                                        \n",
      "Batch # 22 loss=0.4145                                        \n",
      "========== EPOCH #7 ========== (0.4165/0.4162)        \n",
      "Batch # 1 loss=0.4087                                        \n",
      "Batch # 2 loss=0.4159                                        \n",
      "Batch # 3 loss=0.4101                                        \n",
      "Batch # 4 loss=0.4144                                        \n",
      "Batch # 5 loss=0.4055                                        \n",
      "Batch # 6 loss=0.4161                                        \n",
      "Batch # 7 loss=0.4142                                        \n",
      "Batch # 8 loss=0.4073                                        \n",
      "Batch # 9 loss=0.4113                                        \n",
      "Batch # 10 loss=0.4100                                        \n",
      "Batch # 11 loss=0.4038                                        \n",
      "Batch # 12 loss=0.4115                                        \n",
      "Batch # 13 loss=0.4064                                        \n",
      "Batch # 14 loss=0.4051                                        \n",
      "Batch # 15 loss=0.4162                                        \n",
      "Batch # 16 loss=0.4142                                        \n",
      "Batch # 17 loss=0.4146                                        \n",
      "Batch # 18 loss=0.4044                                        \n",
      "Batch # 19 loss=0.3978                                        \n",
      "Batch # 20 loss=0.4096                                        \n",
      "Batch # 21 loss=0.4165                                        \n",
      "Batch # 22 loss=0.4129                                        \n",
      "========== EPOCH #8 ========== (0.4103/0.4153)        \n",
      "Batch # 1 loss=0.4092                                        \n",
      "Batch # 2 loss=0.4119                                        \n",
      "Batch # 3 loss=0.4093                                        \n",
      "Batch # 4 loss=0.4143                                        \n",
      "Batch # 5 loss=0.4007                                        \n",
      "Batch # 6 loss=0.4155                                        \n",
      "Batch # 7 loss=0.4126                                        \n",
      "Batch # 8 loss=0.4054                                        \n",
      "Batch # 9 loss=0.4114                                        \n",
      "Batch # 10 loss=0.4092                                        \n",
      "Batch # 11 loss=0.4025                                        \n",
      "Batch # 12 loss=0.4103                                        \n",
      "Batch # 13 loss=0.4052                                        \n",
      "Batch # 14 loss=0.4034                                        \n",
      "Batch # 15 loss=0.4154                                        \n",
      "Batch # 16 loss=0.4131                                        \n",
      "Batch # 17 loss=0.4134                                        \n",
      "Batch # 18 loss=0.4039                                        \n",
      "Batch # 19 loss=0.3972                                        \n",
      "Batch # 20 loss=0.4078                                        \n",
      "Batch # 21 loss=0.4178                                        \n",
      "Batch # 22 loss=0.4095                                        \n",
      "========== EPOCH #9 ========== (0.4090/0.4108)        \n",
      "Batch # 1 loss=0.4042                                        \n",
      "Batch # 2 loss=0.4113                                        \n",
      "Batch # 3 loss=0.4053                                        \n",
      "Batch # 4 loss=0.4119                                        \n",
      "Batch # 5 loss=0.3989                                        \n",
      "Batch # 6 loss=0.4129                                        \n",
      "Batch # 7 loss=0.4111                                        \n",
      "Batch # 8 loss=0.4051                                        \n",
      "Batch # 9 loss=0.4081                                        \n",
      "Batch # 10 loss=0.4077                                        \n",
      "Batch # 11 loss=0.4011                                        \n",
      "Batch # 12 loss=0.4083                                        \n",
      "Batch # 13 loss=0.4038                                        \n",
      "Batch # 14 loss=0.4027                                        \n",
      "Batch # 15 loss=0.4132                                        \n",
      "Batch # 16 loss=0.4120                                        \n",
      "Batch # 17 loss=0.4123                                        \n",
      "Batch # 18 loss=0.4016                                        \n",
      "Batch # 19 loss=0.3960                                        \n",
      "Batch # 20 loss=0.4059                                        \n",
      "Batch # 21 loss=0.4149                                        \n",
      "Batch # 22 loss=0.4084                                        \n",
      "========== EPOCH #10 ========== (0.4071/0.4090)       \n",
      "Batch # 1 loss=0.4022                                        \n",
      "Batch # 2 loss=0.4087                                        \n",
      "Batch # 3 loss=0.4043                                        \n",
      "Batch # 4 loss=0.4102                                        \n",
      "Batch # 5 loss=0.3979                                        \n",
      "Batch # 6 loss=0.4118                                        \n",
      "Batch # 7 loss=0.4098                                        \n",
      "Batch # 8 loss=0.4033                                        \n",
      "Batch # 9 loss=0.4072                                        \n",
      "Batch # 10 loss=0.4063                                        \n",
      "Batch # 11 loss=0.3998                                        \n",
      "Batch # 12 loss=0.4070                                        \n",
      "Batch # 13 loss=0.4026                                        \n",
      "Batch # 14 loss=0.4012                                        \n",
      "Batch # 15 loss=0.4124                                        \n",
      "Batch # 16 loss=0.4107                                        \n",
      "Batch # 17 loss=0.4108                                        \n",
      "Batch # 18 loss=0.4008                                        \n",
      "Batch # 19 loss=0.3945                                        \n",
      "Batch # 20 loss=0.4052                                        \n",
      "Batch # 21 loss=0.4140                                        \n",
      "Batch # 22 loss=0.4078                                        \n",
      "========== EPOCH #11 ========== (0.4058/0.4096)       \n",
      "Batch # 1 loss=0.4037                                        \n",
      "Batch # 2 loss=0.4080                                        \n",
      "Batch # 3 loss=0.4040                                        \n",
      "Batch # 4 loss=0.4103                                        \n",
      "Batch # 5 loss=0.3968                                        \n",
      "Batch # 6 loss=0.4113                                        \n",
      "Batch # 7 loss=0.4090                                        \n",
      "Batch # 8 loss=0.4019                                        \n",
      "Batch # 9 loss=0.4067                                        \n",
      "Batch # 10 loss=0.4053                                        \n",
      "Batch # 11 loss=0.3988                                        \n",
      "Batch # 12 loss=0.4060                                        \n",
      "Batch # 13 loss=0.4014                                        \n",
      "Batch # 14 loss=0.4001                                        \n",
      "Batch # 15 loss=0.4118                                        \n",
      "Batch # 16 loss=0.4096                                        \n",
      "Batch # 17 loss=0.4098                                        \n",
      "Batch # 18 loss=0.4001                                        \n",
      "Batch # 19 loss=0.3932                                        \n",
      "Batch # 20 loss=0.4047                                        \n",
      "Batch # 21 loss=0.4129                                        \n",
      "Batch # 22 loss=0.4073                                        \n",
      "========== EPOCH #12 ========== (0.4051/0.4106)       \n",
      "Batch # 1 loss=0.4054                                        \n",
      "Batch # 2 loss=0.4062                                        \n",
      "Batch # 3 loss=0.4043                                        \n",
      "Batch # 4 loss=0.4107                                        \n",
      "Batch # 5 loss=0.3957                                        \n",
      "Batch # 6 loss=0.4113                                        \n",
      "Batch # 7 loss=0.4084                                        \n",
      "Batch # 8 loss=0.4007                                        \n",
      "Batch # 9 loss=0.4066                                        \n",
      "Batch # 10 loss=0.4046                                        \n",
      "Batch # 11 loss=0.3977                                        \n",
      "Batch # 12 loss=0.4052                                        \n",
      "Batch # 13 loss=0.4006                                        \n",
      "Batch # 14 loss=0.3989                                        \n",
      "Batch # 15 loss=0.4113                                        \n",
      "Batch # 16 loss=0.4086                                        \n",
      "Batch # 17 loss=0.4086                                        \n",
      "Batch # 18 loss=0.3997                                        \n",
      "Batch # 19 loss=0.3920                                        \n",
      "Batch # 20 loss=0.4037                                        \n",
      "Batch # 21 loss=0.4128                                        \n",
      "Batch # 22 loss=0.4055                                        \n",
      "========== EPOCH #13 ========== (0.4045/0.4092)       \n",
      "Batch # 1 loss=0.4042                                        \n",
      "Batch # 2 loss=0.4052                                        \n",
      "Batch # 3 loss=0.4022                                        \n",
      "Batch # 4 loss=0.4100                                        \n",
      "Batch # 5 loss=0.3942                                        \n",
      "Batch # 6 loss=0.4097                                        \n",
      "Batch # 7 loss=0.4078                                        \n",
      "Batch # 8 loss=0.3994                                        \n",
      "Batch # 9 loss=0.4048                                        \n",
      "Batch # 10 loss=0.4038                                        \n",
      "Batch # 11 loss=0.3961                                        \n",
      "Batch # 12 loss=0.4036                                        \n",
      "Batch # 13 loss=0.3997                                        \n",
      "Batch # 14 loss=0.3975                                        \n",
      "Batch # 15 loss=0.4102                                        \n",
      "Batch # 16 loss=0.4077                                        \n",
      "Batch # 17 loss=0.4069                                        \n",
      "Batch # 18 loss=0.3987                                        \n",
      "Batch # 19 loss=0.3909                                        \n",
      "Batch # 20 loss=0.4019                                        \n",
      "Batch # 21 loss=0.4119                                        \n",
      "Batch # 22 loss=0.4040                                        \n",
      "========== EPOCH #14 ========== (0.4032/0.4071)       \n",
      "Batch # 1 loss=0.4023                                        \n",
      "Batch # 2 loss=0.4039                                        \n",
      "Batch # 3 loss=0.4006                                        \n",
      "Batch # 4 loss=0.4082                                        \n",
      "Batch # 5 loss=0.3930                                        \n",
      "Batch # 6 loss=0.4085                                        \n",
      "Batch # 7 loss=0.4061                                        \n",
      "Batch # 8 loss=0.3980                                        \n",
      "Batch # 9 loss=0.4033                                        \n",
      "Batch # 10 loss=0.4021                                        \n",
      "Batch # 11 loss=0.3948                                        \n",
      "Batch # 12 loss=0.4019                                        \n",
      "Batch # 13 loss=0.3980                                        \n",
      "Batch # 14 loss=0.3962                                        \n",
      "Batch # 15 loss=0.4088                                        \n",
      "Batch # 16 loss=0.4061                                        \n",
      "Batch # 17 loss=0.4055                                        \n",
      "Batch # 18 loss=0.3970                                        \n",
      "Batch # 19 loss=0.3893                                        \n",
      "Batch # 20 loss=0.4009                                        \n",
      "Batch # 21 loss=0.4096                                        \n",
      "Batch # 22 loss=0.4037                                        \n",
      "========== EPOCH #15 ========== (0.4017/0.4077)       \n",
      "Batch # 1 loss=0.4037                                        \n",
      "Batch # 2 loss=0.4022                                        \n",
      "Batch # 3 loss=0.4013                                        \n",
      "Batch # 4 loss=0.4075                                        \n",
      "Batch # 5 loss=0.3922                                        \n",
      "Batch # 6 loss=0.4089                                        \n",
      "Batch # 7 loss=0.4044                                        \n",
      "Batch # 8 loss=0.3969                                        \n",
      "Batch # 9 loss=0.4030                                        \n",
      "Batch # 10 loss=0.4003                                        \n",
      "Batch # 11 loss=0.3944                                        \n",
      "Batch # 12 loss=0.4007                                        \n",
      "Batch # 13 loss=0.3964                                        \n",
      "Batch # 14 loss=0.3955                                        \n",
      "Batch # 15 loss=0.4076                                        \n",
      "Batch # 16 loss=0.4049                                        \n",
      "Batch # 17 loss=0.4047                                        \n",
      "Batch # 18 loss=0.3955                                        \n",
      "Batch # 19 loss=0.3883                                        \n",
      "Batch # 20 loss=0.4001                                        \n",
      "Batch # 21 loss=0.4079                                        \n",
      "Batch # 22 loss=0.4033                                        \n",
      "========== EPOCH #16 ========== (0.4009/0.4080)       \n",
      "Batch # 1 loss=0.4045                                        \n",
      "Batch # 2 loss=0.4008                                        \n",
      "Batch # 3 loss=0.4015                                        \n",
      "Batch # 4 loss=0.4069                                        \n",
      "Batch # 5 loss=0.3913                                        \n",
      "Batch # 6 loss=0.4089                                        \n",
      "Batch # 7 loss=0.4032                                        \n",
      "Batch # 8 loss=0.3959                                        \n",
      "Batch # 9 loss=0.4024                                        \n",
      "Batch # 10 loss=0.3991                                        \n",
      "Batch # 11 loss=0.3936                                        \n",
      "Batch # 12 loss=0.3996                                        \n",
      "Batch # 13 loss=0.3952                                        \n",
      "Batch # 14 loss=0.3946                                        \n",
      "Batch # 15 loss=0.4068                                        \n",
      "Batch # 16 loss=0.4038                                        \n",
      "Batch # 17 loss=0.4036                                        \n",
      "Batch # 18 loss=0.3946                                        \n",
      "Batch # 19 loss=0.3872                                        \n",
      "Batch # 20 loss=0.3993                                        \n",
      "Batch # 21 loss=0.4070                                        \n",
      "Batch # 22 loss=0.4019                                        \n",
      "========== EPOCH #17 ========== (0.4001/0.4075)       \n",
      "Batch # 1 loss=0.4045                                        \n",
      "Batch # 2 loss=0.3996                                        \n",
      "Batch # 3 loss=0.4003                                        \n",
      "Batch # 4 loss=0.4066                                        \n",
      "Batch # 5 loss=0.3898                                        \n",
      "Batch # 6 loss=0.4082                                        \n",
      "Batch # 7 loss=0.4025                                        \n",
      "Batch # 8 loss=0.3945                                        \n",
      "Batch # 9 loss=0.4015                                        \n",
      "Batch # 10 loss=0.3982                                        \n",
      "Batch # 11 loss=0.3922                                        \n",
      "Batch # 12 loss=0.3985                                        \n",
      "Batch # 13 loss=0.3941                                        \n",
      "Batch # 14 loss=0.3933                                        \n",
      "Batch # 15 loss=0.4062                                        \n",
      "Batch # 16 loss=0.4027                                        \n",
      "Batch # 17 loss=0.4023                                        \n",
      "Batch # 18 loss=0.3940                                        \n",
      "Batch # 19 loss=0.3859                                        \n",
      "Batch # 20 loss=0.3983                                        \n",
      "Batch # 21 loss=0.4064                                        \n",
      "Batch # 22 loss=0.4002                                        \n",
      "========== EPOCH #18 ========== (0.3991/0.4065)       \n",
      "Batch # 1 loss=0.4037                                        \n",
      "Batch # 2 loss=0.3985                                        \n",
      "Batch # 3 loss=0.3987                                        \n",
      "Batch # 4 loss=0.4058                                        \n",
      "Batch # 5 loss=0.3886                                        \n",
      "Batch # 6 loss=0.4071                                        \n",
      "Batch # 7 loss=0.4017                                        \n",
      "Batch # 8 loss=0.3932                                        \n",
      "Batch # 9 loss=0.4003                                        \n",
      "Batch # 10 loss=0.3972                                        \n",
      "Batch # 11 loss=0.3909                                        \n",
      "Batch # 12 loss=0.3972                                        \n",
      "Batch # 13 loss=0.3931                                        \n",
      "Batch # 14 loss=0.3922                                        \n",
      "Batch # 15 loss=0.4053                                        \n",
      "Batch # 16 loss=0.4018                                        \n",
      "Batch # 17 loss=0.4010                                        \n",
      "Batch # 18 loss=0.3931                                        \n",
      "Batch # 19 loss=0.3850                                        \n",
      "Batch # 20 loss=0.3972                                        \n",
      "Batch # 21 loss=0.4054                                        \n",
      "Batch # 22 loss=0.3990                                        \n",
      "========== EPOCH #19 ========== (0.3980/0.4055)       \n",
      "Batch # 1 loss=0.4030                                        \n",
      "Batch # 2 loss=0.3975                                        \n",
      "Batch # 3 loss=0.3977                                        \n",
      "Batch # 4 loss=0.4048                                        \n",
      "Batch # 5 loss=0.3877                                        \n",
      "Batch # 6 loss=0.4064                                        \n",
      "Batch # 7 loss=0.4006                                        \n",
      "Batch # 8 loss=0.3922                                        \n",
      "Batch # 9 loss=0.3993                                        \n",
      "Batch # 10 loss=0.3960                                        \n",
      "Batch # 11 loss=0.3901                                        \n",
      "Batch # 12 loss=0.3960                                        \n",
      "Batch # 13 loss=0.3921                                        \n",
      "Batch # 14 loss=0.3914                                        \n",
      "Batch # 15 loss=0.4043                                        \n",
      "Batch # 16 loss=0.4010                                        \n",
      "Batch # 17 loss=0.4001                                        \n",
      "Batch # 18 loss=0.3920                                        \n",
      "Batch # 19 loss=0.3842                                        \n",
      "Batch # 20 loss=0.3963                                        \n",
      "Batch # 21 loss=0.4043                                        \n",
      "Batch # 22 loss=0.3983                                        \n",
      "========== EPOCH #20 ========== (0.3971/0.4049)       \n",
      "Batch # 1 loss=0.4027                                        \n",
      "Batch # 2 loss=0.3966                                        \n",
      "Batch # 3 loss=0.3971                                        \n",
      "Batch # 4 loss=0.4041                                        \n",
      "Batch # 5 loss=0.3871                                        \n",
      "Batch # 6 loss=0.4059                                        \n",
      "Batch # 7 loss=0.3997                                        \n",
      "Batch # 8 loss=0.3915                                        \n",
      "Batch # 9 loss=0.3986                                        \n",
      "Batch # 10 loss=0.3951                                        \n",
      "Batch # 11 loss=0.3896                                        \n",
      "Batch # 12 loss=0.3951                                        \n",
      "Batch # 13 loss=0.3914                                        \n",
      "Batch # 14 loss=0.3907                                        \n",
      "Batch # 15 loss=0.4037                                        \n",
      "Batch # 16 loss=0.4004                                        \n",
      "Batch # 17 loss=0.3993                                        \n",
      "Batch # 18 loss=0.3914                                        \n",
      "Batch # 19 loss=0.3836                                        \n",
      "Batch # 20 loss=0.3956                                        \n",
      "Batch # 21 loss=0.4036                                        \n",
      "Batch # 22 loss=0.3973                                        \n",
      "========== EPOCH #21 ========== (0.3964/0.4041)       \n",
      "Batch # 1 loss=0.4020                                        \n",
      "Batch # 2 loss=0.3959                                        \n",
      "Batch # 3 loss=0.3960                                        \n",
      "Batch # 4 loss=0.4036                                        \n",
      "Batch # 5 loss=0.3863                                        \n",
      "Batch # 6 loss=0.4052                                        \n",
      "Batch # 7 loss=0.3992                                        \n",
      "Batch # 8 loss=0.3906                                        \n",
      "Batch # 9 loss=0.3978                                        \n",
      "Batch # 10 loss=0.3946                                        \n",
      "Batch # 11 loss=0.3887                                        \n",
      "Batch # 12 loss=0.3943                                        \n",
      "Batch # 13 loss=0.3909                                        \n",
      "Batch # 14 loss=0.3899                                        \n",
      "Batch # 15 loss=0.4032                                        \n",
      "Batch # 16 loss=0.3999                                        \n",
      "Batch # 17 loss=0.3984                                        \n",
      "Batch # 18 loss=0.3911                                        \n",
      "Batch # 19 loss=0.3828                                        \n",
      "Batch # 20 loss=0.3947                                        \n",
      "Batch # 21 loss=0.4029                                        \n",
      "Batch # 22 loss=0.3960                                        \n",
      "========== EPOCH #22 ========== (0.3956/0.4031)       \n",
      "Batch # 1 loss=0.4012                                        \n",
      "Batch # 2 loss=0.3954                                        \n",
      "Batch # 3 loss=0.3944                                        \n",
      "Batch # 4 loss=0.4027                                        \n",
      "Batch # 5 loss=0.3855                                        \n",
      "Batch # 6 loss=0.4038                                        \n",
      "Batch # 7 loss=0.3985                                        \n",
      "Batch # 8 loss=0.3896                                        \n",
      "Batch # 9 loss=0.3973                                        \n",
      "Batch # 10 loss=0.3938                                        \n",
      "Batch # 11 loss=0.3877                                        \n",
      "Batch # 12 loss=0.3932                                        \n",
      "Batch # 13 loss=0.3900                                        \n",
      "Batch # 14 loss=0.3889                                        \n",
      "Batch # 15 loss=0.4018                                        \n",
      "Batch # 16 loss=0.3981                                        \n",
      "Batch # 17 loss=0.3967                                        \n",
      "Batch # 18 loss=0.3880                                        \n",
      "Batch # 19 loss=0.3806                                        \n",
      "Batch # 20 loss=0.3922                                        \n",
      "Batch # 21 loss=0.3992                                        \n",
      "Batch # 22 loss=0.3918                                        \n",
      "========== EPOCH #23 ========== (0.3941/0.4010)       \n",
      "Batch # 1 loss=0.3998                                        \n",
      "Batch # 2 loss=0.3925                                        \n",
      "Batch # 3 loss=0.3916                                        \n",
      "Batch # 4 loss=0.3992                                        \n",
      "Batch # 5 loss=0.3833                                        \n",
      "Batch # 6 loss=0.4002                                        \n",
      "Batch # 7 loss=0.3925                                        \n",
      "Batch # 8 loss=0.3870                                        \n",
      "Batch # 9 loss=0.3930                                        \n",
      "Batch # 10 loss=0.3869                                        \n",
      "Batch # 11 loss=0.3837                                        \n",
      "Batch # 12 loss=0.3841                                        \n",
      "Batch # 13 loss=0.3833                                        \n",
      "Batch # 14 loss=0.3831                                        \n",
      "Batch # 15 loss=0.3929                                        \n",
      "Batch # 16 loss=0.3930                                        \n",
      "Batch # 17 loss=0.3901                                        \n",
      "Batch # 18 loss=0.3798                                        \n",
      "Batch # 19 loss=0.3759                                        \n",
      "Batch # 20 loss=0.3851                                        \n",
      "Batch # 21 loss=0.3907                                        \n",
      "Batch # 22 loss=0.3853                                        \n",
      "========== EPOCH #24 ========== (0.3888/0.3940)       \n",
      "Batch # 1 loss=0.3937                                        \n",
      "Batch # 2 loss=0.3856                                        \n",
      "Batch # 3 loss=0.3867                                        \n",
      "Batch # 4 loss=0.3920                                        \n",
      "Batch # 5 loss=0.3786                                        \n",
      "Batch # 6 loss=0.3943                                        \n",
      "Batch # 7 loss=0.3831                                        \n",
      "Batch # 8 loss=0.3808                                        \n",
      "Batch # 9 loss=0.3854                                        \n",
      "Batch # 10 loss=0.3805                                        \n",
      "Batch # 11 loss=0.3804                                        \n",
      "Batch # 12 loss=0.3804                                        \n",
      "Batch # 13 loss=0.3797                                        \n",
      "Batch # 14 loss=0.3797                                        \n",
      "Batch # 15 loss=0.3910                                        \n",
      "Batch # 16 loss=0.3899                                        \n",
      "Batch # 17 loss=0.3881                                        \n",
      "Batch # 18 loss=0.3784                                        \n",
      "Batch # 19 loss=0.3725                                        \n",
      "Batch # 20 loss=0.3835                                        \n",
      "Batch # 21 loss=0.3889                                        \n",
      "Batch # 22 loss=0.3804                                        \n",
      "========== EPOCH #25 ========== (0.3843/0.3904)       \n",
      "Batch # 1 loss=0.3892                                        \n",
      "Batch # 2 loss=0.3835                                        \n",
      "Batch # 3 loss=0.3798                                        \n",
      "Batch # 4 loss=0.3915                                        \n",
      "Batch # 5 loss=0.3751                                        \n",
      "Batch # 6 loss=0.3897                                        \n",
      "Batch # 7 loss=0.3832                                        \n",
      "Batch # 8 loss=0.3768                                        \n",
      "Batch # 9 loss=0.3827                                        \n",
      "Batch # 10 loss=0.3791                                        \n",
      "Batch # 11 loss=0.3755                                        \n",
      "Batch # 12 loss=0.3784                                        \n",
      "Batch # 13 loss=0.3783                                        \n",
      "Batch # 14 loss=0.3760                                        \n",
      "Batch # 15 loss=0.3887                                        \n",
      "Batch # 16 loss=0.3869                                        \n",
      "Batch # 17 loss=0.3840                                        \n",
      "Batch # 18 loss=0.3771                                        \n",
      "Batch # 19 loss=0.3689                                        \n",
      "Batch # 20 loss=0.3798                                        \n",
      "Batch # 21 loss=0.3864                                        \n",
      "Batch # 22 loss=0.3726                                        \n",
      "========== EPOCH #26 ========== (0.3811/0.3824)       \n",
      "Batch # 1 loss=0.3809                                        \n",
      "Batch # 2 loss=0.3802                                        \n",
      "Batch # 3 loss=0.3712                                        \n",
      "Batch # 4 loss=0.3837                                        \n",
      "Batch # 5 loss=0.3691                                        \n",
      "Batch # 6 loss=0.3837                                        \n",
      "Batch # 7 loss=0.3751                                        \n",
      "Batch # 8 loss=0.3723                                        \n",
      "Batch # 9 loss=0.3753                                        \n",
      "Batch # 10 loss=0.3743                                        \n",
      "Batch # 11 loss=0.3684                                        \n",
      "Batch # 12 loss=0.3721                                        \n",
      "Batch # 13 loss=0.3717                                        \n",
      "Batch # 14 loss=0.3712                                        \n",
      "Batch # 15 loss=0.3809                                        \n",
      "Batch # 16 loss=0.3802                                        \n",
      "Batch # 17 loss=0.3784                                        \n",
      "Batch # 18 loss=0.3677                                        \n",
      "Batch # 19 loss=0.3626                                        \n",
      "Batch # 20 loss=0.3725                                        \n",
      "Batch # 21 loss=0.3783                                        \n",
      "Batch # 22 loss=0.3664                                        \n",
      "========== EPOCH #27 ========== (0.3744/0.3788)       \n",
      "Batch # 1 loss=0.3786                                        \n",
      "Batch # 2 loss=0.3760                                        \n",
      "Batch # 3 loss=0.3708                                        \n",
      "Batch # 4 loss=0.3757                                        \n",
      "Batch # 5 loss=0.3704                                        \n",
      "Batch # 6 loss=0.3804                                        \n",
      "Batch # 7 loss=0.3704                                        \n",
      "Batch # 8 loss=0.3697                                        \n",
      "Batch # 9 loss=0.3685                                        \n",
      "Batch # 10 loss=0.3689                                        \n",
      "Batch # 11 loss=0.3660                                        \n",
      "Batch # 12 loss=0.3685                                        \n",
      "Batch # 13 loss=0.3696                                        \n",
      "Batch # 14 loss=0.3677                                        \n",
      "Batch # 15 loss=0.3764                                        \n",
      "Batch # 16 loss=0.3780                                        \n",
      "Batch # 17 loss=0.3743                                        \n",
      "Batch # 18 loss=0.3654                                        \n",
      "Batch # 19 loss=0.3601                                        \n",
      "Batch # 20 loss=0.3684                                        \n",
      "Batch # 21 loss=0.3753                                        \n",
      "Batch # 22 loss=0.3633                                        \n",
      "========== EPOCH #28 ========== (0.3710/0.3731)       \n",
      "Batch # 1 loss=0.3729                                        \n",
      "Batch # 2 loss=0.3727                                        \n",
      "Batch # 3 loss=0.3652                                        \n",
      "Batch # 4 loss=0.3737                                        \n",
      "Batch # 5 loss=0.3655                                        \n",
      "Batch # 6 loss=0.3787                                        \n",
      "Batch # 7 loss=0.3673                                        \n",
      "Batch # 8 loss=0.3651                                        \n",
      "Batch # 9 loss=0.3672                                        \n",
      "Batch # 10 loss=0.3657                                        \n",
      "Batch # 11 loss=0.3620                                        \n",
      "Batch # 12 loss=0.3674                                        \n",
      "Batch # 13 loss=0.3654                                        \n",
      "Batch # 14 loss=0.3664                                        \n",
      "Batch # 15 loss=0.3751                                        \n",
      "Batch # 16 loss=0.3747                                        \n",
      "Batch # 17 loss=0.3731                                        \n",
      "Batch # 18 loss=0.3636                                        \n",
      "Batch # 19 loss=0.3584                                        \n",
      "Batch # 20 loss=0.3675                                        \n",
      "Batch # 21 loss=0.3747                                        \n",
      "Batch # 22 loss=0.3612                                        \n",
      "========== EPOCH #29 ========== (0.3683/0.3720)       \n",
      "Batch # 1 loss=0.3717                                        \n",
      "Batch # 2 loss=0.3715                                        \n",
      "Batch # 3 loss=0.3635                                        \n",
      "Batch # 4 loss=0.3723                                        \n",
      "Batch # 5 loss=0.3651                                        \n",
      "Batch # 6 loss=0.3777                                        \n",
      "Batch # 7 loss=0.3665                                        \n",
      "Batch # 8 loss=0.3650                                        \n",
      "Batch # 9 loss=0.3658                                        \n",
      "Batch # 10 loss=0.3651                                        \n",
      "Batch # 11 loss=0.3621                                        \n",
      "Batch # 12 loss=0.3666                                        \n",
      "Batch # 13 loss=0.3654                                        \n",
      "Batch # 14 loss=0.3657                                        \n",
      "Batch # 15 loss=0.3745                                        \n",
      "Batch # 16 loss=0.3742                                        \n",
      "Batch # 17 loss=0.3726                                        \n",
      "Batch # 18 loss=0.3623                                        \n",
      "Batch # 19 loss=0.3581                                        \n",
      "Batch # 20 loss=0.3661                                        \n",
      "Batch # 21 loss=0.3740                                        \n",
      "Batch # 22 loss=0.3602                                        \n",
      "========== EPOCH #30 ========== (0.3675/0.3707)       \n"
     ]
    }
   ],
   "source": [
    "# models = get_models(params)\n",
    "train_model(params, models, dataset, \"deep_torch_11000\", save_frequency=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2674a-fb87-4c50-a726-32d39a29bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weigths(models, path_node_gnn, path_edge_linear):\n",
    "    models[0].load_state_dict(torch.load(path_node_gnn, weights_only=True))\n",
    "    models[1].load_state_dict(torch.load(path_edge_linear, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca54f343-cb1a-4731-9c2c-c0d71d48c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_load = get_models(params)\n",
    "load_weigths(models_load, \"deep_torch_11000_node_gnn_end\", \"deep_torch_11000_edge_linear_end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4d097ece-7450-4682-b01d-f178dc020a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_classification_edges(models, graph, k=0.51):\n",
    "    i = graph[\"A\"]\n",
    "    v_in = [rev_dist(e) for e in graph[\"edges_feature\"]]\n",
    "    x = graph[\"nodes_feature\"]\n",
    "    N = len(x)\n",
    "    X = torch.tensor(data=x, dtype=torch.float32)\n",
    "    sp_A = torch.sparse_coo_tensor(indices=i, values=v_in, size=(N, N), dtype=torch.float32)\n",
    "    \n",
    "    H_end = models[0](X, sp_A)\n",
    "    Omega = torch.cat([H_end[i[0]], H_end[i[1]]],dim=1)\n",
    "    E_pred = models[1](Omega)\n",
    "    a = np.zeros(E_pred.shape)\n",
    "    return E_pred\n",
    "    a[E_pred>k] = 1.0\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecfdfcd6-00c4-4813-bb17-29d5a86bd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch_classification_edges(models, dataset[1], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bac399b2-9eee-4986-992a-6fc2b542b441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3835616438356164)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mask == np.array(dataset[2]['true_edges']))/ len(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ca165-54bb-435f-87e6-436d5935df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.90 -  1500 \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7192cb90-9f67-4d5f-816a-32883794b407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f7eb3-f353-43c8-9ccc-b75d80e6551c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
